{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T4_old_optimal_epochs.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPnwWCJgEp54UdYEDXmCsD3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/voquangtuong/AAA_drought_prediction/blob/main/T4_old_optimal_epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjmSI_mvaIwc",
        "outputId": "795fa190-3203-4e5b-f7ca-3b5231386fef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZ50DaMaTDl"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/dynamic/T4old')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-26pZn4sRVR3"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Nov 19 00:18:39 2021\n",
        "Bo het historical NDI o droplist1a\n",
        "\n",
        "@author: Administrator\n",
        "\"\"\"\n",
        "\n",
        "# from lstm_utils import *\n",
        "import pickle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "####LIBRARY\n",
        "import scipy\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow import keras # tai sao import tu tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "# =============================================================================\n",
        "# Import library\n",
        "import os \n",
        "os.chdir('/content/drive/MyDrive/dynamic/T4old')\n",
        "outs=['save_model_T4','save_pickle','table_T4','fig_T4']\n",
        "for out in outs:\n",
        "  if not os.path.exists(out):\n",
        "    os.makedirs(out)\n",
        "# =============================================================================\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"all_utils.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1ydQW-LmuXBguZbpvhMM2-LpdkVfdpRrg\n",
        "\"\"\"\n",
        "\n",
        "# !pip install -q -U keras-tuner --q\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "####LIBRARY\n",
        "import scipy\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import Sequential, optimizers, backend\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow import keras # tai sao import tu tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# ROC\n",
        "import datetime\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.dates as mdates\n",
        "import datetime\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# import statsmodels as sm\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib\n",
        "###  SET FONTS FOR PLOTTING\n",
        "font = {'family' : 'normal',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 12}\n",
        "\n",
        "matplotlib.rc('font', **font)\n",
        "### cap nhat font\n",
        "# plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "####RANDOM SEED SET\n",
        "#tf.random.set_seed(10000000)\n",
        "#np.random.seed(10000000)\n",
        "\n",
        "####PANDAS LIB\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "###### Univrate LSTM\n",
        "# univariate lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "######## Keras tunner\n",
        "# import keras_tuner as kt\n",
        "\n",
        "################################################\n",
        "# CUSTOMIZE FUNCTION\n",
        "# generate sample data by pandas shift\n",
        " ####cutomized sub.\n",
        "def series_to_supervised_df(data, n_in, n_out, dropnan=True): # dung cho pandas\n",
        "\t\"\"\"\n",
        "\tFrame a time series as a supervised learning dataset.\n",
        "\tArguments:\n",
        "\t\tdata: Sequence of observations as a list or NumPy array.\n",
        "\t\tn_in: Number of lag observations as input (X).\n",
        "\t\tn_out: Number of observations as output (y).\n",
        "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
        "\tReturns:\n",
        "\t\tPandas DataFrame of series framed for supervised learning.\n",
        "\t\"\"\"\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg\n",
        "\n",
        "  # SAMPLE GENERATE\n",
        "\n",
        "# CREATE A DATA INPUT FOR MODEL\n",
        "#####################################################\n",
        "def generate_input_M1(dataset,dataset_climate,k0,n_in0,n_out0):\n",
        "  # n_window0=5\n",
        "  dataset0=dataset[k0]\n",
        "  dataset0_climate=dataset_climate[k0]\n",
        "  df_supervised0=series_to_supervised_df(dataset0,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  df_supervised0_climate=series_to_supervised_df(dataset0_climate,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  # thang df_supervisied000: tong hop cua mo hinh quan trac + thay doi gia tri tai t ban mo hinh khi hau\n",
        "  df_supervised0.iloc[:,[-2,-3,-4]]=df_supervised0_climate.iloc[:,[-2,-3,-4]]\n",
        "  df_supervised0_obs_cli=df_supervised0_climate # da co so lieu cua climate model o day\n",
        "  \"\"\"## loai bo cac gia tri cua NDI theo thang CH* Han\"\"\"\n",
        "  # Bo het NDI\n",
        "  drop1=np.array(range(3,df_supervised0_obs_cli.shape[1],4)) # toan bo gia tri NDI trong input\n",
        "  # print(drop1)\n",
        "\n",
        "  drop1a=drop1[:-1] # chua lai thang cuoi la thang du bao\n",
        "  # print(drop1a) \n",
        "  # # van giu lai dam lau la luc lac tai buoc t. Khong bo gi het\n",
        "  # # drop2=np.array(range(df_supervised0.shape[1]))\n",
        "  # # print(drop2)\n",
        "  # ########  QUAN TRONG\n",
        "  # ''' bo het cac bien cua NDI trong phan input (drop1)\n",
        "\n",
        "  # input cua PRS gom 2 phan:\n",
        "  # phan 1: gia tri thuc do tu dau den buoc t-1\n",
        "  # phan 2: gia tri cua mo hinh du bao tai buoc t\n",
        "  # -> giai quyet bang cach go bo cac gia tri PRS tai t\n",
        "  # thay bang cac gia tri cua mo hinh du bao tai buoc t\n",
        "  # khong can bo thang drop 2, chi can thay no ban gia tri trong mo hinh khi hau la duoc\n",
        "\n",
        "  # '''\n",
        "\n",
        "  # # drop2a=drop2[df_supervised0.shape[1]-4:df_supervised0.shape[1]-1]\n",
        "  # # print(drop2a)\n",
        "  list_drop_cols=[]\n",
        "\n",
        "  [list_drop_cols.append(drop) for drop in drop1a]\n",
        "  # # [list_drop_cols.append(drop) for drop in drop2a]\n",
        "  # # print(list_drop_cols)\n",
        "\n",
        "  # \"\"\"## Bo di bay lu khon nan\"\"\"\n",
        "\n",
        "  df_supervised=df_supervised0_obs_cli.drop(df_supervised0_obs_cli.columns[[list_drop_cols]],axis=1)\n",
        "  # df_supervised\n",
        "\n",
        "  \"\"\"# Chia du lieu theo ti le0.6:0.2:0.2\"\"\"\n",
        "\n",
        "  # chieu dai cua train\n",
        "  n_train=int(df_supervised.shape[0]*0.6)\n",
        "  # print(n_train)\n",
        "  n_val=int(df_supervised.shape[0]*0.8)-n_train\n",
        "  n_test=df_supervised.shape[0]-n_val-n_train\n",
        "  # print(n_val)\n",
        "  # print(n_test)\n",
        "\n",
        "  # df train, val, test\n",
        "  train_df=df_supervised.iloc[0:n_train,:]\n",
        "  val_df=df_supervised.iloc[n_train:n_train+n_val,:]\n",
        "  test_df=df_supervised.iloc[n_train+n_val:,:]\n",
        "  # print(train_df.shape,val_df.shape,test_df.shape)\n",
        "  # 342 doan dau vao, moi doan la 16 dactinh\n",
        "  # bao gom 3 bien x5 buoc + bien dau ra -> 16 bien\n",
        "  # moi an doc 1 buoc \n",
        "  # bo vao 15 gia tri x so batsize de du bao gia tri 16\n",
        "\n",
        "  \"\"\"## Phan ra du lieu de train va target \"\"\"\n",
        "\n",
        "  x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "  y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "  # print(x_train.shape,y_train.shape)\n",
        "\n",
        "  x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "  y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "  # print(x_val.shape,y_val.shape)\n",
        "\n",
        "  x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "  y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "  # print(x_test.shape,y_test.shape)\n",
        "\n",
        "  ## check input_train\n",
        "  # print('input',x_train[0], 'output',y_train[0])\n",
        "  # print('df_train',train_df.iloc[0,:])\n",
        "  # gia tri output va gia tri du bao phai giong nhau\n",
        "\n",
        "  \"\"\"# Scale Max-Min data\"\"\"\n",
        "\n",
        "  # tao 2 scaler rieng cho X, Y de invert cho de\n",
        "  scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "  scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "  x_train_scale = scaler_x.fit_transform(x_train)\n",
        "  y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "  # fit scale cua train cho val va test\n",
        "  x_val_scale=scaler_x.transform(x_val)\n",
        "  y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "  x_test_scale=scaler_x.transform(x_test)\n",
        "  y_test_scale=scaler_y.transform(y_test)\n",
        "\n",
        "  \"\"\"# Tensorflow format\"\"\"\n",
        "\n",
        "  # # reshape input to be 3D [samples, timesteps, features]\n",
        "  # n_features=1\n",
        "  # train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "  # val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "  # test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "\n",
        "  # Kiem tra lai\n",
        "  n_features=1\n",
        "  train_X = x_train_scale.reshape((x_train_scale.shape[0], n_features,x_train_scale.shape[1]))\n",
        "  val_X = x_val_scale.reshape((x_val_scale.shape[0],  n_features,x_val_scale.shape[1]))\n",
        "  test_X = x_test_scale.reshape((x_test_scale.shape[0], n_features, x_test_scale.shape[1]))\n",
        "  print(['input shape output shape'])\n",
        "  print(train_X.shape,y_train_scale.shape)\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "  return train_X, y_train_scale, val_X,y_val_scale,test_X,y_test_scale,scaler_y,n_train,n_val\n",
        "\n",
        "#######################################################################################\n",
        "\n",
        "def generate_input_M2(dataset,dataset_climate,k0,n_in0,n_out0):\n",
        "  # n_window0=5\n",
        "  dataset0=dataset[k0]\n",
        "  dataset0_climate=dataset_climate[k0]\n",
        "  df_supervised0=series_to_supervised_df(dataset0,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  df_supervised0_climate=series_to_supervised_df(dataset0_climate,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  # thay doi cac gia tri cho mo hinh khi hau\n",
        "  df_supervised0.iloc[:,[-2,-3,-4,-6,-7,-8]]=df_supervised0_climate.iloc[:,[-2,-3,-4,-6,-7,-8]]\n",
        "  df_supervised0_obs_cli=df_supervised0_climate # da co so lieu cua climate model o day\n",
        "  \"\"\"## loai bo cac gia tri cua NDI theo thang CH* Han\"\"\"\n",
        "  # Bo het NDI\n",
        "  drop1=np.array(range(3,df_supervised0_obs_cli.shape[1],4)) # toan bo gia tri NDI trong input\n",
        "  # print(drop1)\n",
        "\n",
        "  drop1a=drop1[:-1] # chua lai thang cuoi la thang du bao\n",
        "  # print(drop1a) \n",
        "  # # van giu lai dam lau la luc lac tai buoc t. Khong bo gi het\n",
        "  # # drop2=np.array(range(df_supervised0.shape[1]))\n",
        "  # # print(drop2)\n",
        "  # ########  QUAN TRONG\n",
        "  # ''' bo het cac bien cua NDI trong phan input (drop1)\n",
        "\n",
        "  # input cua PRS gom 2 phan:\n",
        "  # phan 1: gia tri thuc do tu dau den buoc t-1\n",
        "  # phan 2: gia tri cua mo hinh du bao tai buoc t\n",
        "  # -> giai quyet bang cach go bo cac gia tri PRS tai t\n",
        "  # thay bang cac gia tri cua mo hinh du bao tai buoc t\n",
        "  # khong can bo thang drop 2, chi can thay no ban gia tri trong mo hinh khi hau la duoc\n",
        "\n",
        "  # '''\n",
        "\n",
        "  # # drop2a=drop2[df_supervised0.shape[1]-4:df_supervised0.shape[1]-1]\n",
        "  # # print(drop2a)\n",
        "  list_drop_cols=[]\n",
        "\n",
        "  [list_drop_cols.append(drop) for drop in drop1a]\n",
        "  # # [list_drop_cols.append(drop) for drop in drop2a]\n",
        "  # # print(list_drop_cols)\n",
        "\n",
        "  # \"\"\"## Bo di bay lu khon nan\"\"\"\n",
        "\n",
        "  df_supervised=df_supervised0_obs_cli.drop(df_supervised0_obs_cli.columns[[list_drop_cols]],axis=1)\n",
        "  # df_supervised\n",
        "\n",
        "  \"\"\"# Chia du lieu theo ti le0.6:0.2:0.2\"\"\"\n",
        "\n",
        "  # chieu dai cua train\n",
        "  n_train=int(df_supervised.shape[0]*0.6)\n",
        "  # print(n_train)\n",
        "  n_val=int(df_supervised.shape[0]*0.8)-n_train\n",
        "  n_test=df_supervised.shape[0]-n_val-n_train\n",
        "  # print(n_val)\n",
        "  # print(n_test)\n",
        "\n",
        "  # df train, val, test\n",
        "  train_df=df_supervised.iloc[0:n_train,:]\n",
        "  val_df=df_supervised.iloc[n_train:n_train+n_val,:]\n",
        "  test_df=df_supervised.iloc[n_train+n_val:,:]\n",
        "  # print(train_df.shape,val_df.shape,test_df.shape)\n",
        "  # 342 doan dau vao, moi doan la 16 dactinh\n",
        "  # bao gom 3 bien x5 buoc + bien dau ra -> 16 bien\n",
        "  # moi an doc 1 buoc \n",
        "  # bo vao 15 gia tri x so batsize de du bao gia tri 16\n",
        "\n",
        "  \"\"\"## Phan ra du lieu de train va target \"\"\"\n",
        "\n",
        "  x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "  y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "  # print(x_train.shape,y_train.shape)\n",
        "\n",
        "  x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "  y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "  # print(x_val.shape,y_val.shape)\n",
        "\n",
        "  x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "  y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "  # print(x_test.shape,y_test.shape)\n",
        "\n",
        "  ## check input_train\n",
        "  # print('input',x_train[0], 'output',y_train[0])\n",
        "  # print('df_train',train_df.iloc[0,:])\n",
        "  # gia tri output va gia tri du bao phai giong nhau\n",
        "\n",
        "  \"\"\"# Scale Max-Min data\"\"\"\n",
        "\n",
        "  # tao 2 scaler rieng cho X, Y de invert cho de\n",
        "  scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "  scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "  x_train_scale = scaler_x.fit_transform(x_train)\n",
        "  y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "  # fit scale cua train cho val va test\n",
        "  x_val_scale=scaler_x.transform(x_val)\n",
        "  y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "  x_test_scale=scaler_x.transform(x_test)\n",
        "  y_test_scale=scaler_y.transform(y_test)\n",
        "\n",
        "  \"\"\"# Tensorflow format\"\"\"\n",
        "\n",
        "  # # reshape input to be 3D [samples, timesteps, features]\n",
        "  # n_features=1\n",
        "  # train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "  # val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "  # test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "\n",
        "  # Kiem tra lai\n",
        "  n_features=1\n",
        "  train_X = x_train_scale.reshape((x_train_scale.shape[0], n_features,x_train_scale.shape[1]))\n",
        "  val_X = x_val_scale.reshape((x_val_scale.shape[0],  n_features,x_val_scale.shape[1]))\n",
        "  test_X = x_test_scale.reshape((x_test_scale.shape[0], n_features, x_test_scale.shape[1]))\n",
        "  print(['input shape output shape'])\n",
        "  print(train_X.shape,y_train_scale.shape)\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "  return train_X, y_train_scale, val_X,y_val_scale,test_X,y_test_scale,scaler_y,n_train,n_val\n",
        "#######################################################################################\n",
        "def generate_input_M3(dataset,dataset_climate,k0,n_in0,n_out0):\n",
        "  # n_window0=5\n",
        "  dataset0=dataset[k0]\n",
        "  dataset0_climate=dataset_climate[k0]\n",
        "  df_supervised0=series_to_supervised_df(dataset0,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  df_supervised0_climate=series_to_supervised_df(dataset0_climate,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  # thay doi cac gia tri cho mo hinh khi hau\n",
        "  df_supervised0.iloc[:,[-2,-3,-4,-6,-7,-8,-10,-11,-12]]=df_supervised0_climate.iloc[:,[-2,-3,-4,-6,-7,-8,-10,-11,-12]]\n",
        "  df_supervised0_obs_cli=df_supervised0_climate # da co so lieu cua climate model o day\n",
        "  \"\"\"## loai bo cac gia tri cua NDI theo thang CH* Han\"\"\"\n",
        "  # Bo het NDI\n",
        "  drop1=np.array(range(3,df_supervised0_obs_cli.shape[1],4)) # toan bo gia tri NDI trong input\n",
        "  # print(drop1)\n",
        "\n",
        "  drop1a=drop1[:-1] # chua lai thang cuoi la thang du bao\n",
        "  # print(drop1a) \n",
        "  # # van giu lai dam lau la luc lac tai buoc t. Khong bo gi het\n",
        "  # # drop2=np.array(range(df_supervised0.shape[1]))\n",
        "  # # print(drop2)\n",
        "  # ########  QUAN TRONG\n",
        "  # ''' bo het cac bien cua NDI trong phan input (drop1)\n",
        "\n",
        "  # input cua PRS gom 2 phan:\n",
        "  # phan 1: gia tri thuc do tu dau den buoc t-1\n",
        "  # phan 2: gia tri cua mo hinh du bao tai buoc t\n",
        "  # -> giai quyet bang cach go bo cac gia tri PRS tai t\n",
        "  # thay bang cac gia tri cua mo hinh du bao tai buoc t\n",
        "  # khong can bo thang drop 2, chi can thay no ban gia tri trong mo hinh khi hau la duoc\n",
        "\n",
        "  # '''\n",
        "\n",
        "  # # drop2a=drop2[df_supervised0.shape[1]-4:df_supervised0.shape[1]-1]\n",
        "  # # print(drop2a)\n",
        "  list_drop_cols=[]\n",
        "\n",
        "  [list_drop_cols.append(drop) for drop in drop1a]\n",
        "  # # [list_drop_cols.append(drop) for drop in drop2a]\n",
        "  # # print(list_drop_cols)\n",
        "\n",
        "  # \"\"\"## Bo di bay lu khon nan\"\"\"\n",
        "\n",
        "  df_supervised=df_supervised0_obs_cli.drop(df_supervised0_obs_cli.columns[[list_drop_cols]],axis=1)\n",
        "  # df_supervised\n",
        "\n",
        "  \"\"\"# Chia du lieu theo ti le0.6:0.2:0.2\"\"\"\n",
        "\n",
        "  # chieu dai cua train\n",
        "  n_train=int(df_supervised.shape[0]*0.6)\n",
        "  # print(n_train)\n",
        "  n_val=int(df_supervised.shape[0]*0.8)-n_train\n",
        "  n_test=df_supervised.shape[0]-n_val-n_train\n",
        "  # print(n_val)\n",
        "  # print(n_test)\n",
        "\n",
        "  # df train, val, test\n",
        "  train_df=df_supervised.iloc[0:n_train,:]\n",
        "  val_df=df_supervised.iloc[n_train:n_train+n_val,:]\n",
        "  test_df=df_supervised.iloc[n_train+n_val:,:]\n",
        "  # print(train_df.shape,val_df.shape,test_df.shape)\n",
        "  # 342 doan dau vao, moi doan la 16 dactinh\n",
        "  # bao gom 3 bien x5 buoc + bien dau ra -> 16 bien\n",
        "  # moi an doc 1 buoc \n",
        "  # bo vao 15 gia tri x so batsize de du bao gia tri 16\n",
        "\n",
        "  \"\"\"## Phan ra du lieu de train va target \"\"\"\n",
        "\n",
        "  x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "  y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "  # print(x_train.shape,y_train.shape)\n",
        "\n",
        "  x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "  y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "  # print(x_val.shape,y_val.shape)\n",
        "\n",
        "  x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "  y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "  # print(x_test.shape,y_test.shape)\n",
        "\n",
        "  ## check input_train\n",
        "  # print('input',x_train[0], 'output',y_train[0])\n",
        "  # print('df_train',train_df.iloc[0,:])\n",
        "  # gia tri output va gia tri du bao phai giong nhau\n",
        "\n",
        "  \"\"\"# Scale Max-Min data\"\"\"\n",
        "\n",
        "  # tao 2 scaler rieng cho X, Y de invert cho de\n",
        "  scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "  scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "  x_train_scale = scaler_x.fit_transform(x_train)\n",
        "  y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "  # fit scale cua train cho val va test\n",
        "  x_val_scale=scaler_x.transform(x_val)\n",
        "  y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "  x_test_scale=scaler_x.transform(x_test)\n",
        "  y_test_scale=scaler_y.transform(y_test)\n",
        "\n",
        "  \"\"\"# Tensorflow format\"\"\"\n",
        "\n",
        "  # # reshape input to be 3D [samples, timesteps, features]\n",
        "  # n_features=1\n",
        "  # train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "  # val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "  # test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "\n",
        "  # Kiem tra lai\n",
        "  n_features=1\n",
        "  train_X = x_train_scale.reshape((x_train_scale.shape[0], n_features,x_train_scale.shape[1]))\n",
        "  val_X = x_val_scale.reshape((x_val_scale.shape[0],  n_features,x_val_scale.shape[1]))\n",
        "  test_X = x_test_scale.reshape((x_test_scale.shape[0], n_features, x_test_scale.shape[1]))\n",
        "  print(['input shape output shape'])\n",
        "  print(train_X.shape,y_train_scale.shape)\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "  return train_X, y_train_scale, val_X,y_val_scale,test_X,y_test_scale,scaler_y,n_train,n_val\n",
        "\n",
        "#######################################################################################\n",
        "\n",
        "# RUN THEORY\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\"\"\"# 0. Change directory\"\"\"\n",
        "\n",
        "# import os\n",
        "# os.chdir('/content/drive/MyDrive/hybrid_batch')\n",
        "# # create the outputs:\n",
        "# outs=['save_models_S4M1','save_pickles_S4M1','tabs_S4M1','figs_S4M1','shps_S4M1','my_dir_S4M1'] \n",
        "# # my_dir la thu muc chua keras tunner\n",
        "# for out in outs:\n",
        "#   if not os.path.exists(out):\n",
        "#     os.makedirs(out)\n",
        "\n",
        "# k0=29\n",
        "# phase=2\n",
        "# #####\n",
        "# ## mo kiem tra lai\n",
        "# with open(outs[1]+'/'+str(k0)+'M1S4_lag5.pkl', 'rb') as f:\n",
        "#     # compressed_file = bz2.BZ2File(f, 'r')\n",
        "#     load_list_con = pickle.load(f)\n",
        "# # 0,1,2 tuong ung voi train, val, test\n",
        "# pearson,dotincay=pearsonr(load_list_con[phase]['obs'],load_list_con[phase]['pred'])\n",
        "# print('cc of test of station'+str(k0+1)+' : '+str(pearson))\n",
        "def run_theory(datatest,thrs,start0):\n",
        "  # thrs=-2.0\n",
        "  # obs_values=load_list_con[phase]['obs']\n",
        "  obs_values=datatest\n",
        "  # obs_values=load_list_con[phase]['obs'].values\n",
        "  # sim=load_list_con[phase]['pred']\n",
        "  # print(type(obs))\n",
        "  # def run_theory(data,thrs)\n",
        "  list_rainfall_all=[]\n",
        "  n_index=np.where(obs_values<=thrs)[0]\n",
        "  n_index\n",
        "  start_point=[]\n",
        "  end_point=[]\n",
        "  n_dd=[]\n",
        "  n_ss=[]\n",
        "\n",
        "  start_point.append(n_index[0]) # gia tri dau tien luon phai them vao\n",
        "  # cac gia tri bat dau o giua duoc xac dinh khi no tru cho gia tri truoc lon hon 1\n",
        "    # noi cach khac no khong lien tuc\n",
        "\n",
        "  for i in range(len(n_index)-1):\n",
        "      if n_index[i+1]-n_index[i] >1:\n",
        "        # print(n_index[i])\n",
        "        start_point.append(n_index[i+1])\n",
        "  print(start_point)\n",
        "\n",
        "  # tim duration cho tung start point. Tinh bat dau bang start point cho den khi n_index\n",
        "    # tang len khac 1, nghia la no ko con lien tuc nua\n",
        "  for i in range(len(n_index)-1):\n",
        "    if n_index[i]-n_index[i+1] <-1:\n",
        "      # print(n_index[i])\n",
        "      end_point.append(n_index[i])\n",
        "  # luon them diem cuoi cua n_index la end_point\n",
        "  end_point.append(n_index[-1])\n",
        "  print(end_point)\n",
        "  n_dd=np.array(end_point)-np.array(start_point)+1\n",
        "  # n_dd\n",
        "  # severity la tong gia tri tu bat dau 1 den ket thuc 1\n",
        "  n_se=[]\n",
        "  for i in range(len(start_point)):\n",
        "    n_se.append(obs_values[start_point[i]:end_point[i]+1].sum())\n",
        "\n",
        "  # Duration\n",
        "  n_du=[]\n",
        "  for i in range(len(start_point)):\n",
        "    n_du.append(end_point[i]-start_point[i]+1)\n",
        "  # Intensity\n",
        "  n_intensity=[]\n",
        "  for i in range(len(start_point)):\n",
        "    n_intensity.append(n_se[i]/n_du[i])\n",
        "\n",
        "  # inteval la khoang cach tu bat dau tran han nay den bat dau tran han khac.\n",
        "    # no it hon n_begin mot gia tri\n",
        "  n_interval=[]\n",
        "  n_interval.append(0)\n",
        "  for i in range(len(start_point)-1):\n",
        "    n_interval.append(start_point[i+1]-start_point[i]+1)\n",
        "\n",
        "  # xuat ket qua ra dang csv\n",
        "  df_rainfall=pd.DataFrame(columns=['begin','end','dd','ss','intens','inter'])\n",
        "  df_rainfall['begin']=start_point\n",
        "  df_rainfall['end']=end_point\n",
        "  df_rainfall['dd']=n_du\n",
        "  df_rainfall['ss']=n_se\n",
        "  df_rainfall['intens']=n_intensity\n",
        "  df_rainfall['inter']=n_interval\n",
        "  # print('ket qua cho stat at rainfall '+ str(thrs))\n",
        "  # print(df_rainfall)\n",
        "  list_rainfall_all.append('ket qua cho stat at rainfall '+ str(thrs))\n",
        "  list_rainfall_all.append(df_rainfall)\n",
        "  list_rainfall_all[1]['begin'].values\n",
        "  # plot figure\n",
        "  vector_date_test=pd.date_range(start=start0,periods=115, \n",
        "                freq='MS').strftime(\"%Y-%m\").tolist()\n",
        "  print(vector_date_test)\n",
        "  # plt.bar(vector_date_test,obs_values)\n",
        "  len(obs_values)\n",
        "  fig,ax=plt.subplots(figsize=(6,3))\n",
        "  plt.ylim([-5.9,2.29])\n",
        "  plt.bar(vector_date_test,obs_values,fill=None,lw=1)\n",
        "  # to mau cho han vi tri han\n",
        "  # ve mua mua\n",
        "  for kk in range(len(list_rainfall_all[1]['begin'].values)):\n",
        "    ax.axvspan(xmin=list_rainfall_all[1]['begin'].values[kk], \n",
        "              xmax=list_rainfall_all[1]['end'].values[kk], \n",
        "              ymin=0, \n",
        "              ymax=1,\n",
        "              color='red',\n",
        "              alpha=0.2)\n",
        "  plt.xticks(list_rainfall_all[1]['begin'].values)\n",
        "  plt.hlines(thrs,xmin=0,xmax=len(obs_values),linestyles='--',lw=1,color='blue')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.ylabel('NDI')\n",
        "  return list_rainfall_all\n",
        "############################################################\n",
        "\n",
        "## ROC PLOT\n",
        "def roc_plot(load_list_con,phase,thrs):\n",
        "  from itertools import cycle\n",
        "  # thrs=-1.0\n",
        "  from sklearn import svm, datasets\n",
        "  from sklearn.metrics import roc_curve, auc\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.preprocessing import label_binarize\n",
        "  from sklearn.multiclass import OneVsRestClassifier\n",
        "  from scipy import interp\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  roc_df=pd.DataFrame(columns=['obs','pred','cls_obs','cls_pred'])\n",
        "  roc_df['obs']=load_list_con[phase]['obs']\n",
        "  for i in range(roc_df.shape[0]):\n",
        "    if roc_df['obs'][i]<=thrs:\n",
        "      roc_df['cls_obs'][i]=1\n",
        "    if roc_df['obs'][i]> thrs:\n",
        "      roc_df['cls_obs'][i]=0\n",
        "  roc_df['pred']=load_list_con[phase]['pred']\n",
        "  for i in range(roc_df.shape[0]):\n",
        "    if roc_df['pred'][i]<=thrs:\n",
        "      roc_df['cls_pred'][i]=1\n",
        "    if roc_df['pred'][i]> thrs:\n",
        "      roc_df['cls_pred'][i]=0\n",
        "\n",
        "  # tinh dung sai cho moi loai. O day co 2 loai thoi\n",
        "  # Compute ROC curve and ROC area for each class\n",
        "  a=roc_df['cls_obs'].to_list()\n",
        "  # print(a)\n",
        "  b=roc_df['cls_pred'].to_list()\n",
        "  # print(b)\n",
        "  tn, fp, fn, tp = confusion_matrix(a, b).ravel()\n",
        "  (tn, fp, fn, tp)\n",
        "  # fig,ax=plt.subplots(figsize=(3,3))\n",
        "  from mlxtend.plotting import plot_confusion_matrix\n",
        "  fig=plt.figure(figsize=(3, 3))\n",
        "  plot_confusion_matrix(confusion_matrix(a, b))\n",
        "  plt.xlabel('Predictions', fontsize=12)\n",
        "  plt.ylabel('Actuals', fontsize=12)\n",
        "  plt.title('Confusion Matrix', fontsize=12)\n",
        "  plt.show()\n",
        "  plt.close(fig)\n",
        "\n",
        "  ######\n",
        "  roc_values = []\n",
        "  for thresh in np.linspace(0, 1, 100):\n",
        "      # preds = get_preds(thresh, probas)\n",
        "      tn, fp, fn, tp = confusion_matrix(b,a).ravel()\n",
        "      tpr = tp/(tp+fn)\n",
        "      fpr = fp/(fp+tn)\n",
        "      roc_values.append([tpr, fpr])\n",
        "  tpr_values, fpr_values = zip(*roc_values)\n",
        "\n",
        "  # ### \n",
        "  # fig, ax = plt.subplots(figsize=(5,5))\n",
        "  # ax.plot(fpr_values, tpr_values)\n",
        "  # ax.plot(np.linspace(0, 1, 100),\n",
        "  #          np.linspace(0, 1, 100),\n",
        "  #          label='baseline',\n",
        "  #          linestyle='--')\n",
        "  # plt.title('Receiver Operating Characteristic Curve', fontsize=18)\n",
        "  # plt.ylabel('TPR', fontsize=16)\n",
        "  # plt.xlabel('FPR', fontsize=16)\n",
        "  # plt.legend(fontsize=12);\n",
        "  # plt.close(fig)\n",
        "\n",
        "  ######\n",
        "  from sklearn import metrics\n",
        "  y_test=b\n",
        "  y_pred=a\n",
        "  auc = metrics.roc_auc_score(y_test, y_pred)\n",
        "  roc = metrics.recall_score(y_test, y_pred)\n",
        "  accuracy=metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "  false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n",
        "\n",
        "  # # plt.figure(figsize=(3, 3), dpi=80)\n",
        "  # fig,ax=plt.subplots(figsize=(3,3))\n",
        "  plt.figure(figsize=(6, 3))\n",
        "  plt.axis('scaled')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  # plt.title(\"AUC & ROC Curve of spatial extreme drought prediction\")\n",
        "  plt.plot(false_positive_rate, true_positive_rate, 'k')\n",
        "  plt.text(0.95, 0.05, 'AUC = %0.2f' % auc, ha='right', fontsize=12, weight='bold', color='black')\n",
        "  plt.text(0.95, 0.2, 'accuracy = %0.2f' % accuracy, ha='right', fontsize=12, weight='bold', color='black')\n",
        "\n",
        "  plt.fill_between(false_positive_rate, true_positive_rate, facecolor='lightgrey', alpha=0.5)\n",
        "\n",
        "  plt.plot(np.linspace(0, 1, 100),\n",
        "          np.linspace(0, 1, 100),\n",
        "          #  label='baseline',\n",
        "          linestyle='--')\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.legend(fontsize=12);\n",
        "  # plt.show()\n",
        "  plt.tight_layout()\n",
        "  # plt.savefig('out_fig/ROC.png')\n",
        "  plt.close(fig)\n",
        "\n",
        "# \"\"\"# Kiem tra cac functions\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "# # load data obs\n",
        "# with open('input_pickles'+'/'+'PRS3_NDI3_59.pkl', 'rb') as f:\n",
        "#     # compressed_file = bz2.BZ2File(f, 'r')\n",
        "#     load_PRS3_NDI3_59 = pickle.load(f)\n",
        "\n",
        "# with open('input_pickles'+'/'+'PRS3_NDI3_59_pseudo.pkl', 'rb') as f_c:\n",
        "#     # compressed_file = bz2.BZ2File(f, 'r')\n",
        "#     load_PRS3_NDI3_59_cli = pickle.load(f_c)\n",
        "\n",
        "\n",
        "\n",
        "# # check ganghwa 29\n",
        "# # for k0 in range(59):\n",
        "# k0=29 # Mo phong cho tram ganghwa\n",
        "# dataset=load_PRS3_NDI3_59\n",
        "# dataset_climate=load_PRS3_NDI3_59_cli\n",
        "\n",
        "# n_in0, n_out0=5,2\n",
        "# dataset0=dataset[k0]\n",
        "# dataset0_climate=dataset_climate[k0]\n",
        "# df_supervised0=series_to_supervised_df(dataset0,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "# df_supervised0_climate=series_to_supervised_df(dataset0_climate,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "# # thay doi cac gia tri cho mo hinh khi hau\n",
        "# df_supervised0.iloc[:,[-2,-3,-4,-6,-7,-8]]=df_supervised0_climate.iloc[:,[-2,-3,-4,-6,-7,-8]]\n",
        "# df_supervised0_obs_cli=df_supervised0_climate # da co so lieu cua climate model o day\n",
        "# \"\"\"## loai bo cac gia tri cua NDI theo thang CH* Han\"\"\"\n",
        "# # Bo het NDI\n",
        "# drop1=np.array(range(3,df_supervised0_obs_cli.shape[1],4)) # toan bo gia tri NDI trong input\n",
        "# # print(drop1)\n",
        "\n",
        "# drop1a=drop1[:-1] # chua lai thang cuoi la thang du bao\n",
        "# # print(drop1a) \n",
        "# # # van giu lai dam lau la luc lac tai buoc t. Khong bo gi het\n",
        "# # # drop2=np.array(range(df_supervised0.shape[1]))\n",
        "# # # print(drop2)\n",
        "# # ########  QUAN TRONG\n",
        "# # ''' bo het cac bien cua NDI trong phan input (drop1)\n",
        "\n",
        "# # input cua PRS gom 2 phan:\n",
        "# # phan 1: gia tri thuc do tu dau den buoc t-1\n",
        "# # phan 2: gia tri cua mo hinh du bao tai buoc t\n",
        "# # -> giai quyet bang cach go bo cac gia tri PRS tai t\n",
        "# # thay bang cac gia tri cua mo hinh du bao tai buoc t\n",
        "# # khong can bo thang drop 2, chi can thay no ban gia tri trong mo hinh khi hau la duoc\n",
        "\n",
        "# # '''\n",
        "\n",
        "# # # drop2a=drop2[df_supervised0.shape[1]-4:df_supervised0.shape[1]-1]\n",
        "# # # print(drop2a)\n",
        "# list_drop_cols=[]\n",
        "\n",
        "# [list_drop_cols.append(drop) for drop in drop1a]\n",
        "# # # [list_drop_cols.append(drop) for drop in drop2a]\n",
        "# # # print(list_drop_cols)\n",
        "\n",
        "# # \"\"\"## Bo di bay lu khon nan\"\"\"\n",
        "\n",
        "# df_supervised=df_supervised0_obs_cli.drop(df_supervised0_obs_cli.columns[[list_drop_cols]],axis=1)\n",
        "# # df_supervised\n",
        "\n",
        "# \"\"\"# Chia du lieu theo ti le0.6:0.2:0.2\"\"\"\n",
        "\n",
        "# # chieu dai cua train\n",
        "# n_train=int(df_supervised.shape[0]*0.6)\n",
        "# # print(n_train)\n",
        "# n_val=int(df_supervised.shape[0]*0.8)-n_train\n",
        "# n_test=df_supervised.shape[0]-n_val-n_train\n",
        "# # print(n_val)\n",
        "# # print(n_test)\n",
        "\n",
        "# # df train, val, test\n",
        "# train_df=df_supervised.iloc[0:n_train,:]\n",
        "# val_df=df_supervised.iloc[n_train:n_train+n_val,:]\n",
        "# test_df=df_supervised.iloc[n_train+n_val:,:]\n",
        "# # print(train_df.shape,val_df.shape,test_df.shape)\n",
        "# # 342 doan dau vao, moi doan la 16 dactinh\n",
        "# # bao gom 3 bien x5 buoc + bien dau ra -> 16 bien\n",
        "# # moi an doc 1 buoc \n",
        "# # bo vao 15 gia tri x so batsize de du bao gia tri 16\n",
        "\n",
        "# \"\"\"## Phan ra du lieu de train va target \"\"\"\n",
        "\n",
        "# x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "# y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "# # print(x_train.shape,y_train.shape)\n",
        "\n",
        "# x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "# y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "# # print(x_val.shape,y_val.shape)\n",
        "\n",
        "# x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "# y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "# # print(x_test.shape,y_test.shape)\n",
        "\n",
        "# ## check input_train\n",
        "# # print('input',x_train[0], 'output',y_train[0])\n",
        "# # print('df_train',train_df.iloc[0,:])\n",
        "# # gia tri output va gia tri du bao phai giong nhau\n",
        "\n",
        "# \"\"\"# Scale Max-Min data\"\"\"\n",
        "\n",
        "# # tao 2 scaler rieng cho X, Y de invert cho de\n",
        "# scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "# scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "# x_train_scale = scaler_x.fit_transform(x_train)\n",
        "# y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "# # fit scale cua train cho val va test\n",
        "# x_val_scale=scaler_x.transform(x_val)\n",
        "# y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "# x_test_scale=scaler_x.transform(x_test)\n",
        "# y_test_scale=scaler_y.transform(y_test)\n",
        "\n",
        "# \"\"\"# Tensorflow format\"\"\"\n",
        "\n",
        "# # # reshape input to be 3D [samples, timesteps, features]\n",
        "# # n_features=1\n",
        "# # train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "# # val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "# # test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "# # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "\n",
        "# # Kiem tra lai\n",
        "# n_features=1\n",
        "# train_X = x_train_scale.reshape((x_train_scale.shape[0], n_features,x_train_scale.shape[1]))\n",
        "# val_X = x_val_scale.reshape((x_val_scale.shape[0],  n_features,x_val_scale.shape[1]))\n",
        "# test_X = x_test_scale.reshape((x_test_scale.shape[0], n_features, x_test_scale.shape[1]))\n",
        "# print(['input shape output shape'])\n",
        "# print(train_X.shape,y_train_scale.shape)\n",
        "\n",
        "# run_theory(load_list_con[phase]['obs'].values,-1)\n",
        "# =============================================================================\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRBWN8dtpcF9",
        "outputId": "5fb71c0b-b0cc-49c4-fbdf-5acc78acd227"
      },
      "source": [
        "\n",
        "# Load du lieu\n",
        "# load data obs\n",
        "with open('input_pickles'+'/'+'PRS3_NDI3_59new.pkl', 'rb') as f1:\n",
        "    # compressed_file = bz2.BZ2File(f, 'r')\n",
        "    PRS3_NDI3_59 = pickle.load(f1)\n",
        "    \n",
        "# kiem tra cho ganghwa\n",
        "k=29\n",
        "n_in0=3\n",
        "n_out0=1\n",
        "m=n_out0 # tinh cho buoc 0\n",
        "df0=PRS3_NDI3_59[k] # 1968-2020\n",
        "# chia du lieu cho 12 lay 6 phan cho train, 3 phan cho val, 3 phan cho test\n",
        "df1=df0.iloc[:(2016-1968+1)*12,:]\n",
        "# df1=df0 # du bao het\n",
        "# =============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "# Chuyen qua suppervised. Chon n_out0=3, n_in0=1 da kiem tra do khong mat so cuoi\n",
        "# no chi mat so dau\n",
        "# def sample_generate_M3(dataset,n_in0,n_out0):\n",
        "df2=series_to_supervised_df(df1,n_in0,n_out0)\n",
        "\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "#     remove values PRS  at fure prediction\n",
        "# var3(t),var2(t),var1(t) have to remove\n",
        "list_drops=[np.arange(2,5)*-1,np.arange(2,9)*-1,np.arange(2,13)*-1]\n",
        "list_drops1=[[],[],[]]\n",
        "list_drops1a=[[-5,-9,-13],[-5,-9,-13,-17],[-5,-9,-13,-17,-21]]\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "df3=df2.drop(df2.columns[[list_drops1[n_out0-1]]],axis=1)\n",
        "df4=df3.drop(df3.columns[[list_drops1a[n_out0-1]]],axis=1)\n",
        "\n",
        "# =============================================================================\n",
        "# Chia du lieu theo ti le 6:3:3\n",
        "n_train=int(df4.shape[0]*0.6)\n",
        "n_val=int(df4.shape[0]*0.8)-n_train\n",
        "n_test=df4.shape[0]-n_val-n_train\n",
        "\n",
        "train_df=df4.iloc[0:n_train,:]\n",
        "val_df=df4.iloc[n_train:n_train+n_val,:]\n",
        "test_df=df4.iloc[n_train+n_val:,:]\n",
        "# print(train_df.shape,val_df.shape,test_df.shape)\n",
        "x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "# lay chinh no du bao no luon\n",
        "# x_train,y_train0=train_df.iloc[:,:].values,train_df.iloc[:,-1].values # KIEM TRA DU BAO CHO CHINH NO\n",
        "y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "# print(x_train.shape,y_train.shape)\n",
        "\n",
        "x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "# x_val,y_val0=val_df.iloc[:,:].values,val_df.iloc[:,-1].values #  KIEM TRA DU BAO CHO CHINH NO\n",
        "y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "# print(x_val.shape,y_val.shape)\n",
        "\n",
        "x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "\n",
        "# x_test,y_test0=test_df.iloc[:,:].values,test_df.iloc[:,-1].values # KIEM TRA DU BAO CHO CHINH NO\n",
        "y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "# print(x_test.shape,y_test.shape)\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Scale data\n",
        "# tao 2 scaler rieng cho X, Y de invert cho de\n",
        "scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "x_train_scale = scaler_x.fit_transform(x_train)\n",
        "y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "# fit scale cua train cho val va test\n",
        "x_val_scale=scaler_x.transform(x_val)\n",
        "y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "x_test_scale=scaler_x.transform(x_test)\n",
        "y_test_scale=scaler_y.transform(y_test)\n",
        "n_features=1\n",
        "train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "\n",
        "    \n",
        "    # return train_X, y_train_scale, val_X,y_val_scale,test_X,y_test_scale,scaler_y,n_train,n_val\n",
        "\n",
        "# Chuyen qua dinh danh cua 3D tensorflow: sample, timesteps, feature\n",
        "# Kiem tra lai trong sach \n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py:4114: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jex8ePoffXs4"
      },
      "source": [
        "# Define model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bnd2QZq0fd85",
        "outputId": "1c508a92-3157-4720-bb9f-d122fd6d8024"
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "# =============================================================================\n",
        "opt = Adam(learning_rate = 0.00095, clipnorm = 1.0)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "callbacks_list = [\n",
        "keras.callbacks.EarlyStopping(\n",
        "monitor=\"val_loss\",\n",
        "patience=300,\n",
        "mode=\"min\",\n",
        "),\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=outs[0]+\"/\"+str(k)+\"lead\"+str(m)+\"best_stop.keras\", # cong them buoc thoi gian\n",
        "monitor=\"val_loss\",\n",
        "save_best_only=True,\n",
        ")\n",
        "]\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate = 0.001, clipnorm = 1.0),\n",
        "loss=\"mse\",\n",
        "metrics=[\"mse\"])\n",
        "# Fit model\n",
        "\n",
        "history1=model.fit(train_X,\n",
        "          y_train_scale,\n",
        "epochs=1500,\n",
        "callbacks=callbacks_list,\n",
        "validation_data=(val_X,y_val_scale))\n",
        "# =============================================================================\n",
        "# # Save loss values\n",
        "# with open(outs[1]+'/'+str(k)+'lead'+str(m)+'T3_lag3loss.csv', 'wb') as f1: # khong nen\n",
        "#   # compressed_file = bz2.BZ2File(f, 'w')\n",
        "#     w = csv.DictWriter(f1, history1.history.keys())\n",
        "#     w.writeheader()\n",
        "#     w.writerow(history1)\n",
        "\n",
        "# # #####\n",
        "# ## mo kiem tra lai\n",
        "# with open(outs[1]+'/'+str(k)+'lead'+str(m)+'T3_lag3loss.csv', 'rb') as f2: # khong nen\n",
        "#     # compressed_file = bz2.BZ2File(f, 'r')\n",
        "#     load_history1 = csv.DictReader(f2)\n",
        "# # 0,1,2 tuong ung voi train, val, test\n",
        "# # pearson,dotincay=pearsonr(load_list_con[1]['obs'],load_list_con[1]['pred'])\n",
        "# # print('cc of val: '+str(pearson))\n",
        "# =============================================================================\n",
        "# LOAD KET QUA TOT NHAT\n",
        "# =============================================================================\n",
        "# Load results\n",
        "loaded_model=load_model(outs[0]+\"/\"+str(k)+\"lead\"+str(m)+\"best_stop.keras\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# =============================================================================\n",
        "# DANH GIA\n",
        "# =============================================================================\n",
        "# TONG KET \n",
        "# ve learning rate to load model\n",
        "#Check the Loss curve\n",
        "fig,ax=plt.subplots(figsize=(6,3))\n",
        "plt.rcParams.update({'font.size': 11})\n",
        "plt.plot(history1.history['loss'])\n",
        "plt.plot(history1.history['val_loss'])\n",
        "# Draw the minimum epochs \n",
        "df_val_loss=pd.DataFrame({'val_loss':history1.history['val_loss']})\n",
        "# print(df_val_loss)\n",
        "idxmin=df_val_loss[['val_loss']].idxmin().values\n",
        "val_loss_min_values=df_val_loss.loc[idxmin,:].values.flatten()\n",
        "print(idxmin,val_loss_min_values)\n",
        "plt.annotate('epochs at min_val_loss: '+str(idxmin[0]+1)+'\\n'+'min_val_loss: '+str(np.round(val_loss_min_values[0],3)),\n",
        "             xy=(idxmin,val_loss_min_values), xycoords='data',\n",
        "            xytext=(idxmin-50, val_loss_min_values+0.02), textcoords='data',\n",
        "            arrowprops=dict(arrowstyle=\"->\",\n",
        "                            connectionstyle=\"arc3\"),\n",
        "            )\n",
        "\n",
        "plt.legend(['train','val'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('mse')\n",
        "# plt.title('learning rate of 1 month leadtime prdiction')\n",
        "plt.tight_layout()\n",
        "plt.savefig(outs[3]+'/'+str(k)+'loss_curve_T3'+str(m)+'.jpeg',dpi=300)\n",
        "plt.show(fig)\n",
        "plt.close(fig)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "11/11 [==============================] - 2s 38ms/step - loss: 0.2345 - mse: 0.2345 - val_loss: 0.2314 - val_mse: 0.2314\n",
            "Epoch 2/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1716 - mse: 0.1716 - val_loss: 0.1571 - val_mse: 0.1571\n",
            "Epoch 3/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.1021 - mse: 0.1021 - val_loss: 0.0706 - val_mse: 0.0706\n",
            "Epoch 4/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0464 - val_mse: 0.0464\n",
            "Epoch 5/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0382 - val_mse: 0.0382\n",
            "Epoch 6/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0363 - mse: 0.0363 - val_loss: 0.0382 - val_mse: 0.0382\n",
            "Epoch 7/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.0365 - val_mse: 0.0365\n",
            "Epoch 8/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0361 - val_mse: 0.0361\n",
            "Epoch 9/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0358 - val_mse: 0.0358\n",
            "Epoch 10/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0348 - val_mse: 0.0348\n",
            "Epoch 11/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0344 - val_mse: 0.0344\n",
            "Epoch 12/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0341 - mse: 0.0341 - val_loss: 0.0344 - val_mse: 0.0344\n",
            "Epoch 13/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 14/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 15/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0327 - val_mse: 0.0327\n",
            "Epoch 16/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0325 - val_mse: 0.0325\n",
            "Epoch 17/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 18/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 19/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0314 - val_mse: 0.0314\n",
            "Epoch 20/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0307 - val_mse: 0.0307\n",
            "Epoch 21/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 22/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0300 - val_mse: 0.0300\n",
            "Epoch 23/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0296 - val_mse: 0.0296\n",
            "Epoch 24/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.0288 - val_mse: 0.0288\n",
            "Epoch 25/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0287 - val_mse: 0.0287\n",
            "Epoch 26/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0277 - val_mse: 0.0277\n",
            "Epoch 27/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0272 - val_mse: 0.0272\n",
            "Epoch 28/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0265 - val_mse: 0.0265\n",
            "Epoch 29/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0269 - val_mse: 0.0269\n",
            "Epoch 30/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0299 - mse: 0.0299 - val_loss: 0.0247 - val_mse: 0.0247\n",
            "Epoch 31/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0294 - mse: 0.0294 - val_loss: 0.0242 - val_mse: 0.0242\n",
            "Epoch 32/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.0234 - val_mse: 0.0234\n",
            "Epoch 33/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0241 - val_mse: 0.0241\n",
            "Epoch 34/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0284 - mse: 0.0284 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 35/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0209 - val_mse: 0.0209\n",
            "Epoch 36/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 37/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0217 - val_mse: 0.0217\n",
            "Epoch 38/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0188 - val_mse: 0.0188\n",
            "Epoch 39/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 40/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 41/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0188 - val_mse: 0.0188\n",
            "Epoch 42/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 43/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 44/1500\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 45/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 46/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 47/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 48/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 49/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 50/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 51/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 52/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 53/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 54/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 55/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 56/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 57/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 58/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 59/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 60/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 61/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 62/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.0167 - val_mse: 0.0167\n",
            "Epoch 63/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 64/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 65/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 66/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 67/1500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 68/1500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 69/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 70/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 71/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 72/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 73/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 74/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 75/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 76/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 77/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 78/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 79/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 80/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 81/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0179 - val_mse: 0.0179\n",
            "Epoch 82/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0177 - val_mse: 0.0177\n",
            "Epoch 83/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 84/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 85/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 86/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 87/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 88/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 89/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 90/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0179 - val_mse: 0.0179\n",
            "Epoch 91/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 92/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0166 - val_mse: 0.0166\n",
            "Epoch 93/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 94/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 95/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 96/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 97/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0202 - val_mse: 0.0202\n",
            "Epoch 98/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 99/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 100/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 101/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 102/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 103/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 104/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 105/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 106/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 107/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 108/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 109/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 110/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 111/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 112/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 113/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0174 - val_mse: 0.0174\n",
            "Epoch 114/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 115/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 116/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 117/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 118/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 119/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 120/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 121/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 122/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 123/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 124/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 125/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 126/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 127/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 128/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 129/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 130/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 131/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 132/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 133/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 134/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0187 - val_mse: 0.0187\n",
            "Epoch 135/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 136/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 137/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 138/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 139/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 140/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0160 - val_mse: 0.0160\n",
            "Epoch 141/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 142/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 143/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 144/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 145/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 146/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 147/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 148/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 149/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 150/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 151/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 152/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 153/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 154/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 155/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 156/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 157/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 158/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 159/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 160/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 161/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 162/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 163/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 164/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 165/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 166/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 167/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 168/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 169/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 170/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 171/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 172/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 173/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 174/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 175/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 176/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 177/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 178/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 179/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 180/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 181/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 182/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 183/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 184/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 185/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 186/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 187/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 188/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 189/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 190/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 191/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 192/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 193/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0164 - val_mse: 0.0164\n",
            "Epoch 194/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 195/1500\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 196/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 197/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 198/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 199/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 200/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 201/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 202/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 203/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 204/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 205/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 206/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 207/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 208/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 209/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 210/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 211/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 212/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 213/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 214/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 215/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 216/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 217/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 218/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 219/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 220/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 221/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 222/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 223/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 224/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 225/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 226/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 227/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 228/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 229/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 230/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 231/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 232/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 233/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 234/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 235/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 236/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 237/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 238/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 239/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 240/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 241/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 242/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 243/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 244/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 245/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 246/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 247/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 248/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 249/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 250/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 251/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 252/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 253/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 254/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 255/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 256/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 257/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 258/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 259/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 260/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0173 - val_mse: 0.0173\n",
            "Epoch 261/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 262/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 263/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 264/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 265/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 266/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 267/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 268/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 269/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 270/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 271/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 272/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 273/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 274/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 275/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 276/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 277/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 278/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 279/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 280/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 281/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 282/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 283/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 284/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 285/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 286/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 287/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 288/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 289/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 290/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 291/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 292/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 293/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 294/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 295/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 296/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 297/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 298/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 299/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 300/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 301/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 302/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 303/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 304/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 305/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 306/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 307/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 308/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 309/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 310/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 311/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 312/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 313/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 314/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 315/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 316/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 317/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 318/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 319/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 320/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 321/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 322/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 323/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0172 - val_mse: 0.0172\n",
            "Epoch 324/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 325/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 326/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 327/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 328/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 329/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 330/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 331/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 332/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 333/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 334/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 335/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 336/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 337/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 338/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 339/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 340/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 341/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 342/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 343/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 344/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 345/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 346/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 347/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 348/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 349/1500\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 350/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 351/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 352/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 353/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 354/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 355/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 356/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 357/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 358/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 359/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 360/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 361/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 362/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 363/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 364/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 365/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 366/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 367/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 368/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 369/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 370/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 371/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 372/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 373/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 374/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 375/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 376/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 377/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 378/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 379/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 380/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 381/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 382/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 383/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 384/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 385/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 386/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 387/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 388/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 389/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 390/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 391/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 392/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 393/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 394/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 395/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 396/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 397/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 398/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 399/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 400/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 401/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 402/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 403/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 404/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 405/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 406/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 407/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 408/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 409/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 410/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 411/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 412/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 413/1500\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 414/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 415/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 416/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 417/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 418/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 419/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 420/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 421/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 422/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 423/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 424/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 425/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 426/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 427/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 428/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 429/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 430/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 431/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 432/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 433/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 434/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 435/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 436/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 437/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 438/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 439/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 440/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 441/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 442/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 443/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 444/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 445/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 446/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 447/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 448/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 449/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 450/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 451/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 452/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 453/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 454/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 455/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 456/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 457/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 458/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 459/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 460/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 461/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 462/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 463/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 464/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 465/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 466/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 467/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 468/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 469/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 470/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 471/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 472/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 473/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 474/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 475/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 476/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 477/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 478/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 479/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 480/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 481/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 482/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 483/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 484/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 485/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 486/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 487/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 488/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 489/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 490/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 491/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 492/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 493/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 494/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 495/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 496/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 497/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 498/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 499/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 500/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 501/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 502/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 503/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 504/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 505/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 506/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 507/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 508/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 509/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 510/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 511/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 512/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 513/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 514/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 515/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 516/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 517/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 518/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 519/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 520/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 521/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 522/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 523/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 524/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 525/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 526/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 527/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 528/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 529/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 530/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 531/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 532/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 533/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 534/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 535/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 536/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 537/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 538/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 539/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 540/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 541/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 542/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 543/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 544/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 545/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 546/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 547/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 548/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 549/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 550/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 551/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 552/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 553/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 554/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 555/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 556/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 557/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 558/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 559/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 560/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 561/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 562/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 563/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 564/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 565/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 566/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 567/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 568/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 569/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 570/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 571/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 572/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 573/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 574/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 575/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 576/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 577/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 578/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 579/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 580/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 581/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 582/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 583/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 584/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 585/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 586/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 587/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 588/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 589/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 590/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 591/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 592/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 593/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 594/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 595/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 596/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 597/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 598/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 599/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 600/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 601/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 602/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 603/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 604/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 605/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 606/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 607/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 608/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 609/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 610/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 611/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 612/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 613/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 614/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 615/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 616/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 617/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 618/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 619/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 620/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 621/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 622/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 623/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 624/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 625/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 626/1500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 627/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 628/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 629/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 630/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 631/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 632/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 633/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 634/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 635/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 636/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 637/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 638/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 639/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 640/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 641/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 642/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 643/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 644/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 645/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 646/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 647/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 648/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 649/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 650/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 651/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 652/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 653/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 654/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 655/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 656/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 657/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 658/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 659/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 660/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 661/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 662/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 663/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 664/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 665/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 666/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 667/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 668/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 669/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 670/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 671/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 672/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 673/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 674/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 675/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 676/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 677/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 678/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 679/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 680/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 681/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 682/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 683/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 684/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 685/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 686/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 687/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 688/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 689/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 690/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 691/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 692/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 693/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 694/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 695/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 696/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 697/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 698/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 699/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 700/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 701/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 702/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 703/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 704/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 705/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 706/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 707/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 708/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 709/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 710/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 711/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 712/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 713/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 714/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 715/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 716/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 717/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 718/1500\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 719/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 720/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 721/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 722/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 723/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0070 - val_mse: 0.0070\n",
            "Epoch 724/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 725/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 726/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 727/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 728/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 729/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0074 - val_mse: 0.0074\n",
            "Epoch 730/1500\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 731/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 732/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 733/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 734/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 735/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 736/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 737/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 738/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 739/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 740/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 741/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0075 - val_mse: 0.0075\n",
            "Epoch 742/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 743/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 744/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 745/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 746/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 747/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 748/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 749/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 750/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 751/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 752/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 753/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 754/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 755/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 756/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 757/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 758/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 759/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 760/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 761/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 762/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 763/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 764/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 765/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 766/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 767/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 768/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 769/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 770/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 771/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 772/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 773/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 774/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 775/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 776/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 777/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 778/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 779/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 780/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 781/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 782/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 783/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 784/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 785/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 786/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 787/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 788/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 789/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 790/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 791/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 792/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 793/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 794/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 795/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 796/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 797/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 798/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 799/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 800/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 801/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 802/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 803/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 804/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 805/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 806/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 807/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 808/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 809/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 810/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 811/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 812/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 813/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 814/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 815/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 816/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 817/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 818/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 819/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 820/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 821/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 822/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 823/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 824/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 825/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 826/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 827/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0073 - val_mse: 0.0073\n",
            "Epoch 828/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 829/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 830/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 831/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 832/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 833/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 834/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 835/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 836/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 837/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 838/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 839/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 840/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 841/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 842/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 843/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 844/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0075 - val_mse: 0.0075\n",
            "Epoch 845/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 846/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 847/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 848/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 849/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 850/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 851/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 852/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 853/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 854/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 855/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 856/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 857/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 858/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 859/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 860/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 861/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 862/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 863/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 864/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 865/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 866/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 867/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 868/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 869/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 870/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 871/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 872/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 873/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 874/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 875/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 876/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 877/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 878/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 879/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 880/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 881/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 882/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 883/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 884/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0072 - val_mse: 0.0072\n",
            "Epoch 885/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 886/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 887/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 888/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 889/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 890/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 891/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 892/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0076 - val_mse: 0.0076\n",
            "Epoch 893/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 894/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 895/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 896/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 897/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 898/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 899/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 900/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 901/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 902/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 903/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 904/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 905/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 906/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 907/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 908/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 909/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 910/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 911/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 912/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 913/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 914/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 915/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 916/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 917/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 918/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 919/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 920/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 921/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 922/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 923/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 924/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 925/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 926/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 927/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 928/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 929/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 930/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0074 - val_mse: 0.0074\n",
            "Epoch 931/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 932/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0082 - val_mse: 0.0082\n",
            "Epoch 933/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 934/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 935/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 936/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 937/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 938/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 939/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 940/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 941/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 942/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 943/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 944/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 945/1500\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 946/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 947/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 948/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 949/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 950/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 951/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 952/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 953/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 954/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 955/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 956/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 957/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 958/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 959/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 960/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0077 - val_mse: 0.0077\n",
            "Epoch 961/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 962/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 963/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 964/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 965/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 966/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 967/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 968/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0078 - val_mse: 0.0078\n",
            "Epoch 969/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 970/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 971/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 972/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 973/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 974/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 975/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0086 - val_mse: 0.0086\n",
            "Epoch 976/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0085\n",
            "Epoch 977/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 978/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0096 - val_mse: 0.0096\n",
            "Epoch 979/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 980/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 981/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 982/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 983/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 984/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 985/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 986/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0100 - val_mse: 0.0100\n",
            "Epoch 987/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 988/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 989/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 990/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0102 - val_mse: 0.0102\n",
            "Epoch 991/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 992/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 993/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 994/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 995/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0094 - val_mse: 0.0094\n",
            "Epoch 996/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 997/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0080 - val_mse: 0.0080\n",
            "Epoch 998/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 999/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 1000/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 1001/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 1002/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 1003/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 1004/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 1005/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0084 - val_mse: 0.0084\n",
            "Epoch 1006/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0092 - val_mse: 0.0092\n",
            "Epoch 1007/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 1008/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0099 - val_mse: 0.0099\n",
            "Epoch 1009/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 1010/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0088 - val_mse: 0.0088\n",
            "Epoch 1011/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0089 - val_mse: 0.0089\n",
            "Epoch 1012/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 1013/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0083 - val_mse: 0.0083\n",
            "Epoch 1014/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0095 - val_mse: 0.0095\n",
            "Epoch 1015/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Epoch 1016/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 1017/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0079 - val_mse: 0.0079\n",
            "Epoch 1018/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 1019/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0090 - val_mse: 0.0090\n",
            "Epoch 1020/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0071 - val_mse: 0.0071\n",
            "Epoch 1021/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0093 - val_mse: 0.0093\n",
            "Epoch 1022/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0087 - val_mse: 0.0087\n",
            "Epoch 1023/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0081 - val_mse: 0.0081\n",
            "Loaded model from disk\n",
            "[722] [0.00699167]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "HC8Z4gVVejVl",
        "outputId": "e9163dc7-3e85-4fd7-d4ac-52904c2915b2"
      },
      "source": [
        "\n",
        "#----------------------Important !!!!-----------------------#\n",
        "pred = loaded_model.predict(train_X)  #(predicted)  \n",
        "obs  = y_train_scale               #(obs) \n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "#----------------------reverse scaling------------------------------#\n",
        "#For training period\n",
        "y_hat_rescaled  = scaler_y.inverse_transform(pred) #prediction value\n",
        "y_rescaled = scaler_y.inverse_transform(obs)         #observed value\n",
        "\n",
        "#Inverse scaled --> pred, obs  \n",
        "pred = y_hat_rescaled\n",
        "obs = y_rescaled\n",
        "\n",
        "# pred1, obs1: pred train, obs train\n",
        "pred1=pred\n",
        "obs1=obs\n",
        "\n",
        "##########################################################\n",
        "# Validation\n",
        "pred = loaded_model.predict(val_X)  #(pred)  \n",
        "obs  = y_val_scale                 #(obs) \n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "#----------------------reverse scaling------------------------------#\n",
        "#For training period\n",
        "y_hat_rescaled  = scaler_y.inverse_transform(pred) #prediction value\n",
        "y_rescaled = scaler_y.inverse_transform(obs)         #observed value\n",
        "\n",
        "#Inverse scaled --> pred, obs  \n",
        "pred = y_hat_rescaled\n",
        "obs = y_rescaled\n",
        "\n",
        "# pred1, obs1: pred val, obs val\n",
        "pred2=pred\n",
        "obs2=obs\n",
        "\n",
        "################################################################\n",
        "pred = loaded_model.predict(test_X)  #(pred)  \n",
        "obs  = y_test_scale                 #(obs) \n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "#----------------------reverse scaling------------------------------#\n",
        "#For training period\n",
        "y_hat_rescaled  = scaler_y.inverse_transform(pred) #prediction value\n",
        "y_rescaled = scaler_y.inverse_transform(obs)         #observed value\n",
        "\n",
        "#Inverse scaled --> pred, obs  \n",
        "pred = y_hat_rescaled\n",
        "obs = y_rescaled\n",
        "\n",
        "# pred1, obs1: pred val, obs val\n",
        "pred3=pred\n",
        "obs3=obs\n",
        "#--------------------------------------------------------------------#\n",
        "\n",
        "# TOM LAI\n",
        "list_con=list()\n",
        "df_train=pd.DataFrame({'obs':obs1.flatten(),'pred':pred1.flatten()})\n",
        "list_con.append(df_train)\n",
        "df_val=pd.DataFrame({'obs':obs2.flatten(),'pred':pred2.flatten()})\n",
        "list_con.append(df_val)\n",
        "df_test=pd.DataFrame({'obs':obs3.flatten(),'pred':pred3.flatten()})\n",
        "list_con.append(df_test)\n",
        "# =============================================================================\n",
        "# LUU LAI KET QUA\n",
        "# =============================================================================\n",
        "with open(outs[1]+'/'+str(k)+'lead'+str(m)+'T3_lag3.pkl', 'wb') as f: # khong nen\n",
        "  # compressed_file = bz2.BZ2File(f, 'w')\n",
        "  pickle.dump(list_con, f)\n",
        "\n",
        "#####\n",
        "## mo kiem tra lai\n",
        "with open(outs[1]+'/'+str(k)+'lead'+str(m)+'T3_lag3.pkl', 'rb') as f: # khong nen\n",
        "    # compressed_file = bz2.BZ2File(f, 'r')\n",
        "    load_list_con = pickle.load(f)\n",
        "# 0,1,2 tuong ung voi train, val, test\n",
        "# pearson,dotincay=pearsonr(load_list_con[1]['obs'],load_list_con[1]['pred'])\n",
        "# print('cc of val: '+str(pearson))\n",
        "# =============================================================================\n",
        "# VE HINH\n",
        "# =============================================================================\n",
        "# HINH  SCATTER\n",
        "# Ve hinh statter plot cua training, validation and testing\n",
        "\n",
        "# scale plot M1\n",
        "\n",
        "\n",
        "axes=[131,132,133]\n",
        "obs_all=[obs1,obs2,obs3]\n",
        "pred_all=[pred1,pred2,pred3]\n",
        "# lead_time=0\n",
        "names_phases=['training','validation','testing']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(9,3))\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "# lead_time=2\n",
        "  for phase in range(3):\n",
        "  # for lead_time in range(3):\n",
        "\n",
        "    plt.subplot(axes[phase])\n",
        "    pearson,dotincay=pearsonr(load_list_con[phase]['obs'],load_list_con[phase]['pred'])\n",
        "    r2_vanila_1m =pearson\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "    # fig,ax=plt.subplots(figsize=(5,5))\n",
        "    # min_values1=np.min([pred_all[m],obs_all[m]])\n",
        "    # min_values=min_values1\n",
        "    # max_values1=np.max([pred_all[m],obs_all[m]])\n",
        "    # max_values=max_values1\n",
        "    min_values=-5.9\n",
        "    max_values=2.29\n",
        "\n",
        "    plt.xlim(min_values,max_values)\n",
        "    plt.ylim(min_values,max_values)\n",
        "\n",
        "    plt.scatter(x=load_list_con[phase]['obs'],\n",
        "                y=load_list_con[phase]['pred'],\n",
        "                s=None,\n",
        "                c='k', \n",
        "                marker='.', \n",
        "                cmap=None,\n",
        "                norm=None,\n",
        "                vmin=None, \n",
        "                vmax=None,\n",
        "                alpha=None,            \n",
        "                linewidths=None,\n",
        "                edgecolors=None,plotnonfinite=False,data=None)\n",
        "\n",
        "    # ve duong 45\n",
        "    # plt.legend(['NDI'])\n",
        "    plt.xlabel('obs')\n",
        "    if lead_time==0:\n",
        "      plt.ylabel('pred')\n",
        "    # if lead_time==1:\n",
        "    # plt.title('M1S4prs_prs '+names_phases[m])\n",
        "    # add_identity(ax, color='r', ls='--')\n",
        "    plt.text(min_values,min_values,'R= '+str(round(r2_vanila_1m,2)))\n",
        "    xpoints = ypoints = plt.xlim()\n",
        "    plt.plot(xpoints, ypoints, linestyle='--', color='r', lw=1, scalex=False, scaley=False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "  plt.savefig(outs[3]+'/'+str(k)+'scatter_T3'+str(m)+'.jpeg',dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "# =============================================================================\n",
        "#VE HINH TIME SERIES\n",
        "# =============================================================================\n",
        "  \n",
        "  # Ve train\n",
        "# Time series cua train\n",
        "#Graph\n",
        "months=['1month','2months','3months']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(6,4))\n",
        "  plt.subplot(211)\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        " \n",
        "  vector_date=pd.date_range(start='1968-01',periods=df1.shape[0],freq='MS')\n",
        "  plt.plot(vector_date[0+lead_time:lead_time+int(obs1.shape[0]*0.5)],obs1[0:int(obs1.shape[0]*0.5),lead_time],'k-.')\n",
        "  plt.plot(vector_date[0+lead_time:lead_time+int(obs1.shape[0]*0.5)],pred1[0:int(obs1.shape[0]*0.5),lead_time],'r-.')\n",
        "\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train-n_out0+lead_time+1], obs1[n_in0+lead_time:n_train-n_out0+lead_time+1,lead_time], 'k-.')\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train+-n_out0+lead_time+1], pred1[:,lead_time], 'r-.')\n",
        "  \n",
        "  plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  # plt.title('Time series '+'1 month' +' lead time prediction at trainning')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.subplot(212)\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  \n",
        "  plt.plot(vector_date[lead_time+int(obs1.shape[0]*0.5):lead_time+int(obs1.shape[0]*1)],obs1[int(obs1.shape[0]*0.5):int(obs1.shape[0]*1),lead_time],'k-.')\n",
        "  plt.plot(vector_date[lead_time+int(obs1.shape[0]*0.5):lead_time+int(obs1.shape[0]*1)],pred1[int(pred1.shape[0]*0.5):int(pred1.shape[0]*1),lead_time],'r-.')\n",
        "  # plt.title('Time series '+'1 month' +' lead time prediction at trainning')\n",
        "  \n",
        "  \n",
        "  \n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)]+lead_time-n_out0+1, pred[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time],'r-.')\n",
        "  # plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  plt.tight_layout()\n",
        "\n",
        "plt.savefig(outs[3]+'/'+str(k)+'train_time_T3'+str(m)+'.jpeg',dpi=300)\n",
        "plt.show()\n",
        "plt.close()\n",
        "############ VAL\n",
        "# Time series cua val\n",
        "#Graph\n",
        "months=['1month','2months','3months']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(6,3))\n",
        "  plt.subplot(111)\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  plt.plot(vector_date[n_train+lead_time:n_train+lead_time+obs2.shape[0]],obs2[:,lead_time],'k-.')\n",
        "  plt.plot(vector_date[n_train+lead_time:n_train+lead_time+obs2.shape[0]],pred2[:,lead_time],'r-.')\n",
        "\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train-n_out0+lead_time+1], obs1[n_in0+lead_time:n_train-n_out0+lead_time+1,lead_time], 'k-.')\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train+-n_out0+lead_time+1], pred1[:,lead_time], 'r-.')\n",
        "  \n",
        "  plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  # plt.title('Time series '+'1 month' +' lead time prediction at validation')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # plt.subplot(212)\n",
        "  # plt.rcParams.update({'font.size': 12})\n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1], \n",
        "  #          obs[int(dataset0.shape[0]*0.3)+input:int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time], 'k-.')\n",
        "  \n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)]+lead_time-n_out0+1, pred[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time],'r-.')\n",
        "  # plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.savefig(outs[3]+'/'+str(k)+'val_time_T3'+str(m)+'.jpeg',dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  # Testing\n",
        "  \n",
        "#Graph\n",
        "months=['1month','2months','3months']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(6,3))\n",
        "  plt.subplot(111)\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  vector_date_test=vector_date[-24:]\n",
        "  # plt.plot(vector_date[n_train+n_val+lead_time:n_train+n_val+n_test+lead_time+obs3.shape[0]],obs3[:,lead_time],'k-.')\n",
        "  # plt.plot(vector_date[n_train+n_val+lead_time:n_train+n_val+lead_time+n_test+obs3.shape[0]],pred3[:,lead_time],'r-.')\n",
        "  plt.plot(vector_date[-n_test:],obs3[:,lead_time],'k-.')\n",
        "  plt.plot(vector_date[-n_test:],pred3[:,lead_time],'r-.')\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train-n_out0+lead_time+1], obs1[n_in0+lead_time:n_train-n_out0+lead_time+1,lead_time], 'k-.')\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train+-n_out0+lead_time+1], pred1[:,lead_time], 'r-.')\n",
        "  # plt.xticks(['2015-01','2015-06','2015-12','2016-12'])\n",
        "  plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  # plt.title('Time series '+'1month' +' lead time prediction at testing')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # plt.subplot(212)\n",
        "  # plt.rcParams.update({'font.size': 12})\n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1], \n",
        "  #          obs[int(dataset0.shape[0]*0.3)+input:int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time], 'k-.')\n",
        "  \n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)]+lead_time-n_out0+1, pred[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time],'r-.')\n",
        "  # plt.legend(['obs','simulation'])\n",
        "\n",
        "  # plt.ylabel('NDI')\n",
        "  # plt.tight_layout()\n",
        "\n",
        "  plt.savefig(outs[3]+'/'+str(k)+'test_time_T3'+str(m)+'.jpeg',dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "# =============================================================================\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAADMCAYAAAA8nNe2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeZzM9f/An5/ZG8ta7Frrvo9F5OhwK0ShUl+RklCkKL+i4ptulaiEEqVviZASSSi3HOs+Y9e9B7trb3vOvH5/fGZPs7szu7M7s3o/H495sO/ztbMzn9f7eB2aiKBQKBQKhaMxOFoAhUKhUChAKSSFQqFQOAlKISkUCoXCKVAKSaFQKBROgVJICoVCoXAKlEJSKBQKhVPg6mgB7EH16tWlfv36jhbDvkRFwaVLEBQEsbEQFga33QYuLo6WTKFQOCMxMXDhAtSpA35+jpbGIgcOHIgWkRoF1d8SCql+/foEBwc7Wgz7MmwYZGTA0aOwbh0MHAgLFsAddzhaMoVC4YyMHKkrpOHD4f33HS2NRTRNu1hYvVMd2Wma5qFp2mJN0y5qmpaoadphTdPuc7RcZY4IbNsG3buzYuVK3vvlF7385EnHyqVQKJyXb76BqlUhPNzRkhQbZ9shuQKXge7AJaA/sELTtNYicsGRgpUpoaEQHk7S7bczduxYEuPj6Ve9Oq28vPBwtGwKhcI50TRo1kw/3i+nONUOSUSSRWSGiFwQEZOIrAPOA7c7WrYyZds2ABadPUtiYiIvT5lCh5gY7vvqKxITEx0snEKhcEomT4a9e8v1DsmpFFJ+NE3zB5oCJxwtS5ly8iR4efH0Rx+xevVqZs6cyXfffcfObdt45ZVXHC2dQqFwNkRg7lz9X7VDsj+aprkBS4FvReS0hfqxmqYFa5oWHBUVVfYCliaxsUi1anhXrsygQYMAGJ6URKIIl9Q9kkKhyE9cnG4EVbMmJCRAUpKjJSoWTqmQNE0zAN8B6cAES21EZKGIdBCRDjVqFGhFWC6Ju3CBM1FRHDt2LKewTRvWNWxIUkyM4wRTKBTOydWr+r/33qtb5KakOFaeYuJsRg1omqYBiwF/oL+IZDhYpDJn6/jxrKpUic/r1MkpvPNOtt53H5kHDzpOMIVC4Zxcu6b/+8QTcM89jpWlBDidQgIWAC2Ae0SkfKr5EjJ4yBAGDxlyU/ncmTMhPt4BEikUCqcma4fk7+9YOUqIUx3ZaZpWD3gGuA2I1DQtyfwa7mDRyhR59VVYtermijvugPHjy14ghULh3GQppMqVISAAZs1yrDzFxKl2SCJyEdAcLYejufLxx5xo3px++XZJMV5eRG/ZQpXISGrWrOkg6RQKhdNx7Zruh1S7Njz4ILRs6WiJioVTKSSFTitPT57q2ZN++cpTfX3xTUkhqZxeWCoUilLi6lWoXl2PdTl/vqOlKTZOdWSngKSkJBITE6lVq9ZNdYEdO1LDaKRBbmMHhcIZSE+HNm2ynboVZUxiIsYaNXjnnXfYuX27bgZeDlEKycmIOniQn4DWyck3V9aqBSZTjkWNk7Jt2zb69evHhQsXHC2Koqw4cwaOHSvXTpnlmh9+YNH48UyfPh2P8eP1zADlEKWQnIy4kyd5CAjwuDlqXWLlygD8vmhRGUuVl1OnTnH06NEC6+Pj4wkPD6dixYokW1KsiluPE+ZgKk2a6NECFGXO/374AYB/4uP18EEmk4Mlsh2lkJyMhIt6dPYq9erdVOfRsCEASWfOlKlM+WnZsiVt27YtsH7gwIFs3ryZZs2a8eWXX5ahZAqHkaWQOndWUekdwciR7HzpJUaNGsXBq1f1qA3l0IleKSQnI/nKFQCqNW58U527OQmhFhFRliLl4caNG9n/D7NwPJOZmYnx8GH8nnySAfXrs2DBAkxOsFJLT0+nRYsWfPfdd44W5dbk5Enw8ICJE8HLy9HS/LtIT4ddu9AuXaJ3795czDDHEiiHx6dKITkZaZGRAFS2sEPCz49MwM2Bd0gHc0WK2LJly031we+8Q3K7drBhA1Pr1iUkJIRNmzaVpYgWCQkJ4fTp07zxxhsYjUZHi3PrceIE1zt3Juq118C8k7crTrCocVrc3Vk3Zw5PHDpE8+bNyVZD5TDqt1JITkaGOVCs5ut7c6WLC3MDA9lVqVIZS5XD3XffTWhoKJ6envz11195KxctouNbb3FO0zA1bUqLhAT8/PyY7wRmqKdOnQLg/PnzrF692sHS3GKkpWE6c4b527fTonFjfpg0iYz0dPuNf+0a+PjABx/kLV+wAB57zH7zlGO2bNnCypUradOmDSk+Pnqh2iEpSkqzGjXIcHXVjz8s8HvLlmx34KWxpmk0bNiQ/v3751VI16/D+PHsq1iRad26Ydi4EcPvvzN69GjWrVvHxYuFZi4udU6f1gPGt2zZ0uJRo6L4xAcHYzCZSAgM5L+1azPs008Z0LIlV8zHzyWmRg09PlvFijlln3yiRy1ZvrzcRra2G9u28fg339CncWNcXV2p27kzJlAKSVFy2tati5ufX4H1dStVoqqDtuImk4kxY8awZcsWevXqxcWLFzl//rxeuWoVZGQwPimJu/r0gXr1wMODkSNHYjKZWLdunUNkzuL06dPUqVOHo0ePMmnSJIfKcqvhfekSAE/Pns3zP/4IQL2LF/nvf/9rn4eipsHq1TDBHPh/5kx48UWoW1f/2Tz/vxU5e5Z2sbE0M0dn6HDnnVwD0suh24VSSKXIjRs3CA4OJiYmBrFyV5MZFQVVqxZYPyIkhGX2WnnayNWrV1m3bh3nzp2jZ8+e1KxZM8fXaOlSEgIDOQz07t0b0tLg5ZdpfPw49evXd/g90unTp2nevDkuLi6ICMePH3eoPLcK6enpGE6dAoOBZgMHorVsCb6+jG7WjIwlSzA1bAgffQSFuAkUyfvvg9mkmZUr4dVX4eGHOf3663qZg3ffjiYpNBSAuh06ANC5c2euubqSeu6cI8UqHiJS7l+33367OBtxcXESFBQkgADi4+Mj06ZNK7TPjRs3ZBlISLNmBbZZMHq0DAbJzMiwt8hWYTKZJDMzU0wmk5hMJr0wLU2kVy/5pVMn8fb2loyMDBGTSaR+fZEZM2TMmDFSuXJlvdxBMterV0+ef/55ERH54osvBJB//vnHIfLcKqSnp0uDBg1k07p1IqdO5VQMGiSZfn4SD3KqWjURb2+RZ54p3iQmk0jVqiJjxug/nz8v8umnIunpUkv3eJK0Tz8t8e9SnrkweLDEg2zZskVERIxGo5gWLBD55huHymUJIFgKeZarWHalQEZGBo8++iinT5/m888/Jz09nTVr1uDr66t7s1+9Cl26gKdnnn4mk4mLM2fSoEcPGhUwtk/v3iScO0dKaiqVHGDcoGkaLi4u2T+LCLi5EbdqFS+0bUv37t1xdTV/rEJDwWDg3pUr+eqrrzh06BAdO3Z0iMwXLlwgw2wOO2jQICpWrEiVKlXKXJZbiZiYGIKCgkgVgebNcyq6dsVlzRrcPT3Z+OSTNHv0UbTiWt6dOwexsWBe/VO/PrzwAgCRwDagQVoadUvyi5Rzbpw/TwbQunVrAAwGAzz7rGOFKi6Faavy8nKmHZLJZJJnnnlGAFm8eLFeaDSKHDyor/YmTBABkSefLN4ECQkiGzaIhIfbTWZr6dOnj3z88cfZP2/dulXq1q0r21avlqCgIHFzc5M//vjjpn6JiYly/vz5MpRUUWakpopMmiSyf39O2fHjIh4eIitWlHz85cv178uBA3mKr1y5kn36sHr16pLPU445XrOm7HN3z1P25eefy8MdOog46FSiIChih6TukOzI1q1b6dy5M19++SVTp05l1KhRekVwMLRvz40lS4h/6SXo0wd27rypf0xMDMl9+2JasqTgSa5cgX79wIIPUGkSExPDxo0bSUtLyy6rW7cuDzVtSpchQ7j98mXWr19Pnz59cjpdvAh33UWlHTuob3bqdQQrVqxg+GOPkTlqFOzaBcCePXvUPVIJiYqKgsuXYeFCOHs2p6JVK0hMhEceITk5md+/+oq4KVOKZ3wQHAzu7hAUlKfY3d2dqVOnArqP2b8Z97g4MvLdO7c6dIhVwcGk5f67lAcK01bl5eUsO6Q9e/bIHXfcIR999JEYjcacithYSZo/X6qCfPTRRyLvv6+v+q5fz9P/k9mz5W+QxJkzC5zj1J49IiCnR48uucCffy4yZ45VTdeuXSuAbN26NW/F5csiU6dK8rlzN3e6cUPE1VVk6lTZt2+fDB06VBISEkout418/vnn8kDTpvp73qSJSFqaBAYGysiRI8tclluFsLAw0TRNFi1apJ8ApKdbbHf+/Hlpbb7rkWXLbJ+oRw+RTp0KrJ5doYKEVa1q+7gOIjMzU8aOHSt///23XcYzmUxy3c1Ngjt2zFsREiKyaNFNzxhHQxE7JIcrE3u8HK2QfvnlF9mwYUOR7ebMmSMHDx4U2bRJf+s3bcpTP2XKFHFzc8sxFrBAeFiYpLi6SvjQoSUTOiVFl6F1a6uajxw5Utzc3CQ5OTmnMDKy6I4dO4p06yabN2+WWrVqyaFDh4opsJnoaJF33tHlt4WlS/XfF0Q+/FA6dOggffv2LZks/2IWL14sgBw5cqTItnu2bxeTu7vIlCm2TWI06gYR48ffVLVt2zaJjo6W/zZuLKtq19aPw8sBycnJAsgjjzxinwEzM0U0TeS//7VYnWdh7AQUpZDUkZ0dePfdd/noo48sV167BnPnQlQUkyZNol27dnD77XrdgQN5mkZERBAQEICmFZw0N6BWLTwbNiSgpKFUfv9d/9eKVMdbt25lyZIlvPDCC1SoUEEP3PjSS/pFdlG+DnfeCfv307NLF65cucJtJQ2L/+OPMG0a/Pmnbf0OHtSdjR96CIxGAgICiHBgTMDyzu+//05gYCCtV6yAN94otG3nrl3RWrWCw4dtm+TMGf3or0MHMjMzs52rb9y4Qe/evfn4448Z/ttvdAkO1n2VikNYGJRhAOAKFSqQnJzMihUr7DNgUpKehyq/0YgIjzZqxHtZ1wblhcK0VXl5OXqHdOPGDbl06ZLlysWL9VX54cMSFxcnGzdulJSUFJFGjUSGDMnTdEznzvJPhQoiu3YVPmGPHmK6++6SCT1kiIifn77L+e23ApvduHFDGjduLA0bNtR3RyaTyCOP6L/TCy/oJt+FsWyZ3tZ86V3Y7s8q5s7Vx7t61arm8fHx0rhxY7naqpV+9GOef+zYsVKjRo2SyVJanD8vMmhQ0Z8DB5GRkSFVqlSRp59+WqR5c5HBgwttf+nSJdkbFCQZ1avbNtF334mAmI4elX79+kmbNm3EZDJJRkaGbN++Xc6cOaO3S0vTjSuyWLtWZM+eosc3mUT69NE/Txcu2CZbMYiJiZFVq1ZJmvk7k5mZWeIxX3vtNenSpYvF71Wii4usrlOnxHPYE9QOqfTx8vKiTkFZXH/7Tc9z36YNf/75J3369OHYsWO6GWtwcN62kZE0vXGjyECSvwQHE1MSR8OEBFi7Fv7zH32HNGiQblprgbfeeouQkBAWLlyo745Wr9adE995Bz79VL9wLoyePcFggF9/Zd26ddStW5e4kmSzzOpboQK733qLBx98MI+hRX7++ecfQkNCqHr+PLRvr6+kReiemIhvVFS2KbhT4eOj/302bnSsHGFh+mc0MxOAlStXsmnTJv7++2/i4+O5v1cvfReTz+AgP5mZmXx//Diu0dFgy640NpZEb2+GTJvG/fffz9GjR9m6dSuurq507dqVJk2aELZzJ+LpSUxWvESTCR54AO64I+9YRiO8+aZuRp7Fb7/lvMf//GO9XMVk6dKlDBkyhFOnTvHcc8/Rt2/fEo/ZoFYt2rZta/FUJc7bG08nT+Z5E4Vpq/LycuQOadGiRfL666/nrFAiI3WzVxF95ebtLTJ2rIiIhIaGCiALFy4U+egjfWUWFZU91qiKFfWyrP4FzenrK+kGQ/HPzb/9Vp9n9259ZXjokMWxjh49Ki4uLvLUU0/pBbGxIgEBIu3a2WZO2rOnSPPm8u2SJQJISEhI8eQWEZk8WcTLS+TNN8WoadIQ5I033iiw+f/+9z9plHV39NVXemFkpAjIJJDLly8XX5bSIDxcZOhQEU9Pke7dHSvLhx9m70ZNJpPcfvvtAoivr6+4urpK4ubNen0RZtcmk0mG+Pnpbdevt0mET+bMkSeeeEJu3Lgh1atXlwceeECWLFmS7QS6b/t2EZB/Hn9c73D8uD5PfqdQszGQbN6cU/b++yINGujlc+faJFdxaNeunbRv315ERN566y0BCj5ZsQaTSb8Dfvlli9WhTZvKPpDrTmTYgNohlS7fffcdf/zxR84KZcwYfcXYvbu++0hMhAEDAKhfvz6VK1fm8OHD0KuXnjvGvEJPTU3FLSu7aiGhgwCSqlTBzWQqfgKuH37QHQzvuEOPOXfbbRbP4Pfu3Yu3tzcfZEVZnjpVd+r96itwtcGn+pFH4PRp6iYmAhBbwG7MKuLi9B3EhAn8t107zgHvvfceJ7ISxOXj1KlTJLm4YJw7F3r31gv9/dk5cyYLwSH3SBkZGfz2228MHTqUSpUq0bx585wMvP/8o9+Pde8Oe/ZAamqZy5fN3r3g5saJTz8lKSmJXbt2MX/+fCpWrEj//v2plJUosn37QofRNA3fnj0BkEOHrJraaN6VTZw0iW+//RYvLy/GjRvHunXreO6557LzWrW7807E35+mWcGIt28HILVTp7wDmu+vpGFDPazVpUv65/nUKahcudR3SBHPPMPSQ4f4+cYNGDOGJzt3BmD58uXFHjMtKYnM/v1znIbz4VqvHrXJiXRfLihMW5WXl6N2SGlpaeLp6Slb2rcX+f13vXDvXpGPP9Z3EqA7CCYlZffp1q2b3HXXXTeNdf78eZmatZK/caPQeWd27Ki3s8LCKT8RR46I0WCQzNwWT2fPiowcKXLxYsEdd+zQ55w82eY5JTJSxGCQCyNHCiCb8lkX2sSQISItWoiISMuWLaVr167S0tdXOnfubPFM/sEHH5TmzZvfVL53714BZM2aNUXPuWePyKVLutXXzp0iwcHFFj8tLU3atGkjgFSrVk2efvppGTRokERHR4uIbr3239dfl8yff9bfb/NOwCHUri1ZlomvDB+eXZwdNmr0aBFfX6t26osWLZJQkLh+/Ypse+bMGXmmQQOJr1dP5PTp7PKIiAhxd3fP63Quot8N3nOP/v+hQ0VAtlavLrJvX3aTxBEj5DrI3M8+Exk+XKRfPxGTSZKSkiS+eXORe+8t+v2wFaNRJCZGREReHzVKfjEYJKN9e5FKlUTq1ZM+7dtL27Ztiz38mjVrxMXFRbfctcD1iRPFCLJ4wYJiz2FvUDuk0uPAgQO4p6bS/tq1HIu5Tp10C7Rz52DePJg/P0/Y/Ntuu40jR47oSeLS08EcLTsiIoKqgNHNrciMm5GNGzPU1xcaNLBZ5vWjRmEwmei5cCExWTssoxGWLCn4ziItTd/51aunn8Pbir8/zJiB6e67ATvskMw7yNjYWIZVrcqRxES89u7l888/v6n56dOnGVKt2k3WgLUzMngHiLcm3fb99+dYIz7yiB5tuph89dVXHD16lC+++ILw8HAWLVrEL7/8QrVq1cBo5OCBA2zbuRND9+763dvWrcWeq0SEhelO2K+9xtEVK3j2rbeyqzRN008EDh3KuZcrgh49enAISDWnASmItWvX0qFDByKjo0mvXj0nojdQs2ZNHjPnP7rrrruyy89mZBB96JCuOrdv54C3NzWjo8GcWwwgY98+DgNvvf02NyZM0L9jMTGMGzeOX0+fJrM00q5PmgQPPED01at8/tNPLHvkEVwPHNCd2iMjWZSYyIkjRwrc3RdKcjI3li9HMxpp0qSJxSZVWrXCAITt31+y36MsKUxblZeXo3ZIH374oQASefFi0dZmZr7++uucwJ4jRogEBoqIHgrl+J13SqafX5FjvPLKK+Lh4VEsi7Vn69SRL/z9ZUruHVJGhoiLi8jrr+dpO378eHnrrbf0u6aKFfWQRSXg8uXLOXdoxaVDB5H+/UVEX6mnx8SIqXlzSaxQQZbPmpWnaVJSkrgYDJLs5ZUTnNNM+t69IiBRRd0dGI1iBPkuIEDefvtt+WfpUpG4ONvlvnZNkiIixN/fX7p37275b7d8uUi9epJq3hWYbr/dcfdIP/0kAmIqyIEzLU3E3b3A+4v8mEwmaRQQII8W4n8TEREhnp6e0r59e7lQgNVbRESELFy4MM/7t7ZFC0nRNN0ZFGRl797i5eWV44OTmSnpbm4y2xxq6L333hMRkR07dgggE0DCW7XSfXrsyXffibz3nowdM0ZcXFzkeO67YfM97jyDQd7p31/fgdvCN9+IgDxWmBXdhg0iIC8V4lhc1qAcY0uPdzp1knaNG9vU5+DBgwLIjz/+KLJ9u8jy5RKXden48MPZx1GF8cEHH8hAkBv5oyYUQXp6uri5ucnUqVNFRI9IPn/+fN3IoH59/SgjF8OGDZOXsx44uYwvikvywYPSFeSDDz4o/iDNmokMG5a37NQp/Rgk69jGzLZt2wSQbZ9+mjcatYiuhCtUEDFHAC8IU3y8CMh0L6/s2Gk//PCD7XK3aiWhTZsKIDt37rTcZuhQ3RQ/M1O2bt0qS6pXF5OHh+1OwHYgdMgQSQX59MMPRf7+W+Tpp/Mashw6JLZGXxg+fLj4+vrKN889d1NsOhHdMdxgMMi53buzj7qsYV2/fiIg6W+/LQIy6Z57BJCLWUfQp06JgIyrVEmWLFkiMeaxL1++LOPGjZMqVarIWLPhkb3Zv3+/aJomL7744s2VkyZJ1pFopK1H4T16SKibW6EKXk6cEAEZX62abWOXIkohWUFERISkFxD6pCCM4eGSAbIhKMimfmlpaeLm5ibDhg0Tk8kkmzZtEh8fH9m9e7dIr14iFu6X8rNo0SL5ByS5Tx+b5j518qQ0BvnOfP4eFhYmgHz66af6SrxLl7wdjEbdp8NOXvCm7t3lOMirr75agkFMImlpsnfvXhkxYkTOQ+eNN8SkaXIp173aBx98IIBcu3bN4lBx7dtLfNOmhU5nvHRJBCTizTclMjJSgoKC5N3atcX04YfWyxwamv3gebZbN8ttUlN1i0xzSKjTp0/LgKw7xTK+R5o3b55sBTlSoYJuhbhqlS5HbkW6c6fI7beLZPkCWcHq1avFzcVFjri46H1NJklMTBQRfXFUuXJlefTRR0UmTtQXGFYq4r/MD/bE+vXlusEgY0ePludAEuvV0z8vP/wgAvLEbbdZ7N+/f39pYcVC0CYuXBDj2bPSuVMn8ff3l/j4+JvbZGRI4vvvyzBPT3lywAA9rcZrrxU9tskkpsqVZW6u3Z5FzIup9b16OU3EhqIU0r/+DuncuXM0adKEBQsW2NQvfNs2XAG55x6b+rm7u9OjRw+OHDmCpmm0cXVlRps2tGrVCho3zoniUAjVqlXjQeDMjBk2zR26dy9ngW7mM+tatWoRGhrK888/r98P5Y+6sHKl7tPxxx82zVMQ2mefMczXt2R3SJoG7u5ERESwbdu2bOtGU8+eaCKs+b//y25at25dPu7VixoFJAdcHxtLhTNnIMu60QIGc3rsmk2b4u/vzwsvvEDDK1fImDmzSH+xbMx3c+LiwrsBAZbbrFqlW2Q++CAAzZo1o9qgQfzh6kpSIX5W9iYkJIQXnnuOzi4uNH/ySWrXrq1bJ7q4wIYNOQ3vvlv3USrg/sISDz74IOmZmbQ5exZWr+ajWbNo06YN8fHxzJ8/n4SEBKZOmaL7uvXseVN6loLwbdcOAMONG/iMGsX0N97ABFS6eBHCw+HwYdIAT3O7/fv3o2ma7g8IdLvrLlacOkXS9OlFTxYba93f/ZNP0Nq04cXnn2f+/PlUrlz55jaurlSaOpWmU6fy844d3Dh4ULcGlCKSecbEoCUkEAKFRz6pXBmWLeO+L77QU1KUBwrTVuXlVZIdkslkknvvvVeqVq2abelkDQenThUBOfjttzbPaTQaJTwrfcTTT4tUrpzX07wITpw4IaNHj5azZ8/qFnxW+vV8OH26PAGSZMlK7L//FTEYsoNknjp1Sjo1biwHZs2y69n6I488Iu+//37xOicni4waJfLXXzfXpaZKpru7XMt37Cj9+okUYMl05csv9ZV/IUefMb/9JgISZz6aSk5Olqez/MV277ZO7gcfFKlXT+Spp0R8fG5e+aem6kembdvqu1IzBw4cEKD471cxWLp0qbTN2pnlPpq8+27d5yVLPjvsmv/etUteGDdOYmJixM/PT/r166dbqYLIkiVWjxN17px8ALJk4kSzaCbp6+Wlj7Nhg6T36iXBmAMbi27R+sADD2QnaNy5c6d8BbL3pZcKnyglRcTfX6R376LvjO+4Q6RrV6vkT0xMlKioqDx/+0Ix+1QNAImIiCiyeUJCgk3PttIEdWRXNMeOHRODwZCdUdQajj/9tAhI5MmTJZpbzA88Wx0Gs+naVSQoyCqFNmzYMKlbt26esoyMDHniiSdk87BhuhzmqN0bN27U71+2bSueXJaIjxeZPVvk8OHi9Y+MFKlVS+Trry3X9+6drXySk5Ml4fp1kWrVdCVmieho/Xcu5Nhj3zvviIAc++KL7LLpL7wgaSDxzz5btMzp6ZJZqZJsb9FCwvbssZzH6tNPsx+e+enWrZvc3bKl9Q+rEjJ58mSp6OEhGfv25Y0UvWSJZDsXZ2bqbg1WRoq3SGiongl26VKZN29eTiT5V17RI8Tb4MxpMpnEzXy/d8B8N9WrbVtd3lmzRK5fl7SjRyUpl/tFblJTU8XT09PyPU9uVqyQ7AC9I0cWrJRTU8Xk7i77evTQF41WYjQa5a677pL/LVpUeMPvvxcB6WLF3VDm4cNyv5ub/N///Z/VcpQmSiFZybhx48TFxUVOWqtgJk/WvelLulLMujt46in9wv7LL63qZjQa9Xuvdev0P2OuB2ZBPNezp0y0EAOvU6dOMi4rPYN59/Htt9/KWJDL9kiylsX16/ocs2eXeKgxY8bI5HwXwekzZoiAnNi+XZYtWyb9NU2f7+efLY5x+vRpifbzk/RCfGNSzPHUkvBST48AACAASURBVHPFRrtw4YKENmokmdYYtBw+LEZNk+GennLVUvy9+HiR6tX1+0MLn6XvBg0SAckohs9ZcejZs6d0smSVZTKJdOum7/BCQkSee674iygRXal5e4s8+6xcv35dFi1aJCajUaRxYz2+nI18AxILkmL24Xvsscck0sVFVxxWsHDhQtnz55+Ff5/HjNEXRNOm6Z+rN9+0vFD4+28RkAdBli9fbvXvEB0dLYtbtJAbPj6FR0KZMUOMIAN69y560KeekqSsO2onoNwpJMAX+BlIBi4Cw4rqYw+FdO3aNalSpYrcf//91nUYOlSkYcMSzysiIo89pptVDxlS4MMzNxkZGeLq6ipvvvmm/gWqWFG32CmKkSPFFBBwU/GHH34oDUGMFSro5r4iMvPddyUVJK2oVaMtmEyS6uYmK2rXLvFQTZo0uSmEf+qff8plkM+eeEJOnDghx4KCxOTrW+DxyooVK2QxSIaPT8EPoqzguPmdhufN08vzW+9ZIjZWMrLyQIWH6wYkWcdh06dL7uCz+flp9myZCnLWnjvVAjCZTFKlShX5tWNHy8eYp07ppt75rRyLS9++Iq1a5fx87JjVi6v8nLn3XjlvDssjou/wr7RsKQJycOBAeaOo049Fi/S5C8vEbDLp+b9MJpHHH9fb+/iIDBigO45nMWeOCEjUkSPZRhtWs3q1CEja778XnGV5xAhJ8vWVX3/9tejxQkJESnqKY0eKUkjOeNM1D0gH/IHhwAJN01qV6owi1KhRg+eee47169frDqN79sCRIwV2ObZhAxfsFZjzoYf0i/XnnoPBg4ts7urqyvTp0+nWrZt+yR8YqF/eFsW5c2iNGt1UPHjwYM4BC2fN0mUBUs+cwQNwb9nSxl+mEDSN5OrVc8K82Mru3XD//UhoKJcvX74poK1Hz5480rkzK86do2VgIEEhIWiPPVZgANiAgAB2ABnu7gUG/dxnMLDjP/+B6tXzlCebQ79ErllTqMgiAj4+uHp76wU1aujGC7Vr64c/Li56kNsCwr/U796dmcDhMgiSee7cOdLj4+l77JjFjMY0bw6vvqqHnlq/vuQTdu0KJ07khMD6+Wf98zxokM1DNdm4kfq50rnce++9BJqDl7b99Ve2795daP9Ms7HJlb/+KriRpul/N02Dr7+G//0PhgyB0NC8IZ727IG6danepg2VKlWy7Rfp2xe8vPht1KhsJ+CbCAmhYtu2PPDAA0WP16gR4VWq8Pfff9smh6MoTFuV9QuoiK6MmuYq+w6YWVi/Eu+Qxo4Veekl2ffnn+IJcsrs1yCFmHRfrVxZ/rGX/1NSkn78N2GCzV3j4uIko2tX/dK5ELZs2SLXPD0l8aGHbqozmUzi7e0tzz33XHbZW126SFEX/sWiXz/dubU4mM/OY/bsEUDmWLjDmDx5sgBy5IUXdPn37i1wuJCQEAHkm/yBOHMxbtw4qWbhrD780iVJBTmQz/cpDzExcq11a3myYcO8q12jMcdQZNMmkStXChzixo0bUg1kUUH3YHbkypUrMm3aNPnnxAmRglb2WYkdGzUq+YTbtuljZYVvat9e5M47Sz6u6KcIl8xHuNaE2Eo0B2X9+b77LDd44AE9GGtRmEwidevK4WbNbDquy8NDD0mCt7e4gsVdUvypU3JyzRo9jU1RREbK2r59pYGmOYXpN+Vsh9QUyBSRM7nKjgClt0MymfQVz+zZdBgxgiMuLjTfsAGaNdNXb+aAoHkQwS89naY9ethHhooVwc0NPv9cX11ZLbqJAQMG8Nfp05iuXCm0bUpsLNVSUzE0bXpTnaZpBAUFcdtvv8GLL+oiZe24bDDrtYq6dZFLl7IWG7ZhTj0RZjbTtpTy42E3Ny4Crp99RmJgIHTsWOBwAeZVcWEBVg0XL9LZwiq3Zu3a0LQpbd3cCpY3LIy0sDCuREYSGBiYa1CDvjMCuOcefYdbAF5eXmzu1Yunvv8+OxBvaREYGMjbb79N05YtoaCVvaenHpJn166ST9ipk7573blTD9p7+LBVJwTWkJKSwsNZbhG5U04UQKUWLTB6eHBf/kR3oL/v3t7ZIb1EhHnz5tGpUyfOm0N/kZkJw4bB6NFw6RL/O3uWQ1YGkr2JUaPwTkzkXbCYyG9HaCgtBw2ybvyoKO7/4w86iJBkdmFwZpxNIVUCEvKVxQPe+RtqmjZW07RgTdOCo3LFrLIZgwG++AL27EGrWRM/T08+7tMHPvlEr7cQZ8poNCJbtsCzzxZ/3vy8/rr+bxGRvnNjMBh44YUXOBwVpSukQh7y97VogQGo0Mqybm/dujWZkZGI+eFcNTqaVFdXKMhvppgciolBu3aN8NBQ2zubFdJF87+WFFKzXr2IAFoCPPFEoXHWKlSogI+3NwO//BIWL7bYpv/hwyyxcByqaRoeAwfiUkg8QQkKoou3N959+uBWmOIqgttGj8aQnm7xs5ib5ORkvv/+++Ipe+DYsWOkjxoFH39ceMPq1fX4hCXF01M/qtyxQx8vIkJ/oNsBb29vpi1dCsA7L7/M7iKO7DAYcGnWDA9LGZDd3GDpUpg4kcjISAYMGMCECRPYv38/EyZM0N9vV1ddiZuP+XeZTHQo4Bi2SAYMgHHjeAUIz5/N9sIFuv39N+u++EL3XSyK2rX1f6BkecjKisK2T2X9AtoBN/KVTQbWFtbPbqGDTKYc65bUVJGsi+h8LFmyRCpVqpQTJcBecxcza+XnTZqIgJgKiEggIjnm5QVY23z22WeC2a/BZDLJeoNBrlgRV89W9j73nAjIP+vW2d75//5PpEKFbDPh8AIuoG8H2QVWvZ/NmjWTYzVqiMyfb7H+kWbNZHoBscB++eWXbN8WS5w+dUoAWVDCaMvxBw6IgGQUIGMWEydOzDGfthGTyST+vr6S6uKiR0ooK6ZM0c28k5NLZfgNixaJK8jeQo5us0js319iqlW7+XNldoU4e/asBAQEiKenp8ydO1dmzZolgPxkNgTSB0mUXydNEneQc+Z+xSIlRSIDAyUG5Fxuv7usKPCHDlk3jskkGZ6eMhvkSBlZahYG5ezI7gzgqmla7nOitkAxwuEWA03LzvOTnJmpb9MtcH3/fh5JTqamlZ7kVs9dr16xujbq1g2AUHMumPyICDNGjNB/sHQkAQSZs34eP36ctLQ02nh6klm/frHkKQyDecy0s2dt72zOhXT58mVcXV3xL2CVPu3nnwlfudKq9zMgIIBxzZrBuHEW6/fcuMGlFi0s1m3YsIGZM2da3plmZlK7c2cmQIkzg67/5x9igfg//7y5MjUVpkzh3Lp1zJs3D4DtBXwOCkNEWD19Oh5Gox6Foazo2lU/7vLx0fMv2ZEzZ87w0uzZZKJHviiKmFq18ImJ4fiWLTmFISHQsCHXZ83innvuIT09nb179zJhwgQmTpzI/fffr2dSzqJSJX5NSqKSry/1S/L98fTEtHw5LoBh1Kic8sGD2bl+PXusPX7TNNJq1Cg3OySnUkgikgysBt7SNK2ipml3A4PQDRvKjDFjxnDHHXfATz/B44/fVF8xOJivRXAvJORMWdJu0iS6AysPHrRYHx4eTpXr13VrMj8/i22CgoKYcNdd3Dl2LJ7BwQSmpVHPxrBI1uDeuDEAxqyzd1vIpZACAwMLDIcyePBghgwZYtWQAQEBhd4htbp2jbbmZHH5CapalcMxMaQsXHhz5dmzVExIwMvPjwbFSBOSm169e2Nq3x4f8zGn0WjMSdu+ahV8+CEVHn2U2p6e9O3bl6o2HPtmYTAYuCsrJE5ZKqS779atDF1cbEv6aAXr1q3j5MmTuLu7U6VKlSLbVxk2DANgzG05uW4dAFN+/53Y2Fj++OMP2rRpA+jWrmvXrqVfv355xjlw4AAdOnSwmFbcFgK6dGFukyasTU3NE65o6rvv8qo1YY7MGAMClEIqAeMBL+AasAwYJyJls0My07dvX5588klMYWGkHzzIs48/zjrzBxPgO5OJEXfeCRbuMByBf1AQpi5dWLZ2rcX6U6dO0QhIyzJZtUCNGjWYu3gxFc+f1zOWGo32N2gAKrRoQW3geBFZRi1iVkg1a9aka9eudpEnICCA4ZcuIW3b3lSXkpLCrLQ07jNnG81PjaAg/gQiLD1IzXcJbsW9R8iFn58f1fr0weX4cUhN5Y8//qBWrVocPXoU45dfklq1Kj4pKWytWZMN69YxYcIEm+fYsWMH1375Rc+xVatWiWW2Gh8fWL4cUlKKzDxrK1m7ImsVg0+PHlw2GKiZ27Bo7Vpo2ZJ3fviBjRs3cruFWJMiwmuvvca6detITU3l2LFjxb8/ykfaf/7DpKgoUtPT9YIZM+h28iR1c+WJKgotMJBaQHx8vF1kKk2cTiGJyHURGSwiFUWkroj8UNYyDBkyhMmTJ/OVhwfVr1zhy6VLefvtt7Pr/7lwgQqtW9t9RVcSXm3YkErHjnHWwlHYyZMneR1IK+qy2vwhP3LyJO1q1eJK/jTQdsCnWjXCgOvF+XKYFdKsWbOyU1iXlClTpjB54kS0o0f1RIS5iImJoTKgFbC6rt+4MSOBExZ2nYk7d5IB1MpKm15Cjnt56UdbR49Ss2ZNBg0aRHODAZedO3kzNpbpNWpQLyQE/u//MBqNpNqY+nzm++9j+Ptv6NLFLvIWixLuKPKTlbjO6p2KprGoaVOWZAVCjY9Htm9H7r8ff39/Opt9z/KTkpLCpk2b+PPPPzl69CiZmZkWFVdxaN26Ne5GI5eXLAFAvv6a5rGx1LPheN/Vzw8f1A6pXBMaGspnn31Gx44dGT9+PPv27ePixYskJiYyMCqK+51stdF3/XpGAj/99NNNdceOHSOiWjV8i3A4fPOjj7imadRITqbtvfdStZh3WoXh4+PDCKDZ77/b3rlKlTwZRO2Bn58flbPuiPJZ02UpJEMBR2BZdwSRFhyok//+m1NA+zvvtIuc8/bt0/+zfz/t27fn66+/xv377zEZDOxs1Ih7vvsOXn+dVBcX/H19mT9/vtVjx8XFEb13L9UzM8v2uK6UadiwIY0aNeKbb76xuk9E1658n3WEu2EDWmYmgxcvZm8h91sVKlRgy5YtzJ49m+DgYAC77ZD69etH2Cuv0GTcODhzBu3yZULAph2Sh58fVYD469ftIlNpohRSAVy5coVp06axuVkzZprP7levXk1oaCjjgQ7FuZQvRVz27mV5hw4Wd0hn9u1jSs2aaEVEc+jSpQsZtWpR67ffWNKmDRVzpV63F66urgx2daVZAcdghbJ5M1dnzKBx48b8/PPPdpHn6tWrLN22Tf8hny9Xi2bNqKxp1DUbfOSnRo0aTHNzY8z06ZDvktn38mXSmjcvPD2ADQR07MhV4NKmTZw6dUovDA/HMGgQO0JCdMOJd97B8+OPGTN+vFUr9MTERN59910aNGhA86yHlSN3SHbG1dWVkJAQhg4danWfFi1aUCcmhoSvv4a1a8n08aFK375F7kgqVaqEpml4eXlRtWpViy4JxaFy5cpUfeEF2Lw5OxpECNi0QzL4+gIw2E679VKlMBO88vIq1YyxzzwjUqWK3Namjdx1112yatUqiQSJshDxwNFY8txOS0uT7i4uuqno778XPcgjj+gm5KWY9rhe7doy0sqgl/m5fPmyDB06VHbkjh1WAkJCQqSFpXQLItkJziRfavTcPF+7tt5m376cwqgovawQk3BbWbVqlTwMEli5srTPFbPtpiCcmZkiv/6qR0YvBJPJJJ07dxZABg4cKNEPPqjHZXMCb35Hsn79evkWJL1KFf39eOIJm/pfvHhRgi2ldykBP/zwg8yaNUv/u4J0BDltTnNvFTExuum6vVO0FwPKmdm389GpE8THM6ZHD3bv3s2uLVvwBypZYUZapmzZgucHH9xUfOLECXYZjaz/5BOrVr8p/v6kahoDLCUUsxNDhw/nTluPspKToVcvagcHs2zZMrrYaSXfoEEDDmXFiQsLy1N3cOtWANILMe9PzYoNmMtpVcy7vww7xgEMCgriJyAsIYGxw4bBU0/phgD57zHPnYOBA4n44AOio6P1sqQkOHYsj3n6oUOH2Lt3L3PmzGHNmjVU69BBdyQuL4ncSonmzZszDdjy+OMQF0fUHXfY5Ghct25du90fZbFhwwY2LV6cnbwxFNuO7PD15VhSEofNCQmLxSuv2N3oxBL/7k+fNZgv9h8MDKRSpUpUuXEDAM8C/Hkcxs6dMGMGo0eMYMyYMdnFB8wBJ5sOGFBwOJhcvL90KZ4i1C/AB8sezHz8ccZu3gynT1vfKTUVMjPJsPGyvigMBgMeNWro702+I7tgc6DNgowaADxbtiQN8iikaLO/0I+2/H5F0KhRIzw8PHB3d+ex+vVhyRL45ZebGzZpQtj331N3zhz9PjEuDnr0gDZtoHNnPeJAejpLlizBw8ODJ0eM0BXVa6/Bp5/aTd7ySr169Yjy9MT94EHEzY1G48czd+5ch8q0cOFCNvz0k275CrhUr46XOYyRVYSHs3PgQGYV4GtnFRcugPnZV5oohVQULVqAtzcBZ84QHR3NG1mhTQqJP+YQzKa6Tb29qZXLbPeOkBBCfH1paGXU4Zrmvj1KM+5VWpqeHt2WB3a1arB9O0/++ivt7bxSmz17NtFeXjcppDGPPgqAW7VqBfZ978MPcW/dOo9CqtihAyH33kv3Rx6xm4yurq507dqVESNGUPnhh/UwO//5j8W2tYYNo3rNmrpC7dcPOXqUpAkTID4eHn8cqV2bs99+y0MDBlB19GjIZUH6b8dgMBAeHk6PLVvYMXMmiUA7c+pzR+Hh4aE/h8zUtdXYKDKScRcu8Jb581wsIiOhZs3i97cS57FbdlZcXPSt8sqVeHz2GbEnTlAVnE8hmeV5ZfjwHEup3bsJmjNH/7mQh2puznbsyLITJ4guwMTVHrz0ySfMBrh0yea+J0+ezKNw7cH27du5MyWF6vkUkpYVWLeQHVKlSpUgKChPsNEKDz9M44cftquMABs3bsw5Pirk4aBpGjNr1uTJFSvI1DSGGgxs+OYbDuzfT7OLF+Hrr3n9iSeoWKuWHtDXx8fuspZnshyLN8XG4uLiYvcjOFtJSUnhqaeeYsRHH9GqRQu+tFUxtG0Lyck0tGVXlZ/ISHVk5zQ89RQkJJD0/ffMGDtWL3NShURYGEajkdjjx5HBg8msVQtZuVIPEGkFXgEBDAOi7OwTkptuDz1EhqurbQrpzz+Rli3h5EnrgkraQO3atdmUmXlTZPAv9+9nzdixUMhd0LVr11gTGqr/Lrt3Q2Ymv335JSeOH7erjKArmoKiU+SnpXlFPaVOHepPmoSHhwfDHn+c9F690FasoMv999OufXs9qOwLL9hd1vLMtm3bGDZsGNu2baN169Z5QwM5AE9PTzZv3syaM2eoP2CA7QrSxYVjoaEs//HH4gtRRjskh1vI2eNVqlZ2IrrlUf36IvfcI8f69xeTh0fJU5fbm5gY3bJrzhxp1aqVrGzRQkwGgzQH+SG/9VghhISESPXq1W2z4ikOTZvqFn3WYk4l3riI/EXFYebMmQJIUlJSnvLOnTvLvffeW2jfmJgYaVG1qsT7+4tUrCiZH38sArKkoLw6ZYTJaJSEXLl0fv75Z9E0Tb755huZOHGiXChmIN9/Az/++KPUq1dPAHnmmWccLY6IiPTo0UNatWol8+fPl9DQUNs6m0yys1MnGaxpYirOcyspSX+2WJMPqghQVnZ2wGCAkSPhzz8JSkpCq1XL7l7lJaZqVT2cf1gY7W67jfZnzpB+992M/+wz7rbB2bFRo0ZERUVZFYyyuKSnp5Pq749cvGh9J7OXeRzQ0p5ZbNF3SKD7nuW2RKsaEUGflJTsy2RL+Pr6cvL6dSofOgQNGnAtNJTngCr33WdXGW1FMxjwzhXcc/DgwZw4cQI/Pz8WLFhAoqU8XwoAHn30UTZs2ABAp1KIVlIcWrduzYkTJxg/fjyHbfXh0zQ6HjlCVylmTqSrV/V/1R2SEzFypB6Y9LHH8gQ6dBo0TTdsCAtjSOPGNDQaCbvnHp5//nlHS3YTy5cvJ2PHDp6sVg1XozEnWV1hmBVSPLrzoj2pU6cO3YCGHTroDojm+7Me167xf9YeKwYEQHAwvy5ZwnxgUr6Am85AixYtaNGiBdeuXbMq2Oi/mX3myBgFhQsqa1q3bg3Azp07aWsh7mJRZHh54ZOWRlxcHN62WtDWr68f2ZXB0aXaIVlLvXp6igIfHzB7PjsdgYEQHk738HDSgdeCg/VVv5NRtWpVtgKuMTF6kkNrFHxcHKkuLgTUrWv7F6oIateuzWUgpFOn7Av+zMxMPk5NZcGYMUUqzFmzZjF8+HCWrV7NSy+9RKNGjWhsjmrujChlVDRPPvkkoPslOQNZEcajo6N1QxobyfT2pgrFjGdnMOgJFEvRFSR7qlKf4Vbixg3dEdGCA6pTEBgIV65QZcMGtnl68r+1a/V8PU6Gj48P3wPnhw2DRYtgwYKiO8XFkaBpdjdoAD1193lgVY8eeup6IDY2ligg07wyLYzLly+zbNkyhg0bRvv27dmxY0eJUw8oHMuAAQPo0qULLtbs3suArM/9E088Uaz+Urly8QOsbt0Kb7yRHbqoNFEKyRZMJn2VkOWd72wsWAB//olWqxY7zJ7c9oqlZk+yzGqDBw3SFVLuBGQFILGxRBuNdr8/At3Pw8/Pj/BLl3RfHfTAqgOBdlbELAwKCkJEePHFF/nrr78IsHPad0XZs27dOnbs2OFoMbLJ2hUlJCQUbwAfn+IrpL//hvfes9pStySoOyRbqFQJYmMdLUXB+Pjor337qDhzJrz6qlMqJB/zsVhcfDxkRZXIMiYoYGdhun4d7zp1eOCBB0pFpoYNG/LGjz/qIYp++IGYmBjGA0GbNhXZd9SoUfTs2dOpj+kU5Z/p06djKub9tcHXlyrAyeIopFdfhZdftu6ut4SoHdKtxPHjuvHFxYu8/MorHD582G5h8O1J1g4pNku5r18P1auDOaq6JVwSE6kTFET37t1LRabdu3dTs1277GgNReVCyiObi4tSRopS56233uKdd94pVl+36tVLlhOpjHK/KYV0K5GYCN9+C6dPYzAYimWNUxZUqFABV1fXnC9Hw4bw8MOFmtInNWxIUileMGuaBrVrZyukhIQEqgCuzmrAolDYgLs5SV98cRTSlCkwb57dZbKEUki3EnfeCRcvQt++jpakUDRNo2rVqjk7pObNYeHCQu/mnnFzo9WqVaUm04YNG1j5999IWBiI8Pjjj9MiMJAKZeGdrlCUMi7VquGiaTxVQPzDQlm2DPbvt79QFlAK6VbDzhlVSwsfH5+8xwcm003BTXPz/PPP88knn5SaPCkpKYRmZqKlp+uBSwEtIcGqIzuFwumZNAktM5PApk1t6ydSdmGDUApJ4SBeeuklhgwZAujhq64//jipzZrx7DPPsCtXoFIAkpK4Y+hQHizFtPEPPvggU5cs0X84dYqvvvxSPwItxbxQCkWZ4ebG73/8wcaNG23rFxsLGRnEeXlxNStiQymirOwUDuHZZ58F9DTaDz30EA02b2Yh8MfChSQmJeUJd3Q9Korkhg2pWrkytrsE2kCWSfnJk5zJCo6qdkiKW4EzZ0h/6il+btCAPn36WN8vMhKAZX/9xbtffVXqjvZqh6RwCPHx8Vy4cIGTJ0+yZ88euphDHI1q04bT+fIk7Tx2jLpbtnDczmkncmM0Gun0wAOkVqgAJ0/y0bRpeoXaISluBRISuN9k4pMpU2zrZ1ZIJ69fp1EZ+F+qHZLCIUybNo1Vq1YRERHB+fPnqe7tDQsWcIe7Ox+cOoWIZEc7OHPiBBr2j2GXGxcXFy5eusQVb28aHDuGKSYGN1AKSXFr0KEDLteuYXPmK7NCOhwZSdMyCDSrdkgKh9CwYUMmTJgAQPXq1cHDA4KCaJacTHJyMmFhYdltq61bRzJQJTm5VGWqU6cOq2rW5HsvL+54/HHSjxxxeotFhcJatmzZwge2hj0zK6Rj0dFqh6S4dZk0aRJpaWl5C2+/nZpm0+7Tp09np4VwO38el6wAj6VI7dq1mbl1KwlHjzJx4kTczQEtFYpyT2Ym/s88w7GQEOSVV6yPtRgZiXh4sPznn2lUBs7fRSokTdOKDDQmIl/bRxzFvwVN0/D09Mxb2L497osXs2bu3Oxw+yKCb1QU0T4+1Crl0CV16tQhKT6eXgEBvNenD8yZo2cLVim+FeUdV1eanjtHkAjJycnWRwzPyEBr0IB+ZZTfy5od0ogi6gVQCklRcsypmQfWrp29G4qMjKRBZiYp5t1SadKgQQNqAZsjImD6dDhwAIYMUQpJcUuQXqECPomJxMfHW6+Q5szh4IgRRPz2G/379y/1KPZFKiQR6VmqEigUWbRpAy4uXF2/noMeHtx3332cPn6cu4HwUjRoyGL06NG0b9cOwsPhrrv0LLzKqEFxi5BZqRI+iYnExcURGBhodb+FCxeycuVKYmJiSlE6HauNGjRNq6ppWl9N0x7TNK2PpmlVS1Mwxb8QLy9YtIjPIiMZO3YsAGG7d+MOVOnYsdSnr1y5Mj169oThw6FBA31nZFB2P4pbA/H2tj3A6qOPMqt1a7Zu3VpaYuXBqm+bpmnTgXBgHTAbWA+Ea5r2RinKpvg3MnIko+bMyf4CJB44AIBPGZicZhMSAg89BDNmlN2cCkVp4+OTJ2vsggUL2Lt3b8HtTSa4fJlKGRnZd7qlTZEKSdO0R4HngccBLxEJADzR75bGaZpWjGh9CkUBJCTQ6OhRGlWsCMBwsyLSzJlcy4TVq+Hnn+Hjj8tuToWilDH4+mbvkHbt2sX48eMZOHAg0dHRBXQwkL5tG2/Gx3PkyJGykdGKNmOAl0TkJxHJBBCRTBFZBUwGxpZUCE3TPDRNW6xp2kVN0xI1TTusaVrZmHUonItLl+Chh/hj8mT27dtH5YgIPXxPYp7WqQAAFg9JREFUjRplJ0PWfVVSUtnNqVCUMq7VqmUrpNdff51q1aoRGxvL8+YoKZa4ePEiM2bM4PDhw2UjoxVtbgMK2gWtBz61kxyXge7AJaA/sELTtNYicsEO4yvKCy1akL51Kw/16sVYPz/C4uPpOmoU1UvZuicPpZAmXaFwNG7mnEhxcXHMmDGD2NhYTp48ybRp03j44Yezgx1n88cf+E2YQDMoswSUmmSlji6ogaYliEiBpkZF1RdbME07CrwpIj8V1bZDhw4SHBxsbxEUDqRJkyaYTCbOnTvHL7/8wqBBg8pucqMxJ0NmEd8PhaLcMGcOGXPmkHHsGBXMQYMzMzO54447uHjxIidOnMDPz09vm5YGnTpx4/x5/BMTORsRQU07pKDQNO2AiBSYxtqaIztN07QGmqY1tPQC7L501TTNH2gKnLD32IpywLFjzDSZ8PP0JP7wYfr07l2287u46MeE999ftvMqFKXJiy+yfu5cpk6fTpL5ONrV1ZVvv/2WxMREevXqxeXLl/W2b7wBR4/yQ8+eSMWK+JdylJQsrFFIFYFQIKSAV0V7CqRpmhuwFPhWRE4X0m6spmnBmqYFR0VF2VMEhaM5d46Hz53j9jNnqHzbbXitXVv2MsTGgiPmVShKkZ9++ok1a9bkiZLSqlUr1q9fT1hYGMHBwbBzJ3z4IYwezRqTiUaNGpW6Q2wW1jjGltgRQ9O0rej3Q5bYJSJdzO0MwHdAOjChCLkWAgtBP7IrqYwKJ6JzZwBqZWby47338p8uXcpehrK8s1IoyoIDB5h35gxxX36Jq2veR3+vXr04d+4cVd3coE0bTPXrY5g9m9DOnWnevHmZiWhNLLu/imgiIlLomYqI9LBiHg1YDPgD/UUko6g+iluUmjVJ9fen0dWrPLVzJ/+pU8fREikUtwTeBgPeWfdE+ahatSosXAjnzzO0enXeDg/n3LlzDBgwoMzks8bKbmkB5YHAC0AFO8myAGgB3CMiKXYaU1FO0Tp35j+//sq6MggZpFD8K7j9dti9u/A2//sf6Y0akd6qFSkpKaSlpZWZhR1YcYckIotzv4Bf0BXHZGA1uvFBidA0rR7wDLqJeaSmaUnm1/CSjq0on3h06wbAN4mJDpZEofiXEBICu3bhPmYMv6xZQ6L5u1cWeZCysDofkqZplYGX0e921gHtRSTUHkKIyEVKwVpPUY4x3yO5JiQ4WBCF4hYhJQU6dYLnn4exFuIZxMdDt256LEega9euxMXF3ZwmphSxJnSQl6ZprwLn0HdGXURkhL2UkUJhkfbt9X8nT3asHArFrYKnJ5w8CZcvQ0ICvPSSHiYri9tvh23bIFeqlypVquDh4VFmIlrjGHsVXXF9BFj0PhWRogwfShXlGHuLYjTq0baVxZtCYR98feG22+DCBTh/Xv9uffEF3HefHm2/evVSnb4ox1hrjuxS0JPwjSugXoCGxZBNoSicUs4Qq1D86/DxgS1boF492LwZ5s2DwEDdEXbNGoiMBDc3h4lnjR9S/TKQQ6FQKBSlzSOPQEyMHsm+ShXIioJSrx707etQZQQ2GDUoFAqFopzzwQeWy4OC9JeDUekwFQqFQuEUKIWkUCgUCqdAKSSFQqFQOAVKISkUCoXCKVAKSaFQKBROgVJICoVCoXAKlEJSKBQKhVOgFJJCoVAonAKlkBQKhULhFCiFpFAoFAqnQCkkhUKhUDgFSiEpFAqFwilQCkmhUCgUToFSSAqFQqFwCpRCUigUCoVToBSSQqFQKJwCpZAUCoVC4RQohaRQKBQKp0ApJIVCoVA4BUohKRQKhcIpUApJoVAoFE6BUkgKhUKhcAqUQlIoFAqFU+DqaAFKE5PJxJUrV0hOTna0KIoCqFixIrVr18ZgUGsjheLfzi2tkKKjo9E0jWbNmqkHnhNiMpkICwsjOjoaPz8/R4ujUCgczC39lI6Li8Pf318pIyfFYDDg7+9PfHy8o0VRKBROgFM+qTVNa6JpWqqmad+XZByj0Yibm5u9xFKUAm5ubmRmZjpaDIVC4QQ4pUIC5gH77TGQpmn2GEZRSqi/j0KhyMLpFJKmaUOBOOBPR8viKEaOHMm0adMcLYZCoVCUKU6lkDRNqwy8BbzkaFkUCoVCUbY4lUIC3ub/27v/6CrK/I7j7y+IG8hPkpuAiQlpSRXNitnKqnVRciKwKoHWXxgJsrRFPFXKqkUFuqnJIriC55RT3a5HYamgB2XdcyysP4sIqC0Y1BZFiK5uTMJdglmWkIjEKE//eIbs5Me9uYHcmTF8X+fM4d4888x8mDt3nvs8M3curDbGNPQ2o4jMFZFdIrLr888/9yCaUkqpePKsQRKRrSJiIkxvikgRMBH411iWZ4x53BgzzhgzLjMzM77h42Tv3r0UFxeTlpZGYWEhGzdu7Chrampi0qRJJCcnM2HCBD777DMAjDHcddddZGVlkZKSwgUXXMAHH3zg139BKaX6jWcNkjGm2BgjEabxQDGQD9SJyAFgAXC9iLzrVUYvtbe3M3XqVCZPnszBgwd55JFHKC8vp6amBoCnn36aiooKmpqaKCoqory8HIBXX32V7du389FHH9Hc3MyGDRvIyMjw87+ilFL9IkhfjH0ceMb1fAG2gfqH/lxJcXFxr/OUlpayYMGCjvlnz57N7NmzaWpq4oYbbohad+vWrTHl2LFjB62trSxcuJBBgwZRUlJCaWkp69evB2DKlClcccUVACxdupTU1FTq6+sZMmQILS0t7Nu3j4svvpjzzjsvpvUppVTQBeYckjHmqDHmwIkJaAWOGWMG5AmicDhMbm5upy/tjho1iv379wOQm5vb8fekpCTS09MJh8OUlJQwb9487rjjDrKyspg7dy5HjhzxPL9SSvW3IPWQOjHGVMZjubH2YHqaPxQK9bl+JNnZ2dTX13P8+PGORqmuro5zzjmH2tpa6uvrO+ZtbW3l0KFDZGdnAzB//nzmz5/PwYMHmT59OitWrGDJkiX9kksppfwSmB7S6eaSSy5h2LBhLF++nPb2drZu3cqmTZsoKysD4MUXX+TNN9/kq6++oqKigksvvZTc3Fyqq6vZuXMn7e3tJCYmkpCQoLdGUkoNCHok88mZZ57Jpk2beOmllwiFQtx+++2sXbuWMWPGADBjxgyqqqpIT0/nnXfe4amn7F2Ujhw5wq233srw4cMZNWoUGRkZ3HPPPX7+V5RSql+IMcbvDKds3LhxZteuXd3+vnfvXj3p/y2gr5NSpwcReccYMy5SufaQlFJKBYI2SEoppQJBGySllFKBoA2SUkqpQNAGSSmlVCBog6SUUioQtEFSSikVCNogKaWUCgRtkAJm2bJlzJkzJy7LLi4uZtWqVSdVt66ujqSkJL755pt+TqWUUlZgb656ulq8eLHfEQDIz89n1apVTJw4EYC8vDxaW1t9TqWUGsi0h6SUUioQtEHy0UMPPUROTg7Jycmce+65vPbaa1RWVjJz5kwAamtrERHWrFlDbm4uw4cP57HHHqO6upqxY8eSlpbGvHnzOpbnruuu//XXX3db9yeffEJJSQkZGRmEQiHKy8s5fPgwALfccgt1dXVMnTqVpKQkli9f3m1Z4XCYadOmkZ6eTkFBAU888USnHNOnT2fWrFkkJydTWFhIT/caVEopN22QfFJTU8Ojjz5KdXU1LS0tvPLKK+Tn5/c4786dO/n444959tlnufPOO1m6dCmbN29mz549bNiwgW3btvV5/cYYFi1aRDgcZu/evdTX11NZWQnAunXryMvLY9OmTbS2tnLvvfd2q19WVsbZZ59NOBzmueeeY/HixWzZsqWjfOPGjZSVlXH48GGmTZvWqeFUSqmenH7nkGL4CXNKS8H5CXOKi2H2bDs1NUEvP2FOjD/gN3jwYNra2vjwww/JzMyM2BgBVFRUkJCQwOTJk0lMTOTmm28mKysLgMsvv5z33nuPCRMmxLTeEwoKCigoKAAgMzOTu+++m6qqqpjq1tfX89Zbb/HCCy+QkJBAUVERc+bMYe3atZSUlAAwfvx4rrnmGsD2uFauXNmnfEqp04/2kHxSUFDAypUrqaysJCsri7KyMsLhcI/zjhgxouPx0KFDuz0/mYsNGhsbKSsrIycnh5SUFGbOnElTU1NMdcPhMOnp6SQnJ3f8zf3z6wAjR47seDxs2DCOHTvW49ChUkqdcPr1kPr6E+Tu+UOhvtePYsaMGcyYMYMjR45w2223cd999zF69OiTXl5iYiJHjx7teH7gwIGI8y5evBgR4f333yc9PZ3nn3++07CaiESsm52dzaFDh2hpaelolOrq6sjJyTnp7EoppT0kn9TU1LBlyxba2tpISEhg6NChp/xT5EVFRWzfvp26ujqam5t58MEHI87b0tJCUlISqamp7N+/nxUrVnQqHzFiBJ9++mmPdXNzc7nssstYtGgRx44dY/fu3axevbrTBRVKKdVX2iD5pK2tjYULFxIKhRg5ciQHDx6M2oDEYtKkSdx0002MHTuWiy66iNLS0ojz3n///bz77rukpqYyZcoUrrvuuk7lixYt4oEHHiAtLY2HH364W/3169dTW1tLdnY21157LVVVVR3fWVJKqZOhP2GufKevk1KnB/0Jc6WUUt8K2iAppZQKBG2QlFJKBYI2SEoppQJhwDdIA+GijYFMXx+l1AkDukEaPHgw7e3tfsdQUbS3t3PGGaff97OVUt0N6AYpLS2NxsZGjh8/7ncU1YPjx4/T2NhIamqq31GUUgEwoD+ahkIhGhoaqKmp8TuKiiAxMZFQKOR3DKVUAAzoBmnQoEHk5eX5HUMppVQMAjVkJyJlIrJXRL4QkU9E5HK/MymllPJGYHpIIjIJeAi4CXgbOMvfREoppbwUmAYJqAJ+aozZ4TzfH21mpZRSA0sghuxEZDAwDsgUkd+KSIOIPCoiQ/3OppRSyhtB6SGNAIYANwCXA+3AfwI/Af65pwoiMheY6zxtFZFol9KFgNh+DjW+NEdnmqO7oGTRHJ1pjs5ONseoaIWe/PyEiGwFJkQofguYChwCZhtjnnTqXA/8xBjzvX5Y/65otzz3iubQHL0JShbNoTn8yOFJD8kYU9zbPCLSALhbR72njFJKnUYCcQ7JsQb4RxHJEpHhwF3Ab3zOpJRSyiNBOYcEsAQ7LvkRcAzYACztp2U/3k/LOVWaozPN0V1QsmiOzjRHZ3HJMSB+wlwppdS3X5CG7JRSSp3GtEFSSikVDMaYb80EzAN2AW3Af3QpmwP8FmgFXgayXWVpwJPAQWeqdJXlOXXckwH+ycscTnkR8AbQDDQAFV5vD6f8Muztm1qA3cD4XnJ8B1gNfObU+V/galf5lcA+4CjwOjCqS91fAkeAA8DdXZYdsa5XOYAzgeeAWmffKPZjewCXAv+F/YrE58CvgLN8yHG+s9/90Zk2A+f7tY+45vsX5/WZ6MM2yXfW7T6ORHz/xnN7AMOAf8d+T6gZ2O7D9ijvsi2OOtvnoqj7SbTCoE3AdcDfAL/AdQAGirEH1kLsweMXwDZX+Rrsm3eYs+N8AvxthHX8GfANkO91DuBD7IUcg4HRwO+BaV7mANKBPwA3OjlmYg86w6PkSAQqnWUNAkqdnTsfe6FKs7O8BGAFsMNV90FsIzwcOM/Zsa9yyqLW9TDHmcCdwHjnNSnuZT+NV46rnXopzmv3S+BlH3KkOcsQZx+ZD+z2Y5u45hkNvA+Eid4gxWub5GMPuGfEeCyL2/YAngKeATKd1ydiIxDv18U172zscUaibpdYNl7QJuABOh+AHwZ+7nqe7ewco53nTcD3XeWLgTciLPt+4HU/cmA/RZzvev4rYJGXOZwdck+X5X8E/H0fX6PdwPXYu2n8d5c3wJfAGOd5GJjsKl8CPOM8jlrXqxxdltdALw2SFzmcsr8EWvzMgb1S9w7gqJ/bBDsKcA22FxuxQYrjvppPHxqkOOYYg+2xpPiZo4dlvg7c39u6B9I5JOnh8XejlLvL7B9FBJiFHc7yI8dKYJaIDBGRc4G/wg6HeJ3DXdZTefQVi4wAzgH2YHtp/3eizBjzBfaTUqHzfbOz3OXO40LnccS6Huc4JXHMcYWzTF9yiMhh7Fc0HgGWxZqjv7OIyI1AmzHmxb5k6O8cjs+ce3GuEZGYf3myH3NcjB1+qxKRJhF537nrjdc53Mschd1X1/a2/oHSIL0MTBeRsc4NWU+MJQ9zlS8UkWQRKQD+zlXmNh57X73nfMrxG+z9/L7EjtuuNsZUe5zjf4BsEbnZaRh/hB0O6Wl7dSMiQ4CngSeNMfuAJGy3360ZSHbK6FJ+ooxe6nqZ46TFK4eIjMW+rvf4lcMYkwakYs9lvhdLjv7OIiLJ2Mbwx7GuPx45cEYdsPdqu8j5+9M+5Dgb++GxGTsyMg94UkTO8ziH2yzsCMzvesswIBokY8xm7FDbr7Fd9lrsOGiDM8t87EH+Y+xNW9e7ytx+BPzaGNPqdQ4RScc2FD/FjtfmAj8Ukdu9zGGM+QPw18DdQCNwFbaX1tP26kREBgHrgK+wbwSwJzRTusya4uRpdT3vWtZbXS9znJR45XA+RLwE/NgY84ZfOaDjU/NjwFoRyfIhSyWwzhhT29u645nDGNNqjNlljPnaGNPoLHOy02B6lgP7vm4HHjDGfGWM2YYdLpvscQ63mEedBkSDBGCM+bkx5i+MMSOwB+IzgA+cskPGmHJjzEhjTCH2//22u77Tk7iRUxuuO5Ucfw58Y4xZ6+zUDdgTk9d4nANjzDZjzPeNMenALdhx6be7r+VPnOHO1dge5vXGmHanaA9woWu+RGyPa48x5o/YiwQudC3qQv40DBWxrsc5+ixeOZzhj83AEmPMOr9ydDEI24PO8SHLlcB8ETkgIgewH+Q2iMh9Hufoyjj/RjzGxinH7ihZvMxxos4PsD212EadTvbElx8T9qCagL26Y53z+MTfvos915EHbAWWueqNBjKwV5xcje1eF3ZZ9gxsTyLqVSDxyoH9dHHYyTEIGIkdPlvm9fYAvof9OZAU7Hmtt2LYJo8BO4CkLn/PxHblr3dyPUTnK3V+BmzDXqkzBruTXxVLXa9yOOXfceo1YD9tJkTbV+K0PXKwY/gL+vCeiUeOSc4+MtjZR/4Ne4I7wYcsGdj3yompHvvBMsnjHJcA52LfuxnAs/RycVSccgzBft2jAnss+AG21xLxQqB45HDN8ziwNub9NdYZgzBhu+emy1SJvQx1N/AF9tLDB4HBrnrTnTfMUex19j/sYdmvYD91+pYDKAGqnZ3gAPAEMMyHHOudDM3OGyurl+0xyln3MTp/96DcKZ+IPSf2JbZxzHfVdX+XoZHu36mIWNfjHLU9bOses8QrB3YY1nRZZqvX2wN7wN/nLOtz4AVgrF/7SA+vU7TLvuO1TW4Gfod9z/0eewJ/pE/7aiH2w+wX2K+SXOtTjgTsh+wrYzmuGmP0XnZKKaWCYcCcQ1JKKfXtpg2SUkqpQNAGSSmlVCBog6SUUioQtEFSSikVCNogKaWUCgRtkJRSSgWCNkhKKaUCQRskpZRSgfD/ZTdejea1vZIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}