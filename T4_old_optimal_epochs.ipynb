{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T4_old_optimal_epochs.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPMQyFRRX4vLgkXRU7dltoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/voquangtuong/AAA_drought_prediction/blob/main/T4_old_optimal_epochs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjmSI_mvaIwc",
        "outputId": "801f681f-408f-4c85-b1ef-48e75347d9c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZ50DaMaTDl"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/dynamic/T4old')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-26pZn4sRVR3"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Nov 19 00:18:39 2021\n",
        "Bo het historical NDI o droplist1a\n",
        "\n",
        "@author: Administrator\n",
        "\"\"\"\n",
        "\n",
        "# from lstm_utils import *\n",
        "import pickle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "####LIBRARY\n",
        "import scipy\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow import keras # tai sao import tu tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "# =============================================================================\n",
        "# Import library\n",
        "import os \n",
        "os.chdir('/content/drive/MyDrive/dynamic/T4old')\n",
        "outs=['save_model_T4','save_pickle','table_T4','fig_T4']\n",
        "for out in outs:\n",
        "  if not os.path.exists(out):\n",
        "    os.makedirs(out)\n",
        "# =============================================================================\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"all_utils.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1ydQW-LmuXBguZbpvhMM2-LpdkVfdpRrg\n",
        "\"\"\"\n",
        "\n",
        "# !pip install -q -U keras-tuner --q\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "####LIBRARY\n",
        "import scipy\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import Sequential, optimizers, backend\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow import keras # tai sao import tu tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# ROC\n",
        "import datetime\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.dates as mdates\n",
        "import datetime\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# import statsmodels as sm\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib\n",
        "###  SET FONTS FOR PLOTTING\n",
        "font = {'family' : 'normal',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 12}\n",
        "\n",
        "matplotlib.rc('font', **font)\n",
        "### cap nhat font\n",
        "# plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "####RANDOM SEED SET\n",
        "#tf.random.set_seed(10000000)\n",
        "#np.random.seed(10000000)\n",
        "\n",
        "####PANDAS LIB\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "###### Univrate LSTM\n",
        "# univariate lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "######## Keras tunner\n",
        "# import keras_tuner as kt\n",
        "\n",
        "################################################\n",
        "# CUSTOMIZE FUNCTION\n",
        "# generate sample data by pandas shift\n",
        " ####cutomized sub.\n",
        "def series_to_supervised_df(data, n_in, n_out, dropnan=True): # dung cho pandas\n",
        "\t\"\"\"\n",
        "\tFrame a time series as a supervised learning dataset.\n",
        "\tArguments:\n",
        "\t\tdata: Sequence of observations as a list or NumPy array.\n",
        "\t\tn_in: Number of lag observations as input (X).\n",
        "\t\tn_out: Number of observations as output (y).\n",
        "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
        "\tReturns:\n",
        "\t\tPandas DataFrame of series framed for supervised learning.\n",
        "\t\"\"\"\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg\n",
        "\n",
        "  # SAMPLE GENERATE\n",
        "\n",
        "# CREATE A DATA INPUT FOR MODEL\n",
        "#####################################################\n",
        "def generate_input_M1(dataset,dataset_climate,k0,n_in0,n_out0):\n",
        "  # n_window0=5\n",
        "  dataset0=dataset[k0]\n",
        "  dataset0_climate=dataset_climate[k0]\n",
        "  df_supervised0=series_to_supervised_df(dataset0,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  df_supervised0_climate=series_to_supervised_df(dataset0_climate,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  # thang df_supervisied000: tong hop cua mo hinh quan trac + thay doi gia tri tai t ban mo hinh khi hau\n",
        "  df_supervised0.iloc[:,[-2,-3,-4]]=df_supervised0_climate.iloc[:,[-2,-3,-4]]\n",
        "  df_supervised0_obs_cli=df_supervised0_climate # da co so lieu cua climate model o day\n",
        "  \"\"\"## loai bo cac gia tri cua NDI theo thang CH* Han\"\"\"\n",
        "  # Bo het NDI\n",
        "  drop1=np.array(range(3,df_supervised0_obs_cli.shape[1],4)) # toan bo gia tri NDI trong input\n",
        "  # print(drop1)\n",
        "\n",
        "  drop1a=drop1[:-1] # chua lai thang cuoi la thang du bao\n",
        "  # print(drop1a) \n",
        "  # # van giu lai dam lau la luc lac tai buoc t. Khong bo gi het\n",
        "  # # drop2=np.array(range(df_supervised0.shape[1]))\n",
        "  # # print(drop2)\n",
        "  # ########  QUAN TRONG\n",
        "  # ''' bo het cac bien cua NDI trong phan input (drop1)\n",
        "\n",
        "  # input cua PRS gom 2 phan:\n",
        "  # phan 1: gia tri thuc do tu dau den buoc t-1\n",
        "  # phan 2: gia tri cua mo hinh du bao tai buoc t\n",
        "  # -> giai quyet bang cach go bo cac gia tri PRS tai t\n",
        "  # thay bang cac gia tri cua mo hinh du bao tai buoc t\n",
        "  # khong can bo thang drop 2, chi can thay no ban gia tri trong mo hinh khi hau la duoc\n",
        "\n",
        "  # '''\n",
        "\n",
        "  # # drop2a=drop2[df_supervised0.shape[1]-4:df_supervised0.shape[1]-1]\n",
        "  # # print(drop2a)\n",
        "  list_drop_cols=[]\n",
        "\n",
        "  [list_drop_cols.append(drop) for drop in drop1a]\n",
        "  # # [list_drop_cols.append(drop) for drop in drop2a]\n",
        "  # # print(list_drop_cols)\n",
        "\n",
        "  # \"\"\"## Bo di bay lu khon nan\"\"\"\n",
        "\n",
        "  df_supervised=df_supervised0_obs_cli.drop(df_supervised0_obs_cli.columns[[list_drop_cols]],axis=1)\n",
        "  # df_supervised\n",
        "\n",
        "  \"\"\"# Chia du lieu theo ti le0.6:0.2:0.2\"\"\"\n",
        "\n",
        "  # chieu dai cua train\n",
        "  n_train=int(df_supervised.shape[0]*0.6)\n",
        "  # print(n_train)\n",
        "  n_val=int(df_supervised.shape[0]*0.8)-n_train\n",
        "  n_test=df_supervised.shape[0]-n_val-n_train\n",
        "  # print(n_val)\n",
        "  # print(n_test)\n",
        "\n",
        "  # df train, val, test\n",
        "  train_df=df_supervised.iloc[0:n_train,:]\n",
        "  val_df=df_supervised.iloc[n_train:n_train+n_val,:]\n",
        "  test_df=df_supervised.iloc[n_train+n_val:,:]\n",
        "  # print(train_df.shape,val_df.shape,test_df.shape)\n",
        "  # 342 doan dau vao, moi doan la 16 dactinh\n",
        "  # bao gom 3 bien x5 buoc + bien dau ra -> 16 bien\n",
        "  # moi an doc 1 buoc \n",
        "  # bo vao 15 gia tri x so batsize de du bao gia tri 16\n",
        "\n",
        "  \"\"\"## Phan ra du lieu de train va target \"\"\"\n",
        "\n",
        "  x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "  y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "  # print(x_train.shape,y_train.shape)\n",
        "\n",
        "  x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "  y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "  # print(x_val.shape,y_val.shape)\n",
        "\n",
        "  x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "  y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "  # print(x_test.shape,y_test.shape)\n",
        "\n",
        "  ## check input_train\n",
        "  # print('input',x_train[0], 'output',y_train[0])\n",
        "  # print('df_train',train_df.iloc[0,:])\n",
        "  # gia tri output va gia tri du bao phai giong nhau\n",
        "\n",
        "  \"\"\"# Scale Max-Min data\"\"\"\n",
        "\n",
        "  # tao 2 scaler rieng cho X, Y de invert cho de\n",
        "  scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "  scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "  x_train_scale = scaler_x.fit_transform(x_train)\n",
        "  y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "  # fit scale cua train cho val va test\n",
        "  x_val_scale=scaler_x.transform(x_val)\n",
        "  y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "  x_test_scale=scaler_x.transform(x_test)\n",
        "  y_test_scale=scaler_y.transform(y_test)\n",
        "\n",
        "  \"\"\"# Tensorflow format\"\"\"\n",
        "\n",
        "  # # reshape input to be 3D [samples, timesteps, features]\n",
        "  # n_features=1\n",
        "  # train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "  # val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "  # test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "\n",
        "  # Kiem tra lai\n",
        "  n_features=1\n",
        "  train_X = x_train_scale.reshape((x_train_scale.shape[0], n_features,x_train_scale.shape[1]))\n",
        "  val_X = x_val_scale.reshape((x_val_scale.shape[0],  n_features,x_val_scale.shape[1]))\n",
        "  test_X = x_test_scale.reshape((x_test_scale.shape[0], n_features, x_test_scale.shape[1]))\n",
        "  print(['input shape output shape'])\n",
        "  print(train_X.shape,y_train_scale.shape)\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "  return train_X, y_train_scale, val_X,y_val_scale,test_X,y_test_scale,scaler_y,n_train,n_val\n",
        "\n",
        "#######################################################################################\n",
        "\n",
        "def generate_input_M2(dataset,dataset_climate,k0,n_in0,n_out0):\n",
        "  # n_window0=5\n",
        "  dataset0=dataset[k0]\n",
        "  dataset0_climate=dataset_climate[k0]\n",
        "  df_supervised0=series_to_supervised_df(dataset0,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  df_supervised0_climate=series_to_supervised_df(dataset0_climate,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  # thay doi cac gia tri cho mo hinh khi hau\n",
        "  df_supervised0.iloc[:,[-2,-3,-4,-6,-7,-8]]=df_supervised0_climate.iloc[:,[-2,-3,-4,-6,-7,-8]]\n",
        "  df_supervised0_obs_cli=df_supervised0_climate # da co so lieu cua climate model o day\n",
        "  \"\"\"## loai bo cac gia tri cua NDI theo thang CH* Han\"\"\"\n",
        "  # Bo het NDI\n",
        "  drop1=np.array(range(3,df_supervised0_obs_cli.shape[1],4)) # toan bo gia tri NDI trong input\n",
        "  # print(drop1)\n",
        "\n",
        "  drop1a=drop1[:-1] # chua lai thang cuoi la thang du bao\n",
        "  # print(drop1a) \n",
        "  # # van giu lai dam lau la luc lac tai buoc t. Khong bo gi het\n",
        "  # # drop2=np.array(range(df_supervised0.shape[1]))\n",
        "  # # print(drop2)\n",
        "  # ########  QUAN TRONG\n",
        "  # ''' bo het cac bien cua NDI trong phan input (drop1)\n",
        "\n",
        "  # input cua PRS gom 2 phan:\n",
        "  # phan 1: gia tri thuc do tu dau den buoc t-1\n",
        "  # phan 2: gia tri cua mo hinh du bao tai buoc t\n",
        "  # -> giai quyet bang cach go bo cac gia tri PRS tai t\n",
        "  # thay bang cac gia tri cua mo hinh du bao tai buoc t\n",
        "  # khong can bo thang drop 2, chi can thay no ban gia tri trong mo hinh khi hau la duoc\n",
        "\n",
        "  # '''\n",
        "\n",
        "  # # drop2a=drop2[df_supervised0.shape[1]-4:df_supervised0.shape[1]-1]\n",
        "  # # print(drop2a)\n",
        "  list_drop_cols=[]\n",
        "\n",
        "  [list_drop_cols.append(drop) for drop in drop1a]\n",
        "  # # [list_drop_cols.append(drop) for drop in drop2a]\n",
        "  # # print(list_drop_cols)\n",
        "\n",
        "  # \"\"\"## Bo di bay lu khon nan\"\"\"\n",
        "\n",
        "  df_supervised=df_supervised0_obs_cli.drop(df_supervised0_obs_cli.columns[[list_drop_cols]],axis=1)\n",
        "  # df_supervised\n",
        "\n",
        "  \"\"\"# Chia du lieu theo ti le0.6:0.2:0.2\"\"\"\n",
        "\n",
        "  # chieu dai cua train\n",
        "  n_train=int(df_supervised.shape[0]*0.6)\n",
        "  # print(n_train)\n",
        "  n_val=int(df_supervised.shape[0]*0.8)-n_train\n",
        "  n_test=df_supervised.shape[0]-n_val-n_train\n",
        "  # print(n_val)\n",
        "  # print(n_test)\n",
        "\n",
        "  # df train, val, test\n",
        "  train_df=df_supervised.iloc[0:n_train,:]\n",
        "  val_df=df_supervised.iloc[n_train:n_train+n_val,:]\n",
        "  test_df=df_supervised.iloc[n_train+n_val:,:]\n",
        "  # print(train_df.shape,val_df.shape,test_df.shape)\n",
        "  # 342 doan dau vao, moi doan la 16 dactinh\n",
        "  # bao gom 3 bien x5 buoc + bien dau ra -> 16 bien\n",
        "  # moi an doc 1 buoc \n",
        "  # bo vao 15 gia tri x so batsize de du bao gia tri 16\n",
        "\n",
        "  \"\"\"## Phan ra du lieu de train va target \"\"\"\n",
        "\n",
        "  x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "  y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "  # print(x_train.shape,y_train.shape)\n",
        "\n",
        "  x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "  y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "  # print(x_val.shape,y_val.shape)\n",
        "\n",
        "  x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "  y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "  # print(x_test.shape,y_test.shape)\n",
        "\n",
        "  ## check input_train\n",
        "  # print('input',x_train[0], 'output',y_train[0])\n",
        "  # print('df_train',train_df.iloc[0,:])\n",
        "  # gia tri output va gia tri du bao phai giong nhau\n",
        "\n",
        "  \"\"\"# Scale Max-Min data\"\"\"\n",
        "\n",
        "  # tao 2 scaler rieng cho X, Y de invert cho de\n",
        "  scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "  scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "  x_train_scale = scaler_x.fit_transform(x_train)\n",
        "  y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "  # fit scale cua train cho val va test\n",
        "  x_val_scale=scaler_x.transform(x_val)\n",
        "  y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "  x_test_scale=scaler_x.transform(x_test)\n",
        "  y_test_scale=scaler_y.transform(y_test)\n",
        "\n",
        "  \"\"\"# Tensorflow format\"\"\"\n",
        "\n",
        "  # # reshape input to be 3D [samples, timesteps, features]\n",
        "  # n_features=1\n",
        "  # train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "  # val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "  # test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "\n",
        "  # Kiem tra lai\n",
        "  n_features=1\n",
        "  train_X = x_train_scale.reshape((x_train_scale.shape[0], n_features,x_train_scale.shape[1]))\n",
        "  val_X = x_val_scale.reshape((x_val_scale.shape[0],  n_features,x_val_scale.shape[1]))\n",
        "  test_X = x_test_scale.reshape((x_test_scale.shape[0], n_features, x_test_scale.shape[1]))\n",
        "  print(['input shape output shape'])\n",
        "  print(train_X.shape,y_train_scale.shape)\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "  return train_X, y_train_scale, val_X,y_val_scale,test_X,y_test_scale,scaler_y,n_train,n_val\n",
        "#######################################################################################\n",
        "def generate_input_M3(dataset,dataset_climate,k0,n_in0,n_out0):\n",
        "  # n_window0=5\n",
        "  dataset0=dataset[k0]\n",
        "  dataset0_climate=dataset_climate[k0]\n",
        "  df_supervised0=series_to_supervised_df(dataset0,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  df_supervised0_climate=series_to_supervised_df(dataset0_climate,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "  # thay doi cac gia tri cho mo hinh khi hau\n",
        "  df_supervised0.iloc[:,[-2,-3,-4,-6,-7,-8,-10,-11,-12]]=df_supervised0_climate.iloc[:,[-2,-3,-4,-6,-7,-8,-10,-11,-12]]\n",
        "  df_supervised0_obs_cli=df_supervised0_climate # da co so lieu cua climate model o day\n",
        "  \"\"\"## loai bo cac gia tri cua NDI theo thang CH* Han\"\"\"\n",
        "  # Bo het NDI\n",
        "  drop1=np.array(range(3,df_supervised0_obs_cli.shape[1],4)) # toan bo gia tri NDI trong input\n",
        "  # print(drop1)\n",
        "\n",
        "  drop1a=drop1[:-1] # chua lai thang cuoi la thang du bao\n",
        "  # print(drop1a) \n",
        "  # # van giu lai dam lau la luc lac tai buoc t. Khong bo gi het\n",
        "  # # drop2=np.array(range(df_supervised0.shape[1]))\n",
        "  # # print(drop2)\n",
        "  # ########  QUAN TRONG\n",
        "  # ''' bo het cac bien cua NDI trong phan input (drop1)\n",
        "\n",
        "  # input cua PRS gom 2 phan:\n",
        "  # phan 1: gia tri thuc do tu dau den buoc t-1\n",
        "  # phan 2: gia tri cua mo hinh du bao tai buoc t\n",
        "  # -> giai quyet bang cach go bo cac gia tri PRS tai t\n",
        "  # thay bang cac gia tri cua mo hinh du bao tai buoc t\n",
        "  # khong can bo thang drop 2, chi can thay no ban gia tri trong mo hinh khi hau la duoc\n",
        "\n",
        "  # '''\n",
        "\n",
        "  # # drop2a=drop2[df_supervised0.shape[1]-4:df_supervised0.shape[1]-1]\n",
        "  # # print(drop2a)\n",
        "  list_drop_cols=[]\n",
        "\n",
        "  [list_drop_cols.append(drop) for drop in drop1a]\n",
        "  # # [list_drop_cols.append(drop) for drop in drop2a]\n",
        "  # # print(list_drop_cols)\n",
        "\n",
        "  # \"\"\"## Bo di bay lu khon nan\"\"\"\n",
        "\n",
        "  df_supervised=df_supervised0_obs_cli.drop(df_supervised0_obs_cli.columns[[list_drop_cols]],axis=1)\n",
        "  # df_supervised\n",
        "\n",
        "  \"\"\"# Chia du lieu theo ti le0.6:0.2:0.2\"\"\"\n",
        "\n",
        "  # chieu dai cua train\n",
        "  n_train=int(df_supervised.shape[0]*0.6)\n",
        "  # print(n_train)\n",
        "  n_val=int(df_supervised.shape[0]*0.8)-n_train\n",
        "  n_test=df_supervised.shape[0]-n_val-n_train\n",
        "  # print(n_val)\n",
        "  # print(n_test)\n",
        "\n",
        "  # df train, val, test\n",
        "  train_df=df_supervised.iloc[0:n_train,:]\n",
        "  val_df=df_supervised.iloc[n_train:n_train+n_val,:]\n",
        "  test_df=df_supervised.iloc[n_train+n_val:,:]\n",
        "  # print(train_df.shape,val_df.shape,test_df.shape)\n",
        "  # 342 doan dau vao, moi doan la 16 dactinh\n",
        "  # bao gom 3 bien x5 buoc + bien dau ra -> 16 bien\n",
        "  # moi an doc 1 buoc \n",
        "  # bo vao 15 gia tri x so batsize de du bao gia tri 16\n",
        "\n",
        "  \"\"\"## Phan ra du lieu de train va target \"\"\"\n",
        "\n",
        "  x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "  y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "  # print(x_train.shape,y_train.shape)\n",
        "\n",
        "  x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "  y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "  # print(x_val.shape,y_val.shape)\n",
        "\n",
        "  x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "  y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "  # print(x_test.shape,y_test.shape)\n",
        "\n",
        "  ## check input_train\n",
        "  # print('input',x_train[0], 'output',y_train[0])\n",
        "  # print('df_train',train_df.iloc[0,:])\n",
        "  # gia tri output va gia tri du bao phai giong nhau\n",
        "\n",
        "  \"\"\"# Scale Max-Min data\"\"\"\n",
        "\n",
        "  # tao 2 scaler rieng cho X, Y de invert cho de\n",
        "  scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "  scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "  x_train_scale = scaler_x.fit_transform(x_train)\n",
        "  y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "  # fit scale cua train cho val va test\n",
        "  x_val_scale=scaler_x.transform(x_val)\n",
        "  y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "  x_test_scale=scaler_x.transform(x_test)\n",
        "  y_test_scale=scaler_y.transform(y_test)\n",
        "\n",
        "  \"\"\"# Tensorflow format\"\"\"\n",
        "\n",
        "  # # reshape input to be 3D [samples, timesteps, features]\n",
        "  # n_features=1\n",
        "  # train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "  # val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "  # test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "\n",
        "  # Kiem tra lai\n",
        "  n_features=1\n",
        "  train_X = x_train_scale.reshape((x_train_scale.shape[0], n_features,x_train_scale.shape[1]))\n",
        "  val_X = x_val_scale.reshape((x_val_scale.shape[0],  n_features,x_val_scale.shape[1]))\n",
        "  test_X = x_test_scale.reshape((x_test_scale.shape[0], n_features, x_test_scale.shape[1]))\n",
        "  print(['input shape output shape'])\n",
        "  print(train_X.shape,y_train_scale.shape)\n",
        "  # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "  return train_X, y_train_scale, val_X,y_val_scale,test_X,y_test_scale,scaler_y,n_train,n_val\n",
        "\n",
        "#######################################################################################\n",
        "\n",
        "# RUN THEORY\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\"\"\"# 0. Change directory\"\"\"\n",
        "\n",
        "# import os\n",
        "# os.chdir('/content/drive/MyDrive/hybrid_batch')\n",
        "# # create the outputs:\n",
        "# outs=['save_models_S4M1','save_pickles_S4M1','tabs_S4M1','figs_S4M1','shps_S4M1','my_dir_S4M1'] \n",
        "# # my_dir la thu muc chua keras tunner\n",
        "# for out in outs:\n",
        "#   if not os.path.exists(out):\n",
        "#     os.makedirs(out)\n",
        "\n",
        "# k0=29\n",
        "# phase=2\n",
        "# #####\n",
        "# ## mo kiem tra lai\n",
        "# with open(outs[1]+'/'+str(k0)+'M1S4_lag5.pkl', 'rb') as f:\n",
        "#     # compressed_file = bz2.BZ2File(f, 'r')\n",
        "#     load_list_con = pickle.load(f)\n",
        "# # 0,1,2 tuong ung voi train, val, test\n",
        "# pearson,dotincay=pearsonr(load_list_con[phase]['obs'],load_list_con[phase]['pred'])\n",
        "# print('cc of test of station'+str(k0+1)+' : '+str(pearson))\n",
        "def run_theory(datatest,thrs,start0):\n",
        "  # thrs=-2.0\n",
        "  # obs_values=load_list_con[phase]['obs']\n",
        "  obs_values=datatest\n",
        "  # obs_values=load_list_con[phase]['obs'].values\n",
        "  # sim=load_list_con[phase]['pred']\n",
        "  # print(type(obs))\n",
        "  # def run_theory(data,thrs)\n",
        "  list_rainfall_all=[]\n",
        "  n_index=np.where(obs_values<=thrs)[0]\n",
        "  n_index\n",
        "  start_point=[]\n",
        "  end_point=[]\n",
        "  n_dd=[]\n",
        "  n_ss=[]\n",
        "\n",
        "  start_point.append(n_index[0]) # gia tri dau tien luon phai them vao\n",
        "  # cac gia tri bat dau o giua duoc xac dinh khi no tru cho gia tri truoc lon hon 1\n",
        "    # noi cach khac no khong lien tuc\n",
        "\n",
        "  for i in range(len(n_index)-1):\n",
        "      if n_index[i+1]-n_index[i] >1:\n",
        "        # print(n_index[i])\n",
        "        start_point.append(n_index[i+1])\n",
        "  print(start_point)\n",
        "\n",
        "  # tim duration cho tung start point. Tinh bat dau bang start point cho den khi n_index\n",
        "    # tang len khac 1, nghia la no ko con lien tuc nua\n",
        "  for i in range(len(n_index)-1):\n",
        "    if n_index[i]-n_index[i+1] <-1:\n",
        "      # print(n_index[i])\n",
        "      end_point.append(n_index[i])\n",
        "  # luon them diem cuoi cua n_index la end_point\n",
        "  end_point.append(n_index[-1])\n",
        "  print(end_point)\n",
        "  n_dd=np.array(end_point)-np.array(start_point)+1\n",
        "  # n_dd\n",
        "  # severity la tong gia tri tu bat dau 1 den ket thuc 1\n",
        "  n_se=[]\n",
        "  for i in range(len(start_point)):\n",
        "    n_se.append(obs_values[start_point[i]:end_point[i]+1].sum())\n",
        "\n",
        "  # Duration\n",
        "  n_du=[]\n",
        "  for i in range(len(start_point)):\n",
        "    n_du.append(end_point[i]-start_point[i]+1)\n",
        "  # Intensity\n",
        "  n_intensity=[]\n",
        "  for i in range(len(start_point)):\n",
        "    n_intensity.append(n_se[i]/n_du[i])\n",
        "\n",
        "  # inteval la khoang cach tu bat dau tran han nay den bat dau tran han khac.\n",
        "    # no it hon n_begin mot gia tri\n",
        "  n_interval=[]\n",
        "  n_interval.append(0)\n",
        "  for i in range(len(start_point)-1):\n",
        "    n_interval.append(start_point[i+1]-start_point[i]+1)\n",
        "\n",
        "  # xuat ket qua ra dang csv\n",
        "  df_rainfall=pd.DataFrame(columns=['begin','end','dd','ss','intens','inter'])\n",
        "  df_rainfall['begin']=start_point\n",
        "  df_rainfall['end']=end_point\n",
        "  df_rainfall['dd']=n_du\n",
        "  df_rainfall['ss']=n_se\n",
        "  df_rainfall['intens']=n_intensity\n",
        "  df_rainfall['inter']=n_interval\n",
        "  # print('ket qua cho stat at rainfall '+ str(thrs))\n",
        "  # print(df_rainfall)\n",
        "  list_rainfall_all.append('ket qua cho stat at rainfall '+ str(thrs))\n",
        "  list_rainfall_all.append(df_rainfall)\n",
        "  list_rainfall_all[1]['begin'].values\n",
        "  # plot figure\n",
        "  vector_date_test=pd.date_range(start=start0,periods=115, \n",
        "                freq='MS').strftime(\"%Y-%m\").tolist()\n",
        "  print(vector_date_test)\n",
        "  # plt.bar(vector_date_test,obs_values)\n",
        "  len(obs_values)\n",
        "  fig,ax=plt.subplots(figsize=(6,3))\n",
        "  plt.ylim([-5.9,2.29])\n",
        "  plt.bar(vector_date_test,obs_values,fill=None,lw=1)\n",
        "  # to mau cho han vi tri han\n",
        "  # ve mua mua\n",
        "  for kk in range(len(list_rainfall_all[1]['begin'].values)):\n",
        "    ax.axvspan(xmin=list_rainfall_all[1]['begin'].values[kk], \n",
        "              xmax=list_rainfall_all[1]['end'].values[kk], \n",
        "              ymin=0, \n",
        "              ymax=1,\n",
        "              color='red',\n",
        "              alpha=0.2)\n",
        "  plt.xticks(list_rainfall_all[1]['begin'].values)\n",
        "  plt.hlines(thrs,xmin=0,xmax=len(obs_values),linestyles='--',lw=1,color='blue')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.ylabel('NDI')\n",
        "  return list_rainfall_all\n",
        "############################################################\n",
        "\n",
        "## ROC PLOT\n",
        "def roc_plot(load_list_con,phase,thrs):\n",
        "  from itertools import cycle\n",
        "  # thrs=-1.0\n",
        "  from sklearn import svm, datasets\n",
        "  from sklearn.metrics import roc_curve, auc\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.preprocessing import label_binarize\n",
        "  from sklearn.multiclass import OneVsRestClassifier\n",
        "  from scipy import interp\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  roc_df=pd.DataFrame(columns=['obs','pred','cls_obs','cls_pred'])\n",
        "  roc_df['obs']=load_list_con[phase]['obs']\n",
        "  for i in range(roc_df.shape[0]):\n",
        "    if roc_df['obs'][i]<=thrs:\n",
        "      roc_df['cls_obs'][i]=1\n",
        "    if roc_df['obs'][i]> thrs:\n",
        "      roc_df['cls_obs'][i]=0\n",
        "  roc_df['pred']=load_list_con[phase]['pred']\n",
        "  for i in range(roc_df.shape[0]):\n",
        "    if roc_df['pred'][i]<=thrs:\n",
        "      roc_df['cls_pred'][i]=1\n",
        "    if roc_df['pred'][i]> thrs:\n",
        "      roc_df['cls_pred'][i]=0\n",
        "\n",
        "  # tinh dung sai cho moi loai. O day co 2 loai thoi\n",
        "  # Compute ROC curve and ROC area for each class\n",
        "  a=roc_df['cls_obs'].to_list()\n",
        "  # print(a)\n",
        "  b=roc_df['cls_pred'].to_list()\n",
        "  # print(b)\n",
        "  tn, fp, fn, tp = confusion_matrix(a, b).ravel()\n",
        "  (tn, fp, fn, tp)\n",
        "  # fig,ax=plt.subplots(figsize=(3,3))\n",
        "  from mlxtend.plotting import plot_confusion_matrix\n",
        "  fig=plt.figure(figsize=(3, 3))\n",
        "  plot_confusion_matrix(confusion_matrix(a, b))\n",
        "  plt.xlabel('Predictions', fontsize=12)\n",
        "  plt.ylabel('Actuals', fontsize=12)\n",
        "  plt.title('Confusion Matrix', fontsize=12)\n",
        "  plt.show()\n",
        "  plt.close(fig)\n",
        "\n",
        "  ######\n",
        "  roc_values = []\n",
        "  for thresh in np.linspace(0, 1, 100):\n",
        "      # preds = get_preds(thresh, probas)\n",
        "      tn, fp, fn, tp = confusion_matrix(b,a).ravel()\n",
        "      tpr = tp/(tp+fn)\n",
        "      fpr = fp/(fp+tn)\n",
        "      roc_values.append([tpr, fpr])\n",
        "  tpr_values, fpr_values = zip(*roc_values)\n",
        "\n",
        "  # ### \n",
        "  # fig, ax = plt.subplots(figsize=(5,5))\n",
        "  # ax.plot(fpr_values, tpr_values)\n",
        "  # ax.plot(np.linspace(0, 1, 100),\n",
        "  #          np.linspace(0, 1, 100),\n",
        "  #          label='baseline',\n",
        "  #          linestyle='--')\n",
        "  # plt.title('Receiver Operating Characteristic Curve', fontsize=18)\n",
        "  # plt.ylabel('TPR', fontsize=16)\n",
        "  # plt.xlabel('FPR', fontsize=16)\n",
        "  # plt.legend(fontsize=12);\n",
        "  # plt.close(fig)\n",
        "\n",
        "  ######\n",
        "  from sklearn import metrics\n",
        "  y_test=b\n",
        "  y_pred=a\n",
        "  auc = metrics.roc_auc_score(y_test, y_pred)\n",
        "  roc = metrics.recall_score(y_test, y_pred)\n",
        "  accuracy=metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "  false_positive_rate, true_positive_rate, thresolds = metrics.roc_curve(y_test, y_pred)\n",
        "\n",
        "  # # plt.figure(figsize=(3, 3), dpi=80)\n",
        "  # fig,ax=plt.subplots(figsize=(3,3))\n",
        "  plt.figure(figsize=(6, 3))\n",
        "  plt.axis('scaled')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  # plt.title(\"AUC & ROC Curve of spatial extreme drought prediction\")\n",
        "  plt.plot(false_positive_rate, true_positive_rate, 'k')\n",
        "  plt.text(0.95, 0.05, 'AUC = %0.2f' % auc, ha='right', fontsize=12, weight='bold', color='black')\n",
        "  plt.text(0.95, 0.2, 'accuracy = %0.2f' % accuracy, ha='right', fontsize=12, weight='bold', color='black')\n",
        "\n",
        "  plt.fill_between(false_positive_rate, true_positive_rate, facecolor='lightgrey', alpha=0.5)\n",
        "\n",
        "  plt.plot(np.linspace(0, 1, 100),\n",
        "          np.linspace(0, 1, 100),\n",
        "          #  label='baseline',\n",
        "          linestyle='--')\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.legend(fontsize=12);\n",
        "  # plt.show()\n",
        "  plt.tight_layout()\n",
        "  # plt.savefig('out_fig/ROC.png')\n",
        "  plt.close(fig)\n",
        "\n",
        "# \"\"\"# Kiem tra cac functions\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "# # load data obs\n",
        "# with open('input_pickles'+'/'+'PRS3_NDI3_59.pkl', 'rb') as f:\n",
        "#     # compressed_file = bz2.BZ2File(f, 'r')\n",
        "#     load_PRS3_NDI3_59 = pickle.load(f)\n",
        "\n",
        "# with open('input_pickles'+'/'+'PRS3_NDI3_59_pseudo.pkl', 'rb') as f_c:\n",
        "#     # compressed_file = bz2.BZ2File(f, 'r')\n",
        "#     load_PRS3_NDI3_59_cli = pickle.load(f_c)\n",
        "\n",
        "\n",
        "\n",
        "# # check ganghwa 29\n",
        "# # for k0 in range(59):\n",
        "# k0=29 # Mo phong cho tram ganghwa\n",
        "# dataset=load_PRS3_NDI3_59\n",
        "# dataset_climate=load_PRS3_NDI3_59_cli\n",
        "\n",
        "# n_in0, n_out0=5,2\n",
        "# dataset0=dataset[k0]\n",
        "# dataset0_climate=dataset_climate[k0]\n",
        "# df_supervised0=series_to_supervised_df(dataset0,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "# df_supervised0_climate=series_to_supervised_df(dataset0_climate,n_in=n_in0,n_out=n_out0)\n",
        "\n",
        "# # thay doi cac gia tri cho mo hinh khi hau\n",
        "# df_supervised0.iloc[:,[-2,-3,-4,-6,-7,-8]]=df_supervised0_climate.iloc[:,[-2,-3,-4,-6,-7,-8]]\n",
        "# df_supervised0_obs_cli=df_supervised0_climate # da co so lieu cua climate model o day\n",
        "# \"\"\"## loai bo cac gia tri cua NDI theo thang CH* Han\"\"\"\n",
        "# # Bo het NDI\n",
        "# drop1=np.array(range(3,df_supervised0_obs_cli.shape[1],4)) # toan bo gia tri NDI trong input\n",
        "# # print(drop1)\n",
        "\n",
        "# drop1a=drop1[:-1] # chua lai thang cuoi la thang du bao\n",
        "# # print(drop1a) \n",
        "# # # van giu lai dam lau la luc lac tai buoc t. Khong bo gi het\n",
        "# # # drop2=np.array(range(df_supervised0.shape[1]))\n",
        "# # # print(drop2)\n",
        "# # ########  QUAN TRONG\n",
        "# # ''' bo het cac bien cua NDI trong phan input (drop1)\n",
        "\n",
        "# # input cua PRS gom 2 phan:\n",
        "# # phan 1: gia tri thuc do tu dau den buoc t-1\n",
        "# # phan 2: gia tri cua mo hinh du bao tai buoc t\n",
        "# # -> giai quyet bang cach go bo cac gia tri PRS tai t\n",
        "# # thay bang cac gia tri cua mo hinh du bao tai buoc t\n",
        "# # khong can bo thang drop 2, chi can thay no ban gia tri trong mo hinh khi hau la duoc\n",
        "\n",
        "# # '''\n",
        "\n",
        "# # # drop2a=drop2[df_supervised0.shape[1]-4:df_supervised0.shape[1]-1]\n",
        "# # # print(drop2a)\n",
        "# list_drop_cols=[]\n",
        "\n",
        "# [list_drop_cols.append(drop) for drop in drop1a]\n",
        "# # # [list_drop_cols.append(drop) for drop in drop2a]\n",
        "# # # print(list_drop_cols)\n",
        "\n",
        "# # \"\"\"## Bo di bay lu khon nan\"\"\"\n",
        "\n",
        "# df_supervised=df_supervised0_obs_cli.drop(df_supervised0_obs_cli.columns[[list_drop_cols]],axis=1)\n",
        "# # df_supervised\n",
        "\n",
        "# \"\"\"# Chia du lieu theo ti le0.6:0.2:0.2\"\"\"\n",
        "\n",
        "# # chieu dai cua train\n",
        "# n_train=int(df_supervised.shape[0]*0.6)\n",
        "# # print(n_train)\n",
        "# n_val=int(df_supervised.shape[0]*0.8)-n_train\n",
        "# n_test=df_supervised.shape[0]-n_val-n_train\n",
        "# # print(n_val)\n",
        "# # print(n_test)\n",
        "\n",
        "# # df train, val, test\n",
        "# train_df=df_supervised.iloc[0:n_train,:]\n",
        "# val_df=df_supervised.iloc[n_train:n_train+n_val,:]\n",
        "# test_df=df_supervised.iloc[n_train+n_val:,:]\n",
        "# # print(train_df.shape,val_df.shape,test_df.shape)\n",
        "# # 342 doan dau vao, moi doan la 16 dactinh\n",
        "# # bao gom 3 bien x5 buoc + bien dau ra -> 16 bien\n",
        "# # moi an doc 1 buoc \n",
        "# # bo vao 15 gia tri x so batsize de du bao gia tri 16\n",
        "\n",
        "# \"\"\"## Phan ra du lieu de train va target \"\"\"\n",
        "\n",
        "# x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "# y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "# # print(x_train.shape,y_train.shape)\n",
        "\n",
        "# x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "# y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "# # print(x_val.shape,y_val.shape)\n",
        "\n",
        "# x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "# y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "# # print(x_test.shape,y_test.shape)\n",
        "\n",
        "# ## check input_train\n",
        "# # print('input',x_train[0], 'output',y_train[0])\n",
        "# # print('df_train',train_df.iloc[0,:])\n",
        "# # gia tri output va gia tri du bao phai giong nhau\n",
        "\n",
        "# \"\"\"# Scale Max-Min data\"\"\"\n",
        "\n",
        "# # tao 2 scaler rieng cho X, Y de invert cho de\n",
        "# scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "# scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "# x_train_scale = scaler_x.fit_transform(x_train)\n",
        "# y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "# # fit scale cua train cho val va test\n",
        "# x_val_scale=scaler_x.transform(x_val)\n",
        "# y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "# x_test_scale=scaler_x.transform(x_test)\n",
        "# y_test_scale=scaler_y.transform(y_test)\n",
        "\n",
        "# \"\"\"# Tensorflow format\"\"\"\n",
        "\n",
        "# # # reshape input to be 3D [samples, timesteps, features]\n",
        "# # n_features=1\n",
        "# # train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "# # val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "# # test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "# # print(train_X.shape,y_train_scale.shape,val_X.shape,y_val_scale.shape)\n",
        "\n",
        "# # Kiem tra lai\n",
        "# n_features=1\n",
        "# train_X = x_train_scale.reshape((x_train_scale.shape[0], n_features,x_train_scale.shape[1]))\n",
        "# val_X = x_val_scale.reshape((x_val_scale.shape[0],  n_features,x_val_scale.shape[1]))\n",
        "# test_X = x_test_scale.reshape((x_test_scale.shape[0], n_features, x_test_scale.shape[1]))\n",
        "# print(['input shape output shape'])\n",
        "# print(train_X.shape,y_train_scale.shape)\n",
        "\n",
        "# run_theory(load_list_con[phase]['obs'].values,-1)\n",
        "# =============================================================================\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRBWN8dtpcF9",
        "outputId": "30fc7eff-3fc5-46b9-ccca-f6332bde1396"
      },
      "source": [
        "\n",
        "# Load du lieu\n",
        "# load data obs\n",
        "with open('input_pickles'+'/'+'PRS3_NDI3_59new.pkl', 'rb') as f1:\n",
        "    # compressed_file = bz2.BZ2File(f, 'r')\n",
        "    PRS3_NDI3_59 = pickle.load(f1)\n",
        "    \n",
        "# kiem tra cho ganghwa\n",
        "k=29\n",
        "n_in0=3\n",
        "n_out0=1\n",
        "m=n_out0 # tinh cho buoc 0\n",
        "df0=PRS3_NDI3_59[k] # 1968-2020\n",
        "# chia du lieu cho 12 lay 6 phan cho train, 3 phan cho val, 3 phan cho test\n",
        "df1=df0.iloc[:(2016-1968+1)*12,:]\n",
        "# df1=df0 # du bao het\n",
        "# =============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "# Chuyen qua suppervised. Chon n_out0=3, n_in0=1 da kiem tra do khong mat so cuoi\n",
        "# no chi mat so dau\n",
        "# def sample_generate_M3(dataset,n_in0,n_out0):\n",
        "df2=series_to_supervised_df(df1,n_in0,n_out0)\n",
        "\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "#     remove values PRS  at fure prediction\n",
        "# var3(t),var2(t),var1(t) have to remove\n",
        "list_drops=[np.arange(2,5)*-1,np.arange(2,9)*-1,np.arange(2,13)*-1]\n",
        "list_drops1=[[],[],[]]\n",
        "list_drops1a=[[-5,-9,-13],[-5,-9,-13,-17],[-5,-9,-13,-17,-21]]\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "df3=df2.drop(df2.columns[[list_drops1[n_out0-1]]],axis=1)\n",
        "df4=df3.drop(df3.columns[[list_drops1a[n_out0-1]]],axis=1)\n",
        "\n",
        "# =============================================================================\n",
        "# Chia du lieu theo ti le 6:3:3\n",
        "n_train=int(df4.shape[0]*0.6)\n",
        "n_val=int(df4.shape[0]*0.8)-n_train\n",
        "n_test=df4.shape[0]-n_val-n_train\n",
        "\n",
        "train_df=df4.iloc[0:n_train,:]\n",
        "val_df=df4.iloc[n_train:n_train+n_val,:]\n",
        "test_df=df4.iloc[n_train+n_val:,:]\n",
        "# print(train_df.shape,val_df.shape,test_df.shape)\n",
        "x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "# lay chinh no du bao no luon\n",
        "# x_train,y_train0=train_df.iloc[:,:].values,train_df.iloc[:,-1].values # KIEM TRA DU BAO CHO CHINH NO\n",
        "y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "# print(x_train.shape,y_train.shape)\n",
        "\n",
        "x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "# x_val,y_val0=val_df.iloc[:,:].values,val_df.iloc[:,-1].values #  KIEM TRA DU BAO CHO CHINH NO\n",
        "y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "# print(x_val.shape,y_val.shape)\n",
        "\n",
        "x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "\n",
        "# x_test,y_test0=test_df.iloc[:,:].values,test_df.iloc[:,-1].values # KIEM TRA DU BAO CHO CHINH NO\n",
        "y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "# print(x_test.shape,y_test.shape)\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Scale data\n",
        "# tao 2 scaler rieng cho X, Y de invert cho de\n",
        "scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "x_train_scale = scaler_x.fit_transform(x_train)\n",
        "y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "# fit scale cua train cho val va test\n",
        "x_val_scale=scaler_x.transform(x_val)\n",
        "y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "x_test_scale=scaler_x.transform(x_test)\n",
        "y_test_scale=scaler_y.transform(y_test)\n",
        "n_features=1\n",
        "train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "\n",
        "    \n",
        "    # return train_X, y_train_scale, val_X,y_val_scale,test_X,y_test_scale,scaler_y,n_train,n_val\n",
        "\n",
        "# Chuyen qua dinh danh cua 3D tensorflow: sample, timesteps, feature\n",
        "# Kiem tra lai trong sach \n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py:4114: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jex8ePoffXs4"
      },
      "source": [
        "# Define model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bnd2QZq0fd85",
        "outputId": "6cf7c58e-1643-4ce5-ada8-4431725ea65e"
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, activation='relu', return_sequences=False, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "# =============================================================================\n",
        "opt = Adam(learning_rate = 0.0009, clipnorm = 1.00)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "callbacks_list = [\n",
        "keras.callbacks.EarlyStopping(\n",
        "monitor=\"val_loss\",\n",
        "patience=400,\n",
        "mode=\"min\",\n",
        "),\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=outs[0]+\"/\"+str(k)+\"lead\"+str(m)+\"best_stop.keras\", # cong them buoc thoi gian\n",
        "monitor=\"val_loss\",\n",
        "save_best_only=True,\n",
        ")\n",
        "]\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate = 0.00095, clipnorm = 1.001),\n",
        "loss=\"mse\",\n",
        "metrics=[\"mse\"])\n",
        "# Fit model\n",
        "\n",
        "history1=model.fit(train_X,\n",
        "          y_train_scale,\n",
        "epochs=1500,\n",
        "callbacks=callbacks_list,\n",
        "validation_data=(val_X,y_val_scale))\n",
        "# =============================================================================\n",
        "# # Save loss values\n",
        "# with open(outs[1]+'/'+str(k)+'lead'+str(m)+'T3_lag3loss.csv', 'wb') as f1: # khong nen\n",
        "#   # compressed_file = bz2.BZ2File(f, 'w')\n",
        "#     w = csv.DictWriter(f1, history1.history.keys())\n",
        "#     w.writeheader()\n",
        "#     w.writerow(history1)\n",
        "\n",
        "# # #####\n",
        "# ## mo kiem tra lai\n",
        "# with open(outs[1]+'/'+str(k)+'lead'+str(m)+'T3_lag3loss.csv', 'rb') as f2: # khong nen\n",
        "#     # compressed_file = bz2.BZ2File(f, 'r')\n",
        "#     load_history1 = csv.DictReader(f2)\n",
        "# # 0,1,2 tuong ung voi train, val, test\n",
        "# # pearson,dotincay=pearsonr(load_list_con[1]['obs'],load_list_con[1]['pred'])\n",
        "# # print('cc of val: '+str(pearson))\n",
        "# =============================================================================\n",
        "# LOAD KET QUA TOT NHAT\n",
        "# =============================================================================\n",
        "# Load results\n",
        "loaded_model=load_model(outs[0]+\"/\"+str(k)+\"lead\"+str(m)+\"best_stop.keras\")\n",
        "print(\"Loaded model from disk\")\n",
        "\n",
        "# =============================================================================\n",
        "# DANH GIA\n",
        "# =============================================================================\n",
        "# TONG KET \n",
        "# ve learning rate to load model\n",
        "#Check the Loss curve\n",
        "fig,ax=plt.subplots(figsize=(6,3))\n",
        "plt.rcParams.update({'font.size': 11})\n",
        "plt.plot(history1.history['loss'])\n",
        "plt.plot(history1.history['val_loss'])\n",
        "# Draw the minimum epochs \n",
        "df_val_loss=pd.DataFrame({'val_loss':history1.history['val_loss']})\n",
        "# print(df_val_loss)\n",
        "idxmin=df_val_loss[['val_loss']].idxmin().values\n",
        "val_loss_min_values=df_val_loss.loc[idxmin,:].values.flatten()\n",
        "print(idxmin,val_loss_min_values)\n",
        "plt.annotate('epochs at min_val_loss: '+str(idxmin[0]+1)+'\\n'+'min_val_loss: '+str(np.round(val_loss_min_values[0],3)),\n",
        "             xy=(idxmin,val_loss_min_values), xycoords='data',\n",
        "            xytext=(idxmin-50, val_loss_min_values+0.02), textcoords='data',\n",
        "            arrowprops=dict(arrowstyle=\"->\",\n",
        "                            connectionstyle=\"arc3\"),\n",
        "            )\n",
        "\n",
        "plt.legend(['train','val'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('mse')\n",
        "# plt.title('learning rate of 1 month leadtime prdiction')\n",
        "plt.tight_layout()\n",
        "plt.savefig(outs[3]+'/'+str(k)+'loss_curve_T3'+str(m)+'.jpeg',dpi=300)\n",
        "plt.show(fig)\n",
        "plt.close(fig)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "11/11 [==============================] - 2s 38ms/step - loss: 0.1991 - mse: 0.1991 - val_loss: 0.1864 - val_mse: 0.1864\n",
            "Epoch 2/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.1324 - mse: 0.1324 - val_loss: 0.1094 - val_mse: 0.1094\n",
            "Epoch 3/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0694 - mse: 0.0694 - val_loss: 0.0444 - val_mse: 0.0444\n",
            "Epoch 4/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0388 - val_mse: 0.0388\n",
            "Epoch 5/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0337 - val_mse: 0.0337\n",
            "Epoch 6/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0346 - mse: 0.0346 - val_loss: 0.0340 - val_mse: 0.0340\n",
            "Epoch 7/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.0323 - val_mse: 0.0323\n",
            "Epoch 8/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0316 - val_mse: 0.0316\n",
            "Epoch 9/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 10/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0302 - val_mse: 0.0302\n",
            "Epoch 11/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.0298 - val_mse: 0.0298\n",
            "Epoch 12/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0314 - mse: 0.0314 - val_loss: 0.0291 - val_mse: 0.0291\n",
            "Epoch 13/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.0285 - val_mse: 0.0285\n",
            "Epoch 14/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.0279 - val_mse: 0.0279\n",
            "Epoch 15/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0274 - val_mse: 0.0274\n",
            "Epoch 16/1500\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0303 - mse: 0.0303 - val_loss: 0.0268 - val_mse: 0.0268\n",
            "Epoch 17/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0260 - val_mse: 0.0260\n",
            "Epoch 18/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.0250 - val_mse: 0.0250\n",
            "Epoch 19/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 20/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0233 - val_mse: 0.0233\n",
            "Epoch 21/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0282 - mse: 0.0282 - val_loss: 0.0225 - val_mse: 0.0225\n",
            "Epoch 22/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 23/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0208 - val_mse: 0.0208\n",
            "Epoch 24/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0191 - val_mse: 0.0191\n",
            "Epoch 25/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0200 - val_mse: 0.0200\n",
            "Epoch 26/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0178 - val_mse: 0.0178\n",
            "Epoch 27/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0170 - val_mse: 0.0170\n",
            "Epoch 28/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0172 - val_mse: 0.0172\n",
            "Epoch 29/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.0169 - val_mse: 0.0169\n",
            "Epoch 30/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 31/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0181 - val_mse: 0.0181\n",
            "Epoch 32/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0166 - val_mse: 0.0166\n",
            "Epoch 33/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0293 - val_mse: 0.0293\n",
            "Epoch 34/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 35/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0212 - val_mse: 0.0212\n",
            "Epoch 36/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0224 - val_mse: 0.0224\n",
            "Epoch 37/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 38/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0243 - val_mse: 0.0243\n",
            "Epoch 39/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0266 - val_mse: 0.0266\n",
            "Epoch 40/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0196 - val_mse: 0.0196\n",
            "Epoch 41/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0181 - val_mse: 0.0181\n",
            "Epoch 42/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0173 - val_mse: 0.0173\n",
            "Epoch 43/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 44/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0207 - val_mse: 0.0207\n",
            "Epoch 45/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 46/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 47/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 48/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 49/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 50/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 51/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 52/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 53/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0196 - val_mse: 0.0196\n",
            "Epoch 54/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 55/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0215 - val_mse: 0.0215\n",
            "Epoch 56/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0156 - val_mse: 0.0156\n",
            "Epoch 57/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0152 - val_mse: 0.0152\n",
            "Epoch 58/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 59/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 60/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 61/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 62/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 63/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 64/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 65/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 66/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 67/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0183 - val_mse: 0.0183\n",
            "Epoch 68/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 69/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0177 - val_mse: 0.0177\n",
            "Epoch 70/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 71/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 72/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0156 - val_mse: 0.0156\n",
            "Epoch 73/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 74/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 75/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 76/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 77/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 78/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 79/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 80/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 81/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 82/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0179 - val_mse: 0.0179\n",
            "Epoch 83/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 84/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 85/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 86/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 87/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 88/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0221 - val_mse: 0.0221\n",
            "Epoch 89/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 90/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0156 - val_mse: 0.0156\n",
            "Epoch 91/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 92/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 93/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 94/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 95/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 96/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 97/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 98/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 99/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 100/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0178 - val_mse: 0.0178\n",
            "Epoch 101/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 102/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0156 - val_mse: 0.0156\n",
            "Epoch 103/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 104/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0167 - val_mse: 0.0167\n",
            "Epoch 105/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 106/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 107/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0162 - val_mse: 0.0162\n",
            "Epoch 108/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0191 - val_mse: 0.0191\n",
            "Epoch 109/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 110/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 111/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 112/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 113/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0190 - val_mse: 0.0190\n",
            "Epoch 114/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 115/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0192 - val_mse: 0.0192\n",
            "Epoch 116/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 117/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0167 - val_mse: 0.0167\n",
            "Epoch 118/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0179 - val_mse: 0.0179\n",
            "Epoch 119/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 120/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 121/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 122/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 123/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 124/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 125/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0185 - val_mse: 0.0185\n",
            "Epoch 126/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 127/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0213 - val_mse: 0.0213\n",
            "Epoch 128/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 129/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0166 - val_mse: 0.0166\n",
            "Epoch 130/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0223 - val_mse: 0.0223\n",
            "Epoch 131/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0230 - val_mse: 0.0230\n",
            "Epoch 132/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0189 - val_mse: 0.0189\n",
            "Epoch 133/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0246 - val_mse: 0.0246\n",
            "Epoch 134/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0180 - val_mse: 0.0180\n",
            "Epoch 135/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0197 - val_mse: 0.0197\n",
            "Epoch 136/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 137/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0183 - val_mse: 0.0183\n",
            "Epoch 138/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 139/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 140/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 141/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0164 - val_mse: 0.0164\n",
            "Epoch 142/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0166 - val_mse: 0.0166\n",
            "Epoch 143/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0177 - val_mse: 0.0177\n",
            "Epoch 144/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 145/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 146/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 147/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 148/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 149/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0160 - val_mse: 0.0160\n",
            "Epoch 150/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 151/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0166 - val_mse: 0.0166\n",
            "Epoch 152/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 153/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 154/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 155/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0189 - val_mse: 0.0189\n",
            "Epoch 156/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 157/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 158/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 159/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 160/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 161/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 162/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 163/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0190 - val_mse: 0.0190\n",
            "Epoch 164/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 165/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 166/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0160 - val_mse: 0.0160\n",
            "Epoch 167/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 168/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0189 - val_mse: 0.0189\n",
            "Epoch 169/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 170/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 171/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 172/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 173/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0179 - val_mse: 0.0179\n",
            "Epoch 174/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 175/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 176/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 177/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 178/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0200 - val_mse: 0.0200\n",
            "Epoch 179/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 180/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 181/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 182/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 183/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0219 - val_mse: 0.0219\n",
            "Epoch 184/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 185/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 186/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 187/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0180 - val_mse: 0.0180\n",
            "Epoch 188/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 189/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 190/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 191/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0173 - val_mse: 0.0173\n",
            "Epoch 192/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0169 - val_mse: 0.0169\n",
            "Epoch 193/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 194/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0170 - val_mse: 0.0170\n",
            "Epoch 195/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 196/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0186 - val_mse: 0.0186\n",
            "Epoch 197/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 198/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 199/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 200/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0160 - val_mse: 0.0160\n",
            "Epoch 201/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 202/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0198 - val_mse: 0.0198\n",
            "Epoch 203/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 204/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 205/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 206/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 207/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0169 - val_mse: 0.0169\n",
            "Epoch 208/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 209/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 210/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 211/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0175 - val_mse: 0.0175\n",
            "Epoch 212/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 213/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 214/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 215/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 216/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 217/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 218/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0189 - val_mse: 0.0189\n",
            "Epoch 219/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 220/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 221/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 222/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 223/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 224/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 225/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0164 - val_mse: 0.0164\n",
            "Epoch 226/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 227/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0162 - val_mse: 0.0162\n",
            "Epoch 228/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 229/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0167 - val_mse: 0.0167\n",
            "Epoch 230/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 231/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 232/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0167 - val_mse: 0.0167\n",
            "Epoch 233/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 234/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0168 - val_mse: 0.0168\n",
            "Epoch 235/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 236/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 237/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0183 - val_mse: 0.0183\n",
            "Epoch 238/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 239/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 240/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 241/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 242/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 243/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0172 - val_mse: 0.0172\n",
            "Epoch 244/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0172 - val_mse: 0.0172\n",
            "Epoch 245/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 246/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 247/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 248/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 249/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 250/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 251/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 252/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0173 - val_mse: 0.0173\n",
            "Epoch 253/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 254/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 255/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 256/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 257/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0155 - val_mse: 0.0155\n",
            "Epoch 258/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 259/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0164 - val_mse: 0.0164\n",
            "Epoch 260/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 261/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 262/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 263/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 264/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 265/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 266/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 267/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 268/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 269/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 270/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 271/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 272/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0179 - val_mse: 0.0179\n",
            "Epoch 273/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 274/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 275/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 276/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 277/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 278/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 279/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0179 - val_mse: 0.0179\n",
            "Epoch 280/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 281/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 282/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 283/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 284/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 285/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 286/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 287/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 288/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 289/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 290/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 291/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 292/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 293/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 294/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 295/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 296/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 297/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 298/1500\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 299/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0162 - val_mse: 0.0162\n",
            "Epoch 300/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 301/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 302/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 303/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 304/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0185 - val_mse: 0.0185\n",
            "Epoch 305/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 306/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 307/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 308/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 309/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0170 - val_mse: 0.0170\n",
            "Epoch 310/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 311/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 312/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 313/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 314/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 315/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 316/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0177 - val_mse: 0.0177\n",
            "Epoch 317/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 318/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 319/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 320/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 321/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 322/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 323/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 324/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 325/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 326/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 327/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 328/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 329/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 330/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 331/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 332/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 333/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 334/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 335/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 336/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 337/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 338/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 339/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 340/1500\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 341/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 342/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 343/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 344/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 345/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 346/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 347/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 348/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 349/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 350/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 351/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 352/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 353/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 354/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0152 - val_mse: 0.0152\n",
            "Epoch 355/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 356/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 357/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 358/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 359/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 360/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 361/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 362/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 363/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 364/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 365/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 366/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 367/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 368/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 369/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 370/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 371/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 372/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 373/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 374/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 375/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 376/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 377/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 378/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 379/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 380/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 381/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 382/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 383/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 384/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 385/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 386/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 387/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 388/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 389/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 390/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 391/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 392/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 393/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 394/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 395/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 396/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 397/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 398/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 399/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 400/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 401/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 402/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 403/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 404/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 405/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 406/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 407/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 408/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0164 - val_mse: 0.0164\n",
            "Epoch 409/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 410/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 411/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 412/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 413/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 414/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 415/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 416/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 417/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 418/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 419/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 420/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 421/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 422/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 423/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 424/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0183 - val_mse: 0.0183\n",
            "Epoch 425/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 426/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 427/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 428/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 429/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 430/1500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 431/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 432/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 433/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 434/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 435/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0164 - val_mse: 0.0164\n",
            "Epoch 436/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 437/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 438/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 439/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 440/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 441/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 442/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 443/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 444/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 445/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 446/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 447/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 448/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 449/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 450/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 451/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 452/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0172 - val_mse: 0.0172\n",
            "Epoch 453/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 454/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 455/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 456/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 457/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 458/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 459/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 460/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 461/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 462/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 463/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 464/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 465/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 466/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 467/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 468/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 469/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 470/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 471/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 472/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 473/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 474/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 475/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 476/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 477/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 478/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 479/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0165 - val_mse: 0.0165\n",
            "Epoch 480/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 481/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 482/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 483/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 484/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 485/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 486/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 487/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 488/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 489/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 490/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 491/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 492/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 493/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 494/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 495/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 496/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 497/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 498/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 499/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 500/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 501/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 502/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 503/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 504/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 505/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 506/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 507/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0182 - val_mse: 0.0182\n",
            "Epoch 508/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 509/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 510/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 511/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 512/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 513/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 514/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 515/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 516/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 517/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 518/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 519/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 520/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 521/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 522/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 523/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 524/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 525/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 526/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 527/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 528/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 529/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 530/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 531/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 532/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 533/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 534/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 535/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 536/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 537/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 538/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 539/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 540/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 541/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 542/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 543/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 544/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 545/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0166 - val_mse: 0.0166\n",
            "Epoch 546/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 547/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 548/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 549/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0152 - val_mse: 0.0152\n",
            "Epoch 550/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 551/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 552/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 553/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 554/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 555/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 556/1500\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0091 - val_mse: 0.0091\n",
            "Epoch 557/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 558/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 559/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 560/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 561/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 562/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 563/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 564/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 565/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 566/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 567/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 568/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 569/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 570/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 571/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 572/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 573/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 574/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 575/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 576/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 577/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 578/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 579/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 580/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 581/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 582/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 583/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 584/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 585/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 586/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 587/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 588/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 589/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 590/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 591/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 592/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 593/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 594/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 595/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 596/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 597/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 598/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 599/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 600/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 601/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 602/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 603/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 604/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 605/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0183 - val_mse: 0.0183\n",
            "Epoch 606/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 607/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 608/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 609/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 610/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 611/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 612/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 613/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 614/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 615/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 616/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 617/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 618/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 619/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 620/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 621/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0186 - val_mse: 0.0186\n",
            "Epoch 622/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 623/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 624/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 625/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 626/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 627/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 628/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 629/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 630/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 631/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 632/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 633/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 634/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 635/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 636/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 637/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 638/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 639/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 640/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 641/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 642/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 643/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 644/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 645/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 646/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 647/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 648/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0146 - val_mse: 0.0146\n",
            "Epoch 649/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 650/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 651/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 652/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0150 - val_mse: 0.0150\n",
            "Epoch 653/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 654/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 655/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 656/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0171 - val_mse: 0.0171\n",
            "Epoch 657/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 658/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 659/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 660/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 661/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 662/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 663/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 664/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 665/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 666/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 667/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 668/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 669/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 670/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0156 - val_mse: 0.0156\n",
            "Epoch 671/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 672/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 673/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 674/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 675/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 676/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 677/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 678/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0158 - val_mse: 0.0158\n",
            "Epoch 679/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 680/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 681/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 682/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 683/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 684/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0151 - val_mse: 0.0151\n",
            "Epoch 685/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 686/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 687/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 688/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 689/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 690/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 691/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 692/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0143 - val_mse: 0.0143\n",
            "Epoch 693/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 694/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 695/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 696/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0152 - val_mse: 0.0152\n",
            "Epoch 697/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0161 - val_mse: 0.0161\n",
            "Epoch 698/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 699/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 700/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 701/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 702/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 703/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 704/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 705/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0162 - val_mse: 0.0162\n",
            "Epoch 706/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 707/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 708/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0177 - val_mse: 0.0177\n",
            "Epoch 709/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 710/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 711/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 712/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 713/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 714/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 715/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 716/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 717/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 718/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 719/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 720/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 721/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 722/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 723/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 724/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 725/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0196 - val_mse: 0.0196\n",
            "Epoch 726/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 727/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 728/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 729/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 730/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0182 - val_mse: 0.0182\n",
            "Epoch 731/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 732/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 733/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 734/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 735/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 736/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 737/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 738/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 739/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0147 - val_mse: 0.0147\n",
            "Epoch 740/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 741/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 742/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 743/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 744/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0167 - val_mse: 0.0167\n",
            "Epoch 745/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 746/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 747/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 748/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0097 - val_mse: 0.0097\n",
            "Epoch 749/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 750/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 751/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0162 - val_mse: 0.0162\n",
            "Epoch 752/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 753/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 754/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 755/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 756/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 757/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 758/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 759/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 760/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 761/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 762/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 763/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 764/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0156 - val_mse: 0.0156\n",
            "Epoch 765/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 766/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 767/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0107 - val_mse: 0.0107\n",
            "Epoch 768/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 769/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 770/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 771/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 772/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 773/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 774/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 775/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 776/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 777/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0103 - val_mse: 0.0103\n",
            "Epoch 778/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0163 - val_mse: 0.0163\n",
            "Epoch 779/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 780/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 781/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 782/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 783/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 784/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 785/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 786/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 787/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 788/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 789/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 790/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 791/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 792/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 793/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 794/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 795/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 796/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0156 - val_mse: 0.0156\n",
            "Epoch 797/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 798/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 799/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 800/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 801/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 802/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 803/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0148 - val_mse: 0.0148\n",
            "Epoch 804/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 805/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 806/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 807/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 808/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 809/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0138 - val_mse: 0.0138\n",
            "Epoch 810/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0154 - val_mse: 0.0154\n",
            "Epoch 811/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 812/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 813/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 814/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 815/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0105 - val_mse: 0.0105\n",
            "Epoch 816/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 817/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 818/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 819/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 820/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0106 - val_mse: 0.0106\n",
            "Epoch 821/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 822/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 823/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 824/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 825/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 826/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 827/1500\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 828/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0104 - val_mse: 0.0104\n",
            "Epoch 829/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 830/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 831/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 832/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0157 - val_mse: 0.0157\n",
            "Epoch 833/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 834/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 835/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 836/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0098 - val_mse: 0.0098\n",
            "Epoch 837/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 838/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 839/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 840/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 841/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 842/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 843/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 844/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 845/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 846/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0128 - val_mse: 0.0128\n",
            "Epoch 847/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0149 - val_mse: 0.0149\n",
            "Epoch 848/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 849/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 850/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 851/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0141 - val_mse: 0.0141\n",
            "Epoch 852/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 853/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 854/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 855/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 856/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 857/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 858/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 859/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Epoch 860/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0136 - val_mse: 0.0136\n",
            "Epoch 861/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 862/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 863/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 864/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 865/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 866/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 867/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 868/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 869/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 870/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 871/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 872/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 873/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0132 - val_mse: 0.0132\n",
            "Epoch 874/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 875/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 876/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0176 - val_mse: 0.0176\n",
            "Epoch 877/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 878/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 879/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 880/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 881/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 882/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 883/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 884/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 885/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0115 - val_mse: 0.0115\n",
            "Epoch 886/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 887/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 888/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 889/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 890/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 891/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 892/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 893/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 894/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 895/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 896/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0118 - val_mse: 0.0118\n",
            "Epoch 897/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 898/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 899/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 900/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 901/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0108 - val_mse: 0.0108\n",
            "Epoch 902/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 903/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0120 - val_mse: 0.0120\n",
            "Epoch 904/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 905/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 906/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0137 - val_mse: 0.0137\n",
            "Epoch 907/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0139 - val_mse: 0.0139\n",
            "Epoch 908/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 909/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 910/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 911/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0109 - val_mse: 0.0109\n",
            "Epoch 912/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 913/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0121 - val_mse: 0.0121\n",
            "Epoch 914/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 915/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0156 - val_mse: 0.0156\n",
            "Epoch 916/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 917/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0125 - val_mse: 0.0125\n",
            "Epoch 918/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 919/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 920/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 921/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 922/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0123 - val_mse: 0.0123\n",
            "Epoch 923/1500\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 924/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0117 - val_mse: 0.0117\n",
            "Epoch 925/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0134 - val_mse: 0.0134\n",
            "Epoch 926/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 927/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 928/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0135 - val_mse: 0.0135\n",
            "Epoch 929/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0101 - val_mse: 0.0101\n",
            "Epoch 930/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 931/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0110 - val_mse: 0.0110\n",
            "Epoch 932/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0131 - val_mse: 0.0131\n",
            "Epoch 933/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0119 - val_mse: 0.0119\n",
            "Epoch 934/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0116 - val_mse: 0.0116\n",
            "Epoch 935/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 936/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 937/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0142 - val_mse: 0.0142\n",
            "Epoch 938/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0127 - val_mse: 0.0127\n",
            "Epoch 939/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0111 - val_mse: 0.0111\n",
            "Epoch 940/1500\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 941/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0112 - val_mse: 0.0112\n",
            "Epoch 942/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 943/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0129 - val_mse: 0.0129\n",
            "Epoch 944/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 945/1500\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 946/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0133 - val_mse: 0.0133\n",
            "Epoch 947/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0113 - val_mse: 0.0113\n",
            "Epoch 948/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0124 - val_mse: 0.0124\n",
            "Epoch 949/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0122 - val_mse: 0.0122\n",
            "Epoch 950/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0162 - val_mse: 0.0162\n",
            "Epoch 951/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0153 - val_mse: 0.0153\n",
            "Epoch 952/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0130 - val_mse: 0.0130\n",
            "Epoch 953/1500\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0114 - val_mse: 0.0114\n",
            "Epoch 954/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0126 - val_mse: 0.0126\n",
            "Epoch 955/1500\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0140 - val_mse: 0.0140\n",
            "Epoch 956/1500\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0144 - val_mse: 0.0144\n",
            "Loaded model from disk\n",
            "[555] [0.00911368]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "HC8Z4gVVejVl",
        "outputId": "47791017-6e44-41fa-ecef-504e2dba794e"
      },
      "source": [
        "\n",
        "#----------------------Important !!!!-----------------------#\n",
        "pred = loaded_model.predict(train_X)  #(predicted)  \n",
        "obs  = y_train_scale               #(obs) \n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "#----------------------reverse scaling------------------------------#\n",
        "#For training period\n",
        "y_hat_rescaled  = scaler_y.inverse_transform(pred) #prediction value\n",
        "y_rescaled = scaler_y.inverse_transform(obs)         #observed value\n",
        "\n",
        "#Inverse scaled --> pred, obs  \n",
        "pred = y_hat_rescaled\n",
        "obs = y_rescaled\n",
        "\n",
        "# pred1, obs1: pred train, obs train\n",
        "pred1=pred\n",
        "obs1=obs\n",
        "\n",
        "##########################################################\n",
        "# Validation\n",
        "pred = loaded_model.predict(val_X)  #(pred)  \n",
        "obs  = y_val_scale                 #(obs) \n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "#----------------------reverse scaling------------------------------#\n",
        "#For training period\n",
        "y_hat_rescaled  = scaler_y.inverse_transform(pred) #prediction value\n",
        "y_rescaled = scaler_y.inverse_transform(obs)         #observed value\n",
        "\n",
        "#Inverse scaled --> pred, obs  \n",
        "pred = y_hat_rescaled\n",
        "obs = y_rescaled\n",
        "\n",
        "# pred1, obs1: pred val, obs val\n",
        "pred2=pred\n",
        "obs2=obs\n",
        "\n",
        "################################################################\n",
        "pred = loaded_model.predict(test_X)  #(pred)  \n",
        "obs  = y_test_scale                 #(obs) \n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "#----------------------reverse scaling------------------------------#\n",
        "#For training period\n",
        "y_hat_rescaled  = scaler_y.inverse_transform(pred) #prediction value\n",
        "y_rescaled = scaler_y.inverse_transform(obs)         #observed value\n",
        "\n",
        "#Inverse scaled --> pred, obs  \n",
        "pred = y_hat_rescaled\n",
        "obs = y_rescaled\n",
        "\n",
        "# pred1, obs1: pred val, obs val\n",
        "pred3=pred\n",
        "obs3=obs\n",
        "#--------------------------------------------------------------------#\n",
        "\n",
        "# TOM LAI\n",
        "list_con=list()\n",
        "df_train=pd.DataFrame({'obs':obs1.flatten(),'pred':pred1.flatten()})\n",
        "list_con.append(df_train)\n",
        "df_val=pd.DataFrame({'obs':obs2.flatten(),'pred':pred2.flatten()})\n",
        "list_con.append(df_val)\n",
        "df_test=pd.DataFrame({'obs':obs3.flatten(),'pred':pred3.flatten()})\n",
        "list_con.append(df_test)\n",
        "# =============================================================================\n",
        "# LUU LAI KET QUA\n",
        "# =============================================================================\n",
        "with open(outs[1]+'/'+str(k)+'lead'+str(m)+'T3_lag3.pkl', 'wb') as f: # khong nen\n",
        "  # compressed_file = bz2.BZ2File(f, 'w')\n",
        "  pickle.dump(list_con, f)\n",
        "\n",
        "#####\n",
        "## mo kiem tra lai\n",
        "with open(outs[1]+'/'+str(k)+'lead'+str(m)+'T3_lag3.pkl', 'rb') as f: # khong nen\n",
        "    # compressed_file = bz2.BZ2File(f, 'r')\n",
        "    load_list_con = pickle.load(f)\n",
        "# 0,1,2 tuong ung voi train, val, test\n",
        "# pearson,dotincay=pearsonr(load_list_con[1]['obs'],load_list_con[1]['pred'])\n",
        "# print('cc of val: '+str(pearson))\n",
        "# =============================================================================\n",
        "# VE HINH\n",
        "# =============================================================================\n",
        "# HINH  SCATTER\n",
        "# Ve hinh statter plot cua training, validation and testing\n",
        "\n",
        "# scale plot M1\n",
        "\n",
        "\n",
        "axes=[131,132,133]\n",
        "obs_all=[obs1,obs2,obs3]\n",
        "pred_all=[pred1,pred2,pred3]\n",
        "# lead_time=0\n",
        "names_phases=['training','validation','testing']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(9,3))\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "# lead_time=2\n",
        "  for phase in range(3):\n",
        "  # for lead_time in range(3):\n",
        "\n",
        "    plt.subplot(axes[phase])\n",
        "    pearson,dotincay=pearsonr(load_list_con[phase]['obs'],load_list_con[phase]['pred'])\n",
        "    r2_vanila_1m =pearson\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "    # fig,ax=plt.subplots(figsize=(5,5))\n",
        "    # min_values1=np.min([pred_all[m],obs_all[m]])\n",
        "    # min_values=min_values1\n",
        "    # max_values1=np.max([pred_all[m],obs_all[m]])\n",
        "    # max_values=max_values1\n",
        "    min_values=-5.9\n",
        "    max_values=2.29\n",
        "\n",
        "    plt.xlim(min_values,max_values)\n",
        "    plt.ylim(min_values,max_values)\n",
        "\n",
        "    plt.scatter(x=load_list_con[phase]['obs'],\n",
        "                y=load_list_con[phase]['pred'],\n",
        "                s=None,\n",
        "                c='k', \n",
        "                marker='.', \n",
        "                cmap=None,\n",
        "                norm=None,\n",
        "                vmin=None, \n",
        "                vmax=None,\n",
        "                alpha=None,            \n",
        "                linewidths=None,\n",
        "                edgecolors=None,plotnonfinite=False,data=None)\n",
        "\n",
        "    # ve duong 45\n",
        "    # plt.legend(['NDI'])\n",
        "    plt.xlabel('obs')\n",
        "    if lead_time==0:\n",
        "      plt.ylabel('pred')\n",
        "    # if lead_time==1:\n",
        "    # plt.title('M1S4prs_prs '+names_phases[m])\n",
        "    # add_identity(ax, color='r', ls='--')\n",
        "    plt.text(min_values,min_values,'R= '+str(round(r2_vanila_1m,2)))\n",
        "    xpoints = ypoints = plt.xlim()\n",
        "    plt.plot(xpoints, ypoints, linestyle='--', color='r', lw=1, scalex=False, scaley=False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "  plt.savefig(outs[3]+'/'+str(k)+'scatter_T3'+str(m)+'.jpeg',dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "# =============================================================================\n",
        "#VE HINH TIME SERIES\n",
        "# =============================================================================\n",
        "  \n",
        "  # Ve train\n",
        "# Time series cua train\n",
        "#Graph\n",
        "months=['1month','2months','3months']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(6,4))\n",
        "  plt.subplot(211)\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        " \n",
        "  vector_date=pd.date_range(start='1968-01',periods=df1.shape[0],freq='MS')\n",
        "  plt.plot(vector_date[0+lead_time:lead_time+int(obs1.shape[0]*0.5)],obs1[0:int(obs1.shape[0]*0.5),lead_time],'k-.')\n",
        "  plt.plot(vector_date[0+lead_time:lead_time+int(obs1.shape[0]*0.5)],pred1[0:int(obs1.shape[0]*0.5),lead_time],'r-.')\n",
        "\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train-n_out0+lead_time+1], obs1[n_in0+lead_time:n_train-n_out0+lead_time+1,lead_time], 'k-.')\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train+-n_out0+lead_time+1], pred1[:,lead_time], 'r-.')\n",
        "  \n",
        "  plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  # plt.title('Time series '+'1 month' +' lead time prediction at trainning')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.subplot(212)\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  \n",
        "  plt.plot(vector_date[lead_time+int(obs1.shape[0]*0.5):lead_time+int(obs1.shape[0]*1)],obs1[int(obs1.shape[0]*0.5):int(obs1.shape[0]*1),lead_time],'k-.')\n",
        "  plt.plot(vector_date[lead_time+int(obs1.shape[0]*0.5):lead_time+int(obs1.shape[0]*1)],pred1[int(pred1.shape[0]*0.5):int(pred1.shape[0]*1),lead_time],'r-.')\n",
        "  # plt.title('Time series '+'1 month' +' lead time prediction at trainning')\n",
        "  \n",
        "  \n",
        "  \n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)]+lead_time-n_out0+1, pred[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time],'r-.')\n",
        "  # plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  plt.tight_layout()\n",
        "\n",
        "plt.savefig(outs[3]+'/'+str(k)+'train_time_T3'+str(m)+'.jpeg',dpi=300)\n",
        "plt.show()\n",
        "plt.close()\n",
        "############ VAL\n",
        "# Time series cua val\n",
        "#Graph\n",
        "months=['1month','2months','3months']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(6,3))\n",
        "  plt.subplot(111)\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  plt.plot(vector_date[n_train+lead_time:n_train+lead_time+obs2.shape[0]],obs2[:,lead_time],'k-.')\n",
        "  plt.plot(vector_date[n_train+lead_time:n_train+lead_time+obs2.shape[0]],pred2[:,lead_time],'r-.')\n",
        "\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train-n_out0+lead_time+1], obs1[n_in0+lead_time:n_train-n_out0+lead_time+1,lead_time], 'k-.')\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train+-n_out0+lead_time+1], pred1[:,lead_time], 'r-.')\n",
        "  \n",
        "  plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  # plt.title('Time series '+'1 month' +' lead time prediction at validation')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # plt.subplot(212)\n",
        "  # plt.rcParams.update({'font.size': 12})\n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1], \n",
        "  #          obs[int(dataset0.shape[0]*0.3)+input:int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time], 'k-.')\n",
        "  \n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)]+lead_time-n_out0+1, pred[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time],'r-.')\n",
        "  # plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.savefig(outs[3]+'/'+str(k)+'val_time_T3'+str(m)+'.jpeg',dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "  # Testing\n",
        "  \n",
        "#Graph\n",
        "months=['1month','2months','3months']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(6,3))\n",
        "  plt.subplot(111)\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  vector_date_test=vector_date[-24:]\n",
        "  # plt.plot(vector_date[n_train+n_val+lead_time:n_train+n_val+n_test+lead_time+obs3.shape[0]],obs3[:,lead_time],'k-.')\n",
        "  # plt.plot(vector_date[n_train+n_val+lead_time:n_train+n_val+lead_time+n_test+obs3.shape[0]],pred3[:,lead_time],'r-.')\n",
        "  plt.plot(vector_date[-n_test:],obs3[:,lead_time],'k-.')\n",
        "  plt.plot(vector_date[-n_test:],pred3[:,lead_time],'r-.')\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train-n_out0+lead_time+1], obs1[n_in0+lead_time:n_train-n_out0+lead_time+1,lead_time], 'k-.')\n",
        "  # plt.plot(vector_date[n_in0+lead_time:n_train+-n_out0+lead_time+1], pred1[:,lead_time], 'r-.')\n",
        "  # plt.xticks(['2015-01','2015-06','2015-12','2016-12'])\n",
        "  plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  # plt.title('Time series '+'1month' +' lead time prediction at testing')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # plt.subplot(212)\n",
        "  # plt.rcParams.update({'font.size': 12})\n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1], \n",
        "  #          obs[int(dataset0.shape[0]*0.3)+input:int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time], 'k-.')\n",
        "  \n",
        "  # plt.plot(vector_date[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)]+lead_time-n_out0+1, pred[int(dataset0.shape[0]*0.3):int(dataset0.shape[0]*0.6)+lead_time-n_out0+1,lead_time],'r-.')\n",
        "  # plt.legend(['obs','simulation'])\n",
        "\n",
        "  # plt.ylabel('NDI')\n",
        "  # plt.tight_layout()\n",
        "\n",
        "  plt.savefig(outs[3]+'/'+str(k)+'test_time_T3'+str(m)+'.jpeg',dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "# =============================================================================\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}