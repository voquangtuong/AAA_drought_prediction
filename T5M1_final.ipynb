{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5M1_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO346gEQOuU4jUdONougbwI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/voquangtuong/AAA_drought_prediction/blob/main/T5M1_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYPjOsEILtgE"
      },
      "source": [
        "T5 we don't training again just use model from T4 to predict\n",
        "\n",
        "Replace observational data with climate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjmSI_mvaIwc",
        "outputId": "bdf74107-99d8-4820-cc4f-c7c0a3d87808"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuZf3Ifqs153"
      },
      "source": [
        "Set Output folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZ50DaMaTDl"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/dynamic_comparison_all_models/')\n",
        "outs=['save_model','save_pickles','tables','figs']\n",
        "for out in outs:\n",
        "  if not os.path.exists(out):\n",
        "    os.makedirs(out)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwdvWT4JtIbG"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny2WIbEnPU4W"
      },
      "source": [
        "# Run functions\n",
        "%run customize_functions.ipynb\n",
        "# For tensorboard\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "import seaborn as sns"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lulMq8Ahqqxw"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EU8iJ58qwNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a82a142-eda8-48a2-af90-80ccfabc9fd1"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr4dGcS5rAbK"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "# from lstm_utils import *\n",
        "import pickle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "####LIBRARY\n",
        "import scipy\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow import keras # tai sao import tu tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "####################################################\n",
        "import datetime\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.dates as mdates\n",
        "import datetime\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import datetime\n",
        "\n",
        "# import statsmodels as sm\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr\n",
        "import matplotlib\n",
        "###  SET FONTS FOR PLOTTING\n",
        "font = {'family' : 'normal',\n",
        "        'weight' : 'normal',\n",
        "        'size'   : 12}\n",
        "\n",
        "matplotlib.rc('font', **font)\n",
        "### cap nhat font\n",
        "# plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "####RANDOM SEED SET\n",
        "#tf.random.set_seed(10000000)\n",
        "#np.random.seed(10000000)\n",
        "\n",
        "####PANDAS LIB\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "###### Univrate LSTM\n",
        "# univariate lstm example\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "######## Keras tunner\n",
        "# import keras_tuner as kt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def series_to_supervised_df(data, n_in, n_out, dropnan=True): # dung cho pandas\n",
        "\t\"\"\"\n",
        "\tFrame a time series as a supervised learning dataset.\n",
        "\tArguments:\n",
        "\t\tdata: Sequence of observations as a list or NumPy array.\n",
        "\t\tn_in: Number of lag observations as input (X).\n",
        "\t\tn_out: Number of observations as output (y).\n",
        "\t\tdropnan: Boolean whether or not to drop rows with NaN values.\n",
        "\tReturns:\n",
        "\t\tPandas DataFrame of series framed for supervised learning.\n",
        "\t\"\"\"\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1): # \n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i)) \n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = pd.concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-26pZn4sRVR3"
      },
      "source": [
        "# Load data and initial paramaters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRBWN8dtpcF9"
      },
      "source": [
        "# Ten mo hinh\n",
        "\n",
        "# Load du lieu\n",
        "# load data obs\n",
        "with open('input_pickles'+'/'+'PRS3_NDI3_59new.pkl', 'rb') as f1:\n",
        "    # compressed_file = bz2.BZ2File(f, 'r')\n",
        "    PRS3_NDI3_59 = pickle.load(f1)\n",
        "\n",
        "# load du lieu tu mo hinh khi hau\n",
        "with open('input_pickles'+'/'+'list_PRS_NDIclim_all.pkl', 'rb') as f2:\n",
        "    # compressed_file = bz2.BZ2File(f, 'r')\n",
        "    PRS3_NDI3_59cli = pickle.load(f2) # co 3 buoc du bao M1, M2, M3\n",
        "    "
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stWu4YmVaoQz"
      },
      "source": [
        "# Define station, lag, lead times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "pX0SXRx_amw8",
        "outputId": "f754180b-5e93-4faf-bd81-b86322c15a33"
      },
      "source": [
        "\n",
        "\n",
        "###### CHOSEN STATION INPUT, LEAD TIME PREDICTION###############################    \n",
        "# kiem tra cho ganghwa\n",
        "names0=['T4M1','T4M2','T4M3'] # CAI NAY DE MO FILE CU\n",
        "names=['T5M1','T5M2','T5M3'] # CAI NAY DE LUU KET QUA MOI\n",
        "\n",
        "k=29 # chi so thu tu cua tram ganghwa\n",
        "n_in0=3\n",
        "n_out0=1 # gia tri lead time du bao\n",
        "m=n_out0 # tinh cho buoc 0\n",
        "df0=PRS3_NDI3_59[k] # 1968-2020\n",
        "# chia du lieu cho 12 lay 6 phan cho train, 3 phan cho val, 3 phan cho test\n",
        "df1=df0.iloc[:(2016-1968+1)*12,:]\n",
        "# df1=df0 # du bao het\n",
        "# df1a: la du lieu tu mo hinh khi hau\n",
        "df1a=PRS3_NDI3_59cli[n_out0-1][k]\n",
        "# =============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "df2=series_to_supervised_df(df1,n_in0,n_out0)\n",
        "# df2a: cung phai chia gia tri mo hinh khi hau theo thuc do\n",
        "df2a=series_to_supervised_df(df1a,n_in0,n_out0)\n",
        "\n",
        "# =============================================================================\n",
        "# =============================================================================\n",
        "#     remove values PRS  at fure prediction\n",
        "# var3(t),var2(t),var1(t) have to remove\n",
        "list_drops=[np.arange(2,5)*-1,np.arange(2,9)*-1,np.arange(2,13)*-1]\n",
        "list_drops1=[[],[],[]]\n",
        "list_drops1a=[[-5,-9,-13],[-5,-9,-13,-17],[-5,-9,-13,-17,-21]]\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "df3=df2.drop(df2.columns[[list_drops1[n_out0-1]]],axis=1)\n",
        "df4obs=df3.drop(df3.columns[[list_drops1a[n_out0-1]]],axis=1)\n",
        "df4climtemp=df4obs # bien tam thoi trung gian cho khi hau de lay du lieu tu khi hau qua\n",
        "# =============================================================================\n",
        "# # IMPORTANT: REPLACE VALUES OF VAR1, VAR2,VAR3 AT T BY CLIMATE VALUE\n",
        "## PHAI THAY TU NAM 2016.12  QUAY NGUOC LAI\n",
        "# =============================================================================\n",
        "df4climtemp.iloc[-df2a.shape[0]:,[-2,-3,-4]]=df2a.iloc[:,[-2,-3,-4]]\n",
        "df4=df4climtemp\n",
        "\n",
        "\n",
        "# ve hinh Kiem tra gia tri tai vi tri thay the\n",
        "# df4obs.iloc[-df2a.shape[0]:,[-2,-3,-4]].plot(kind='line')\n",
        "# df4.iloc[-df2a.shape[0]:,[-2,-3,-4]].plot(kind='line')\n",
        "df_error=pd.concat([df3.iloc[-df2a.shape[0]:,[-2,-3,-4]],df4.iloc[-df2a.shape[0]:,[-2,-3,-4]]],axis=1)\n",
        "df_error.columns=['Sobs','Robs','Pobs','Scli','Rcli','Pcli']\n",
        "pearson,dotincay=pearsonr(df_error['Sobs'],df_error['Scli'])\n",
        "min_values=np.min(df_error['Sobs'])\n",
        "max_values=np.max(df_error['Sobs'])\n",
        "\n",
        "r2_vanila_1m =pearson\n",
        "fig,ax=plt.subplots(figsize=(3,3))\n",
        "plt.xlim(min_values,max_values)\n",
        "plt.ylim(min_values,max_values)\n",
        "\n",
        "plt.scatter(x=df_error['Sobs'],\n",
        "            y=df_error['Scli'],\n",
        "            s=None,\n",
        "            c='k', \n",
        "            marker='.', \n",
        "            cmap=None,\n",
        "            norm=None,\n",
        "            vmin=None, \n",
        "            vmax=None,\n",
        "            alpha=None,            \n",
        "            linewidths=None,\n",
        "            edgecolors=None,plotnonfinite=False,data=None) \n",
        "# text\n",
        "plt.text(min_values,min_values,'R= '+str(round(r2_vanila_1m,2)))\n",
        "# duong 45\n",
        "xpoints = ypoints = plt.xlim()\n",
        "plt.plot(xpoints, ypoints, linestyle='--', color='r', lw=1, scalex=False, scaley=False)\n",
        "\n",
        "# Runoff\n",
        "pearson,dotincay=pearsonr(df_error['Robs'],df_error['Rcli'])\n",
        "min_values=np.min(df_error['Robs'])\n",
        "max_values=np.max(df_error['Robs'])\n",
        "\n",
        "r2_vanila_1m =pearson\n",
        "fig,ax=plt.subplots(figsize=(3,3))\n",
        "plt.xlim(min_values,max_values)\n",
        "plt.ylim(min_values,max_values)\n",
        "\n",
        "plt.scatter(x=df_error['Robs'],\n",
        "            y=df_error['Rcli'],\n",
        "            s=None,\n",
        "            c='k', \n",
        "            marker='.', \n",
        "            cmap=None,\n",
        "            norm=None,\n",
        "            vmin=None, \n",
        "            vmax=None,\n",
        "            alpha=None,            \n",
        "            linewidths=None,\n",
        "            edgecolors=None,plotnonfinite=False,data=None) \n",
        "# text\n",
        "plt.text(min_values,min_values,'R= '+str(round(r2_vanila_1m,2)))\n",
        "# duong 45\n",
        "xpoints = ypoints = plt.xlim()\n",
        "plt.plot(xpoints, ypoints, linestyle='--', color='r', lw=1, scalex=False, scaley=False)\n",
        "\n",
        "# Pre\n",
        "pearson,dotincay=pearsonr(df_error['Pobs'],df_error['Pcli'])\n",
        "min_values=np.min(df_error['Pobs'])\n",
        "max_values=np.max(df_error['Pobs'])\n",
        "\n",
        "r2_vanila_1m =pearson\n",
        "fig,ax=plt.subplots(figsize=(3,3))\n",
        "plt.xlim(min_values,max_values)\n",
        "plt.ylim(min_values,max_values)\n",
        "\n",
        "plt.scatter(x=df_error['Pobs'],\n",
        "            y=df_error['Pcli'],\n",
        "            s=None,\n",
        "            c='k', \n",
        "            marker='.', \n",
        "            cmap=None,\n",
        "            norm=None,\n",
        "            vmin=None, \n",
        "            vmax=None,\n",
        "            alpha=None,            \n",
        "            linewidths=None,\n",
        "            edgecolors=None,plotnonfinite=False,data=None) \n",
        "# text\n",
        "plt.text(min_values,min_values,'R= '+str(round(r2_vanila_1m,2)))\n",
        "# duong 45\n",
        "xpoints = ypoints = plt.xlim()\n",
        "plt.plot(xpoints, ypoints, linestyle='--', color='r', lw=1, scalex=False, scaley=False)\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# Chia du lieu theo ti le 6:3:3\n",
        "n_train=int(df4.shape[0]*0.6)\n",
        "n_val=int(df4.shape[0]*0.8)-n_train\n",
        "n_test=df4.shape[0]-n_val-n_train\n",
        "\n",
        "train_df=df4.iloc[0:n_train,:]\n",
        "val_df=df4.iloc[n_train:n_train+n_val,:]\n",
        "test_df0=df4.iloc[n_train+n_val:,:] # ORG\n",
        "# chi lay test dung so lieu cua khi hau\n",
        "test_df=test_df0.iloc[-df2a.shape[0]:,:]\n",
        "# print(train_df.shape,val_df.shape,test_df.shape)\n",
        "x_train,y_train0=train_df.iloc[:,:-1].values,train_df.iloc[:,-1].values\n",
        "# lay chinh no du bao no luon\n",
        "# x_train,y_train0=train_df.iloc[:,:].values,train_df.iloc[:,-1].values # KIEM TRA DU BAO CHO CHINH NO\n",
        "y_train=y_train0.reshape(y_train0.shape[0],1)\n",
        "# print(x_train.shape,y_train.shape)\n",
        "\n",
        "x_val,y_val0=val_df.iloc[:,:-1].values,val_df.iloc[:,-1].values\n",
        "# x_val,y_val0=val_df.iloc[:,:].values,val_df.iloc[:,-1].values #  KIEM TRA DU BAO CHO CHINH NO\n",
        "y_val=y_val0.reshape(y_val0.shape[0],1)\n",
        "# print(x_val.shape,y_val.shape)\n",
        "\n",
        "x_test,y_test0=test_df.iloc[:,:-1].values,test_df.iloc[:,-1].values\n",
        "\n",
        "# x_test,y_test0=test_df.iloc[:,:].values,test_df.iloc[:,-1].values # KIEM TRA DU BAO CHO CHINH NO\n",
        "\n",
        "y_test=y_test0.reshape(y_test0.shape[0],1)\n",
        "# print(x_test.shape,y_test.shape)\n",
        "\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Scale data\n",
        "# tao 2 scaler rieng cho X, Y de invert cho de\n",
        "scaler_x = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "scaler_y = MinMaxScaler(feature_range=(0.01, 0.99))\n",
        "\n",
        "x_train_scale = scaler_x.fit_transform(x_train)\n",
        "y_train_scale = scaler_y.fit_transform(y_train)\n",
        "\n",
        "# fit scale cua train cho val va test\n",
        "x_val_scale=scaler_x.transform(x_val)\n",
        "y_val_scale=scaler_y.transform(y_val)\n",
        "\n",
        "x_test_scale=scaler_x.transform(x_test)\n",
        "y_test_scale=scaler_y.transform(y_test)\n",
        "# Can xem lai 12 gia tri nay la buoc thoi gian \n",
        "# hay 12 gia tri duoc xem nhu feature\n",
        "# # TH1 : Xem no nhu 12 buoc thoi gian\n",
        "# n_features=1\n",
        "# train_X = x_train_scale.reshape((x_train_scale.shape[0], x_train_scale.shape[1], n_features))\n",
        "# val_X = x_val_scale.reshape((x_val_scale.shape[0], x_val_scale.shape[1], n_features))\n",
        "# test_X = x_test_scale.reshape((x_test_scale.shape[0], x_test_scale.shape[1], n_features))\n",
        "\n",
        "# TH2: xem no nhu 12 dac tinh\n",
        "n_step=1\n",
        "train_X = x_train_scale.reshape((x_train_scale.shape[0],n_step, x_train_scale.shape[1]))\n",
        "val_X = x_val_scale.reshape((x_val_scale.shape[0], n_step,x_val_scale.shape[1]))\n",
        "test_X = x_test_scale.reshape((x_test_scale.shape[0], n_step,x_test_scale.shape[1]))\n",
        "print(train_X.shape)\n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py:4114: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  result = getitem(key)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(351, 1, 12)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jex8ePoffXs4"
      },
      "source": [
        "# Define model and setup training, save models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnd2QZq0fd85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f837f0e8-5d4e-4a93-c717-698634ba143d"
      },
      "source": [
        "# # dinh nghia lai loss function, cai nay optimize kem\n",
        "# tf.keras.backend.clear_session()\n",
        "# mape = tf.keras.losses.MeanAbsolutePercentageError()\n",
        "# # =============================================================================\n",
        "## KHONG CHAY NUA NE KHOA LAI CHO CHAC\n",
        "# # =============================================================================\n",
        "# # =============================================================================\n",
        "# # Define model\n",
        "# model = Sequential()\n",
        "# # # TH1 : xem 12 gia tri la buoc thoi gian\n",
        "# # model.add(LSTM(256,activation='relu', return_sequences=False, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "\n",
        "# # TH2 : xem 12 gia tri la dac tinh\n",
        "# model.add(LSTM(128,activation='relu', return_sequences=False, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "# # model.add(Bidirectional(LSTM(32, activation='relu')))\n",
        "# model.add(Dense(1))\n",
        "# # =============================================================================\n",
        "# # opt = Adam(learning_rate = 0.001,  beta_1=0.9, beta_2=0.999, epsilon=1e-07,clipnorm = 0.999)\n",
        "# opt = Adam(learning_rate = 0.001,  beta_1=0.9, beta_2=0.999, epsilon=1e-07,clipnorm = 1.0)\n",
        "# model.compile(optimizer=opt, loss='mse')\n",
        "# model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               72192     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 72,321\n",
            "Trainable params: 72,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_PIDPryDblP"
      },
      "source": [
        "### KHONG CHAY NUA NEN KHOA LAI CHO CHAC\n",
        "\n",
        "# ###############################################################################\n",
        "# # NAME=\"T4-M1-TB-{}\".format(int(time.time()))\n",
        "# NAME1=names[n_out0-1]+\"-{}\".format(datetime.datetime.now().strftime(\"%Y/%m%d-%H-%M-%S\"))\n",
        "# # tensorboard=TensorBoard(log_dir='logs/{}'.format(NAME))\n",
        "# # path=\"logs/fit\"+datetime.datetime.now().strftime(\"%Y/%m%d-%H-%M-%S\") # luu logs\n",
        "# # tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=path,histogram_freq=1)\n",
        "# tensorboard_callback1=tf.keras.callbacks.TensorBoard(log_dir='logs/{}'.format(NAME1),\n",
        "#                                                      histogram_freq=1) # ket hop \n",
        "# # conditional call back\n",
        "# value00=0.0045 # cho validation\n",
        "# from keras.callbacks import Callback\n",
        "# class EarlyStoppingByLossVal(Callback):\n",
        "#     def __init__(self, monitor='val_loss', value=value00, verbose=0):\n",
        "#         super(Callback, self).__init__()\n",
        "#         self.monitor = monitor\n",
        "#         self.value = value\n",
        "#         self.verbose = verbose\n",
        "\n",
        "#     def on_epoch_end(self, epoch, logs={}):\n",
        "#         current = logs.get(self.monitor)\n",
        "#         if current is None:\n",
        "#             warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
        "\n",
        "#         if current < self.value:\n",
        "#             if self.verbose > 0:\n",
        "#                 print(\"Epoch %05d: early stopping THR\" % epoch)\n",
        "#             self.model.stop_training = True\n",
        "\n",
        "# callbacks_threshole_val = EarlyStoppingByLossVal(monitor='val_loss', value=value00, verbose=1)\n",
        "\n",
        "# ###############\n",
        "# # condtion for training\n",
        "# # conditional call back\n",
        "# value0=0.0025 # sai so 5 % mse=(ypred-yobs)^2\n",
        "# from keras.callbacks import Callback\n",
        "# class EarlyStoppingByLoss(Callback):\n",
        "#     def __init__(self, monitor='loss', value=value0, verbose=0):\n",
        "#         super(Callback, self).__init__()\n",
        "#         self.monitor = monitor\n",
        "#         self.value = value\n",
        "#         self.verbose = verbose\n",
        "\n",
        "#     def on_epoch_end(self, epoch, logs={}):\n",
        "#         current = logs.get(self.monitor)\n",
        "#         if current is None:\n",
        "#             warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
        "\n",
        "#         if current < self.value:\n",
        "#             if self.verbose > 0:\n",
        "#                 print(\"Epoch %05d: early stopping THR\" % epoch)\n",
        "#             self.model.stop_training = True\n",
        "\n",
        "# callbacks_threshole_train = EarlyStoppingByLossVal(monitor='loss', value=value0, verbose=1)\n",
        "    \n",
        "    \n",
        "  \n",
        "# ##### callbacks\n",
        "# callbacks_list = [\n",
        "# # callbacks_threshole_val,\n",
        "# #  # stopping\n",
        "# keras.callbacks.EarlyStopping(\n",
        "# monitor=\"val_loss\",\n",
        "# patience=300,\n",
        "# mode=\"min\",\n",
        "# ),\n",
        "\n",
        "# ###################################################################\n",
        "\n",
        "# # checkpoint\n",
        "# keras.callbacks.ModelCheckpoint(\n",
        "# filepath=outs[0]+\"/\"+names[n_out0-1]+str(k)+\"lead\"+str(m)+\"best_stop.keras\", # cong them buoc thoi gian\n",
        "# monitor=\"val_loss\",\n",
        "# save_best_only=True,\n",
        "# ),\n",
        "# # tensorboard,\n",
        "# tensorboard_callback1,\n",
        "# ]\n",
        "# ######################################################################\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6FurUM4-wd1"
      },
      "source": [
        "# TRAINING MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0hyZdFZ-rPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d9aa48-9558-4a42-dc24-ef40907b638f"
      },
      "source": [
        "## KHONG CHAY NUA NEN KHOA LAI\n",
        "# # set seed de ket qua model khong bi thay doi\n",
        "# seed=123456789\n",
        "# import random\n",
        "# # import numpy as np\n",
        "# # import tensorflow as tf\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "# tf.random.set_seed(seed)\n",
        "\n",
        "# # Fit model can bo sung them batchsize\n",
        "\n",
        "# history1=model.fit(train_X,\n",
        "#           y_train_scale,\n",
        "# epochs=1500,\n",
        "# callbacks=callbacks_list,\n",
        "# validation_data=(val_X,y_val_scale),\n",
        "# batch_size=36,sample_weight=None,\n",
        "# steps_per_epoch=12,\n",
        "# initial_epoch=10,\n",
        "# )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/1500\n",
            "12/12 [==============================] - 3s 73ms/step - loss: 0.2218 - val_loss: 0.1802\n",
            "Epoch 12/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.1196 - val_loss: 0.0827\n",
            "Epoch 13/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0563 - val_loss: 0.0421\n",
            "Epoch 14/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0412 - val_loss: 0.0407\n",
            "Epoch 15/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0376 - val_loss: 0.0346\n",
            "Epoch 16/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0345 - val_loss: 0.0314\n",
            "Epoch 17/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0326 - val_loss: 0.0288\n",
            "Epoch 18/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0310 - val_loss: 0.0264\n",
            "Epoch 19/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0290 - val_loss: 0.0249\n",
            "Epoch 20/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0279 - val_loss: 0.0237\n",
            "Epoch 21/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0272 - val_loss: 0.0227\n",
            "Epoch 22/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0245 - val_loss: 0.0224\n",
            "Epoch 23/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0286 - val_loss: 0.0213\n",
            "Epoch 24/1500\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 0.0226 - val_loss: 0.0211\n",
            "Epoch 25/1500\n",
            "12/12 [==============================] - 0s 43ms/step - loss: 0.0252 - val_loss: 0.0210\n",
            "Epoch 26/1500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0232 - val_loss: 0.0202\n",
            "Epoch 27/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0226 - val_loss: 0.0203\n",
            "Epoch 28/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0238 - val_loss: 0.0199\n",
            "Epoch 29/1500\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0230 - val_loss: 0.0189\n",
            "Epoch 30/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0228 - val_loss: 0.0189\n",
            "Epoch 31/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0212 - val_loss: 0.0182\n",
            "Epoch 32/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0172\n",
            "Epoch 33/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0205 - val_loss: 0.0176\n",
            "Epoch 34/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 0.0164\n",
            "Epoch 35/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.0165\n",
            "Epoch 36/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0186 - val_loss: 0.0158\n",
            "Epoch 37/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0191 - val_loss: 0.0151\n",
            "Epoch 38/1500\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.0185 - val_loss: 0.0148\n",
            "Epoch 39/1500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0172 - val_loss: 0.0143\n",
            "Epoch 40/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.0141\n",
            "Epoch 41/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0170 - val_loss: 0.0135\n",
            "Epoch 42/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0173 - val_loss: 0.0145\n",
            "Epoch 43/1500\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 0.0148 - val_loss: 0.0130\n",
            "Epoch 44/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0150 - val_loss: 0.0132\n",
            "Epoch 45/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0151 - val_loss: 0.0126\n",
            "Epoch 46/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0123\n",
            "Epoch 47/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0144 - val_loss: 0.0121\n",
            "Epoch 48/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0128 - val_loss: 0.0122\n",
            "Epoch 49/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0148 - val_loss: 0.0118\n",
            "Epoch 50/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0125 - val_loss: 0.0118\n",
            "Epoch 51/1500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0122 - val_loss: 0.0118\n",
            "Epoch 52/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0132 - val_loss: 0.0115\n",
            "Epoch 53/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0134 - val_loss: 0.0115\n",
            "Epoch 54/1500\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.0115 - val_loss: 0.0114\n",
            "Epoch 55/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0113\n",
            "Epoch 56/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0123 - val_loss: 0.0113\n",
            "Epoch 57/1500\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.0109 - val_loss: 0.0111\n",
            "Epoch 58/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0121 - val_loss: 0.0110\n",
            "Epoch 59/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0113 - val_loss: 0.0110\n",
            "Epoch 60/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0107 - val_loss: 0.0110\n",
            "Epoch 61/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0106 - val_loss: 0.0114\n",
            "Epoch 62/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0118 - val_loss: 0.0127\n",
            "Epoch 63/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0115 - val_loss: 0.0110\n",
            "Epoch 64/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0100 - val_loss: 0.0112\n",
            "Epoch 65/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0109 - val_loss: 0.0109\n",
            "Epoch 66/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0108\n",
            "Epoch 67/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0102 - val_loss: 0.0109\n",
            "Epoch 68/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0111\n",
            "Epoch 69/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0111\n",
            "Epoch 70/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0097 - val_loss: 0.0111\n",
            "Epoch 71/1500\n",
            "12/12 [==============================] - 0s 44ms/step - loss: 0.0098 - val_loss: 0.0110\n",
            "Epoch 72/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0098 - val_loss: 0.0110\n",
            "Epoch 73/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0110\n",
            "Epoch 74/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0091 - val_loss: 0.0106\n",
            "Epoch 75/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0110\n",
            "Epoch 76/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0090 - val_loss: 0.0112\n",
            "Epoch 77/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0094 - val_loss: 0.0110\n",
            "Epoch 78/1500\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.0088 - val_loss: 0.0108\n",
            "Epoch 79/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0089 - val_loss: 0.0110\n",
            "Epoch 80/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0087 - val_loss: 0.0107\n",
            "Epoch 81/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0090 - val_loss: 0.0110\n",
            "Epoch 82/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0087 - val_loss: 0.0116\n",
            "Epoch 83/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0085 - val_loss: 0.0109\n",
            "Epoch 84/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 0.0107\n",
            "Epoch 85/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0108\n",
            "Epoch 86/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0080 - val_loss: 0.0108\n",
            "Epoch 87/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0107\n",
            "Epoch 88/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0105\n",
            "Epoch 89/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0082 - val_loss: 0.0106\n",
            "Epoch 90/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0105\n",
            "Epoch 91/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0076 - val_loss: 0.0104\n",
            "Epoch 92/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0107\n",
            "Epoch 93/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0105\n",
            "Epoch 94/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0078 - val_loss: 0.0104\n",
            "Epoch 95/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0107\n",
            "Epoch 96/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0076 - val_loss: 0.0103\n",
            "Epoch 97/1500\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 0.0074 - val_loss: 0.0101\n",
            "Epoch 98/1500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0071 - val_loss: 0.0101\n",
            "Epoch 99/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0073 - val_loss: 0.0100\n",
            "Epoch 100/1500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0071 - val_loss: 0.0103\n",
            "Epoch 101/1500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0101\n",
            "Epoch 102/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0100\n",
            "Epoch 103/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0063 - val_loss: 0.0098\n",
            "Epoch 104/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0102\n",
            "Epoch 105/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0066 - val_loss: 0.0097\n",
            "Epoch 106/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0070 - val_loss: 0.0098\n",
            "Epoch 107/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0061 - val_loss: 0.0097\n",
            "Epoch 108/1500\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 0.0070 - val_loss: 0.0096\n",
            "Epoch 109/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0065 - val_loss: 0.0098\n",
            "Epoch 110/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0070 - val_loss: 0.0094\n",
            "Epoch 111/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0093\n",
            "Epoch 112/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0063 - val_loss: 0.0094\n",
            "Epoch 113/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 0.0094\n",
            "Epoch 114/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0066 - val_loss: 0.0092\n",
            "Epoch 115/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0093\n",
            "Epoch 116/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - val_loss: 0.0093\n",
            "Epoch 117/1500\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.0058 - val_loss: 0.0091\n",
            "Epoch 118/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0071 - val_loss: 0.0090\n",
            "Epoch 119/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0062 - val_loss: 0.0092\n",
            "Epoch 120/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0090\n",
            "Epoch 121/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0061 - val_loss: 0.0094\n",
            "Epoch 122/1500\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0088\n",
            "Epoch 123/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0090\n",
            "Epoch 124/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0064 - val_loss: 0.0087\n",
            "Epoch 125/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0061 - val_loss: 0.0086\n",
            "Epoch 126/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0088\n",
            "Epoch 127/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0052 - val_loss: 0.0088\n",
            "Epoch 128/1500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.0064 - val_loss: 0.0085\n",
            "Epoch 129/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0085\n",
            "Epoch 130/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0088\n",
            "Epoch 131/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0084\n",
            "Epoch 132/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 0.0084\n",
            "Epoch 133/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0051 - val_loss: 0.0084\n",
            "Epoch 134/1500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.0059 - val_loss: 0.0082\n",
            "Epoch 135/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0084\n",
            "Epoch 136/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0086\n",
            "Epoch 137/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0059 - val_loss: 0.0081\n",
            "Epoch 138/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0053 - val_loss: 0.0081\n",
            "Epoch 139/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0081\n",
            "Epoch 140/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0086\n",
            "Epoch 141/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0080\n",
            "Epoch 142/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0053 - val_loss: 0.0080\n",
            "Epoch 143/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0054 - val_loss: 0.0082\n",
            "Epoch 144/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0049 - val_loss: 0.0080\n",
            "Epoch 145/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0054 - val_loss: 0.0080\n",
            "Epoch 146/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0052 - val_loss: 0.0078\n",
            "Epoch 147/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0081\n",
            "Epoch 148/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0079\n",
            "Epoch 149/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0078\n",
            "Epoch 150/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0081\n",
            "Epoch 151/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0051 - val_loss: 0.0078\n",
            "Epoch 152/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0080\n",
            "Epoch 153/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 0.0081\n",
            "Epoch 154/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0051 - val_loss: 0.0077\n",
            "Epoch 155/1500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0074\n",
            "Epoch 156/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0076\n",
            "Epoch 157/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0049 - val_loss: 0.0076\n",
            "Epoch 158/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0048 - val_loss: 0.0074\n",
            "Epoch 159/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0074\n",
            "Epoch 160/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0050 - val_loss: 0.0073\n",
            "Epoch 161/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 0.0075\n",
            "Epoch 162/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0074\n",
            "Epoch 163/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0076\n",
            "Epoch 164/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 0.0073\n",
            "Epoch 165/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0047 - val_loss: 0.0071\n",
            "Epoch 166/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0072\n",
            "Epoch 167/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0072\n",
            "Epoch 168/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0075\n",
            "Epoch 169/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0048 - val_loss: 0.0069\n",
            "Epoch 170/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0069\n",
            "Epoch 171/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0048 - val_loss: 0.0071\n",
            "Epoch 172/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0071\n",
            "Epoch 173/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0075\n",
            "Epoch 174/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0070\n",
            "Epoch 175/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0047 - val_loss: 0.0069\n",
            "Epoch 176/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0077\n",
            "Epoch 177/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0069\n",
            "Epoch 178/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0044 - val_loss: 0.0067\n",
            "Epoch 179/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0073\n",
            "Epoch 180/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0070\n",
            "Epoch 181/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0045 - val_loss: 0.0067\n",
            "Epoch 182/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0067\n",
            "Epoch 183/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0045 - val_loss: 0.0066\n",
            "Epoch 184/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0068\n",
            "Epoch 185/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0068\n",
            "Epoch 186/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0044 - val_loss: 0.0065\n",
            "Epoch 187/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0067\n",
            "Epoch 188/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0067\n",
            "Epoch 189/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0042 - val_loss: 0.0065\n",
            "Epoch 190/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 0.0068\n",
            "Epoch 191/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0074\n",
            "Epoch 192/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 0.0076\n",
            "Epoch 193/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 0.0068\n",
            "Epoch 194/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0042 - val_loss: 0.0064\n",
            "Epoch 195/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0067\n",
            "Epoch 196/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0066\n",
            "Epoch 197/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - val_loss: 0.0067\n",
            "Epoch 198/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0065\n",
            "Epoch 199/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0066\n",
            "Epoch 200/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0066\n",
            "Epoch 201/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0069\n",
            "Epoch 202/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0065\n",
            "Epoch 203/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0039 - val_loss: 0.0066\n",
            "Epoch 204/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0047 - val_loss: 0.0069\n",
            "Epoch 205/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0042 - val_loss: 0.0066\n",
            "Epoch 206/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0068\n",
            "Epoch 207/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0065\n",
            "Epoch 208/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0067\n",
            "Epoch 209/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 0.0063\n",
            "Epoch 210/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0066\n",
            "Epoch 211/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0041 - val_loss: 0.0064\n",
            "Epoch 212/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0041 - val_loss: 0.0065\n",
            "Epoch 213/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0039 - val_loss: 0.0063\n",
            "Epoch 214/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0066\n",
            "Epoch 215/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0063\n",
            "Epoch 216/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0065\n",
            "Epoch 217/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0065\n",
            "Epoch 218/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0063\n",
            "Epoch 219/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0066\n",
            "Epoch 220/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0065\n",
            "Epoch 221/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0064\n",
            "Epoch 222/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 0.0065\n",
            "Epoch 223/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0063\n",
            "Epoch 224/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0063\n",
            "Epoch 225/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0069\n",
            "Epoch 226/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0067\n",
            "Epoch 227/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0065\n",
            "Epoch 228/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0065\n",
            "Epoch 229/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0070\n",
            "Epoch 230/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0067\n",
            "Epoch 231/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0063\n",
            "Epoch 232/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0066\n",
            "Epoch 233/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0037 - val_loss: 0.0063\n",
            "Epoch 234/1500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.0062\n",
            "Epoch 235/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0064\n",
            "Epoch 236/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0063\n",
            "Epoch 237/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0065\n",
            "Epoch 238/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0062\n",
            "Epoch 239/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0066\n",
            "Epoch 240/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0069\n",
            "Epoch 241/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0065\n",
            "Epoch 242/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0065\n",
            "Epoch 243/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0065\n",
            "Epoch 244/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0064\n",
            "Epoch 245/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0066\n",
            "Epoch 246/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0063\n",
            "Epoch 247/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0067\n",
            "Epoch 248/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0066\n",
            "Epoch 249/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0065\n",
            "Epoch 250/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0068\n",
            "Epoch 251/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0066\n",
            "Epoch 252/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 253/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0063\n",
            "Epoch 254/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0067\n",
            "Epoch 255/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0067\n",
            "Epoch 256/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0065\n",
            "Epoch 257/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0063\n",
            "Epoch 258/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0067\n",
            "Epoch 259/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0064\n",
            "Epoch 260/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0067\n",
            "Epoch 261/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 0.0066\n",
            "Epoch 262/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0066\n",
            "Epoch 263/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0038 - val_loss: 0.0073\n",
            "Epoch 264/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0040 - val_loss: 0.0067\n",
            "Epoch 265/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0073\n",
            "Epoch 266/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0036 - val_loss: 0.0064\n",
            "Epoch 267/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 0.0067\n",
            "Epoch 268/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0065\n",
            "Epoch 269/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0067\n",
            "Epoch 270/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0066\n",
            "Epoch 271/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0066\n",
            "Epoch 272/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0037 - val_loss: 0.0066\n",
            "Epoch 273/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0065\n",
            "Epoch 274/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0065\n",
            "Epoch 275/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0065\n",
            "Epoch 276/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0069\n",
            "Epoch 277/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0064\n",
            "Epoch 278/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.0066\n",
            "Epoch 279/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0032 - val_loss: 0.0066\n",
            "Epoch 280/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0066\n",
            "Epoch 281/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0071\n",
            "Epoch 282/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0068\n",
            "Epoch 283/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0067\n",
            "Epoch 284/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 0.0068\n",
            "Epoch 285/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 286/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0066\n",
            "Epoch 287/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0064\n",
            "Epoch 288/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0066\n",
            "Epoch 289/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0065\n",
            "Epoch 290/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0070\n",
            "Epoch 291/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0071\n",
            "Epoch 292/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0067\n",
            "Epoch 293/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0068\n",
            "Epoch 294/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0065\n",
            "Epoch 295/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0067\n",
            "Epoch 296/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0064\n",
            "Epoch 297/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0069\n",
            "Epoch 298/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0067\n",
            "Epoch 299/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0069\n",
            "Epoch 300/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0064\n",
            "Epoch 301/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0067\n",
            "Epoch 302/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.0064\n",
            "Epoch 303/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0065\n",
            "Epoch 304/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0065\n",
            "Epoch 305/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0033 - val_loss: 0.0066\n",
            "Epoch 306/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0079\n",
            "Epoch 307/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0036 - val_loss: 0.0069\n",
            "Epoch 308/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0068\n",
            "Epoch 309/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0073\n",
            "Epoch 310/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0071\n",
            "Epoch 311/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0074\n",
            "Epoch 312/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0065\n",
            "Epoch 313/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 0.0065\n",
            "Epoch 314/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0064\n",
            "Epoch 315/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 0.0064\n",
            "Epoch 316/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 317/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0065\n",
            "Epoch 318/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0063\n",
            "Epoch 319/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0064\n",
            "Epoch 320/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0066\n",
            "Epoch 321/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0064\n",
            "Epoch 322/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0065\n",
            "Epoch 323/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0065\n",
            "Epoch 324/1500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.0034 - val_loss: 0.0067\n",
            "Epoch 325/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0065\n",
            "Epoch 326/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0065\n",
            "Epoch 327/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0033 - val_loss: 0.0066\n",
            "Epoch 328/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0064\n",
            "Epoch 329/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 330/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0065\n",
            "Epoch 331/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0065\n",
            "Epoch 332/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0064\n",
            "Epoch 333/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0033 - val_loss: 0.0068\n",
            "Epoch 334/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0063\n",
            "Epoch 335/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0066\n",
            "Epoch 336/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0032 - val_loss: 0.0064\n",
            "Epoch 337/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0033 - val_loss: 0.0063\n",
            "Epoch 338/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0065\n",
            "Epoch 339/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0064\n",
            "Epoch 340/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0063\n",
            "Epoch 341/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0064\n",
            "Epoch 342/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0067\n",
            "Epoch 343/1500\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 344/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0069\n",
            "Epoch 345/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0065\n",
            "Epoch 346/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0066\n",
            "Epoch 347/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0069\n",
            "Epoch 348/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0064\n",
            "Epoch 349/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0067\n",
            "Epoch 350/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0063\n",
            "Epoch 351/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0064\n",
            "Epoch 352/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 353/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0065\n",
            "Epoch 354/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0032 - val_loss: 0.0066\n",
            "Epoch 355/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0063\n",
            "Epoch 356/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0064\n",
            "Epoch 357/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0065\n",
            "Epoch 358/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0063\n",
            "Epoch 359/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0069\n",
            "Epoch 360/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0030 - val_loss: 0.0064\n",
            "Epoch 361/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0064\n",
            "Epoch 362/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0067\n",
            "Epoch 363/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0068\n",
            "Epoch 364/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0063\n",
            "Epoch 365/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0064\n",
            "Epoch 366/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0066\n",
            "Epoch 367/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0030 - val_loss: 0.0062\n",
            "Epoch 368/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0066\n",
            "Epoch 369/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0032 - val_loss: 0.0064\n",
            "Epoch 370/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0067\n",
            "Epoch 371/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0061\n",
            "Epoch 372/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0063\n",
            "Epoch 373/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0030 - val_loss: 0.0065\n",
            "Epoch 374/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0062\n",
            "Epoch 375/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0066\n",
            "Epoch 376/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0064\n",
            "Epoch 377/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0070\n",
            "Epoch 378/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0068\n",
            "Epoch 379/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0064\n",
            "Epoch 380/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0065\n",
            "Epoch 381/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0068\n",
            "Epoch 382/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0070\n",
            "Epoch 383/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0075\n",
            "Epoch 384/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0074\n",
            "Epoch 385/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0067\n",
            "Epoch 386/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0070\n",
            "Epoch 387/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0065\n",
            "Epoch 388/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0067\n",
            "Epoch 389/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0065\n",
            "Epoch 390/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0063\n",
            "Epoch 391/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0065\n",
            "Epoch 392/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0069\n",
            "Epoch 393/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 0.0063\n",
            "Epoch 394/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0064\n",
            "Epoch 395/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0064\n",
            "Epoch 396/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0066\n",
            "Epoch 397/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0063\n",
            "Epoch 398/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0062\n",
            "Epoch 399/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0065\n",
            "Epoch 400/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0069\n",
            "Epoch 401/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0070\n",
            "Epoch 402/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0067\n",
            "Epoch 403/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0070\n",
            "Epoch 404/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0072\n",
            "Epoch 405/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0065\n",
            "Epoch 406/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0070\n",
            "Epoch 407/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0067\n",
            "Epoch 408/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0062\n",
            "Epoch 409/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0068\n",
            "Epoch 410/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0067\n",
            "Epoch 411/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0066\n",
            "Epoch 412/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.0062\n",
            "Epoch 413/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0064\n",
            "Epoch 414/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0063\n",
            "Epoch 415/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0027 - val_loss: 0.0068\n",
            "Epoch 416/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0066\n",
            "Epoch 417/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0066\n",
            "Epoch 418/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0066\n",
            "Epoch 419/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0063\n",
            "Epoch 420/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0064\n",
            "Epoch 421/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0067\n",
            "Epoch 422/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0067\n",
            "Epoch 423/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0027 - val_loss: 0.0068\n",
            "Epoch 424/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0065\n",
            "Epoch 425/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0064\n",
            "Epoch 426/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0065\n",
            "Epoch 427/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0073\n",
            "Epoch 428/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0069\n",
            "Epoch 429/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0066\n",
            "Epoch 430/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0072\n",
            "Epoch 431/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0069\n",
            "Epoch 432/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0029 - val_loss: 0.0065\n",
            "Epoch 433/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0027 - val_loss: 0.0067\n",
            "Epoch 434/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0066\n",
            "Epoch 435/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0063\n",
            "Epoch 436/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0067\n",
            "Epoch 437/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0072\n",
            "Epoch 438/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 0.0066\n",
            "Epoch 439/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0065\n",
            "Epoch 440/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.0065\n",
            "Epoch 441/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.0066\n",
            "Epoch 442/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0064\n",
            "Epoch 443/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 444/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0062\n",
            "Epoch 445/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0065\n",
            "Epoch 446/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0063\n",
            "Epoch 447/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0063\n",
            "Epoch 448/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0068\n",
            "Epoch 449/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0062\n",
            "Epoch 450/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.0064\n",
            "Epoch 451/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0064\n",
            "Epoch 452/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0063\n",
            "Epoch 453/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.0065\n",
            "Epoch 454/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.0065\n",
            "Epoch 455/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.0064\n",
            "Epoch 456/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 0.0066\n",
            "Epoch 457/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0064\n",
            "Epoch 458/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0028 - val_loss: 0.0066\n",
            "Epoch 459/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 460/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0026 - val_loss: 0.0065\n",
            "Epoch 461/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0068\n",
            "Epoch 462/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 463/1500\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.0028 - val_loss: 0.0061\n",
            "Epoch 464/1500\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0026 - val_loss: 0.0061\n",
            "Epoch 465/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0028 - val_loss: 0.0068\n",
            "Epoch 466/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 467/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0064\n",
            "Epoch 468/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0064\n",
            "Epoch 469/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0065\n",
            "Epoch 470/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0062\n",
            "Epoch 471/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0063\n",
            "Epoch 472/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0065\n",
            "Epoch 473/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0065\n",
            "Epoch 474/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0070\n",
            "Epoch 475/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0073\n",
            "Epoch 476/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0080\n",
            "Epoch 477/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 0.0066\n",
            "Epoch 478/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0069\n",
            "Epoch 479/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0062\n",
            "Epoch 480/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0064\n",
            "Epoch 481/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0024 - val_loss: 0.0063\n",
            "Epoch 482/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0068\n",
            "Epoch 483/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0063\n",
            "Epoch 484/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0064\n",
            "Epoch 485/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0062\n",
            "Epoch 486/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0069\n",
            "Epoch 487/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0061\n",
            "Epoch 488/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0070\n",
            "Epoch 489/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0069\n",
            "Epoch 490/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0069\n",
            "Epoch 491/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0063\n",
            "Epoch 492/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0066\n",
            "Epoch 493/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 0.0063\n",
            "Epoch 494/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0067\n",
            "Epoch 495/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0064\n",
            "Epoch 496/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0062\n",
            "Epoch 497/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0068\n",
            "Epoch 498/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 499/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0075\n",
            "Epoch 500/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0063\n",
            "Epoch 501/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0063\n",
            "Epoch 502/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 503/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0066\n",
            "Epoch 504/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0028 - val_loss: 0.0061\n",
            "Epoch 505/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0064\n",
            "Epoch 506/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0067\n",
            "Epoch 507/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0071\n",
            "Epoch 508/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 0.0063\n",
            "Epoch 509/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0064\n",
            "Epoch 510/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0064\n",
            "Epoch 511/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0066\n",
            "Epoch 512/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0067\n",
            "Epoch 513/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0061\n",
            "Epoch 514/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0067\n",
            "Epoch 515/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 0.0061\n",
            "Epoch 516/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0063\n",
            "Epoch 517/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0062\n",
            "Epoch 518/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0074\n",
            "Epoch 519/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0027 - val_loss: 0.0063\n",
            "Epoch 520/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0064\n",
            "Epoch 521/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0069\n",
            "Epoch 522/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0063\n",
            "Epoch 523/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0065\n",
            "Epoch 524/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0026 - val_loss: 0.0065\n",
            "Epoch 525/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0063\n",
            "Epoch 526/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0067\n",
            "Epoch 527/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0066\n",
            "Epoch 528/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0071\n",
            "Epoch 529/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.0068\n",
            "Epoch 530/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0026 - val_loss: 0.0070\n",
            "Epoch 531/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0025 - val_loss: 0.0063\n",
            "Epoch 532/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0066\n",
            "Epoch 533/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 534/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0074\n",
            "Epoch 535/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0071\n",
            "Epoch 536/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0064\n",
            "Epoch 537/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0023 - val_loss: 0.0068\n",
            "Epoch 538/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0080\n",
            "Epoch 539/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0023 - val_loss: 0.0060\n",
            "Epoch 540/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0067\n",
            "Epoch 541/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0063\n",
            "Epoch 542/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0068\n",
            "Epoch 543/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0064\n",
            "Epoch 544/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0068\n",
            "Epoch 545/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0072\n",
            "Epoch 546/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0024 - val_loss: 0.0065\n",
            "Epoch 547/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0061\n",
            "Epoch 548/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0062\n",
            "Epoch 549/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0063\n",
            "Epoch 550/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 551/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 552/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0072\n",
            "Epoch 553/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0066\n",
            "Epoch 554/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0061\n",
            "Epoch 555/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0065\n",
            "Epoch 556/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0064\n",
            "Epoch 557/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0064\n",
            "Epoch 558/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0066\n",
            "Epoch 559/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0064\n",
            "Epoch 560/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0069\n",
            "Epoch 561/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0068\n",
            "Epoch 562/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0065\n",
            "Epoch 563/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 564/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 565/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0062\n",
            "Epoch 566/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0068\n",
            "Epoch 567/1500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0066\n",
            "Epoch 568/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0062\n",
            "Epoch 569/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0063\n",
            "Epoch 570/1500\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.0059\n",
            "Epoch 571/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0064\n",
            "Epoch 572/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0069\n",
            "Epoch 573/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 0.0066\n",
            "Epoch 574/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 575/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0063\n",
            "Epoch 576/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0062\n",
            "Epoch 577/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0060\n",
            "Epoch 578/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0065\n",
            "Epoch 579/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0066\n",
            "Epoch 580/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0062\n",
            "Epoch 581/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0062\n",
            "Epoch 582/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0060\n",
            "Epoch 583/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0061\n",
            "Epoch 584/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 0.0071\n",
            "Epoch 585/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0061\n",
            "Epoch 586/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 0.0066\n",
            "Epoch 587/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0070\n",
            "Epoch 588/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0065\n",
            "Epoch 589/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0064\n",
            "Epoch 590/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0059\n",
            "Epoch 591/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0064\n",
            "Epoch 592/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0068\n",
            "Epoch 593/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0068\n",
            "Epoch 594/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0066\n",
            "Epoch 595/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0021 - val_loss: 0.0058\n",
            "Epoch 596/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0068\n",
            "Epoch 597/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 598/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 599/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0062\n",
            "Epoch 600/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0060\n",
            "Epoch 601/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0064\n",
            "Epoch 602/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0063\n",
            "Epoch 603/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0064\n",
            "Epoch 604/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0064\n",
            "Epoch 605/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0062\n",
            "Epoch 606/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0058\n",
            "Epoch 607/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0061\n",
            "Epoch 608/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0060\n",
            "Epoch 609/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0059\n",
            "Epoch 610/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 611/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0058\n",
            "Epoch 612/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0067\n",
            "Epoch 613/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0061\n",
            "Epoch 614/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0059\n",
            "Epoch 615/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0066\n",
            "Epoch 616/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0064\n",
            "Epoch 617/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 618/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 619/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0071\n",
            "Epoch 620/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0067\n",
            "Epoch 621/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0059\n",
            "Epoch 622/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0065\n",
            "Epoch 623/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0060\n",
            "Epoch 624/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0064\n",
            "Epoch 625/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0065\n",
            "Epoch 626/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0059\n",
            "Epoch 627/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 628/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0061\n",
            "Epoch 629/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0064\n",
            "Epoch 630/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0065\n",
            "Epoch 631/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0065\n",
            "Epoch 632/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0058\n",
            "Epoch 633/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0061\n",
            "Epoch 634/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0065\n",
            "Epoch 635/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0065\n",
            "Epoch 636/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0062\n",
            "Epoch 637/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0072\n",
            "Epoch 638/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0020 - val_loss: 0.0057\n",
            "Epoch 639/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0065\n",
            "Epoch 640/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0020 - val_loss: 0.0060\n",
            "Epoch 641/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0058\n",
            "Epoch 642/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0058\n",
            "Epoch 643/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 644/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0064\n",
            "Epoch 645/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0064\n",
            "Epoch 646/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 647/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0061\n",
            "Epoch 648/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0059\n",
            "Epoch 649/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0064\n",
            "Epoch 650/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0062\n",
            "Epoch 651/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0069\n",
            "Epoch 652/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0070\n",
            "Epoch 653/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0068\n",
            "Epoch 654/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0061\n",
            "Epoch 655/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0062\n",
            "Epoch 656/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0067\n",
            "Epoch 657/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0019 - val_loss: 0.0064\n",
            "Epoch 658/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0061\n",
            "Epoch 659/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0061\n",
            "Epoch 660/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0062\n",
            "Epoch 661/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0062\n",
            "Epoch 662/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0066\n",
            "Epoch 663/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0065\n",
            "Epoch 664/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0061\n",
            "Epoch 665/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0063\n",
            "Epoch 666/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0062\n",
            "Epoch 667/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0059\n",
            "Epoch 668/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0062\n",
            "Epoch 669/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0064\n",
            "Epoch 670/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0058\n",
            "Epoch 671/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0062\n",
            "Epoch 672/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0064\n",
            "Epoch 673/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0018 - val_loss: 0.0057\n",
            "Epoch 674/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0060\n",
            "Epoch 675/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0061\n",
            "Epoch 676/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0059\n",
            "Epoch 677/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0063\n",
            "Epoch 678/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 679/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0062\n",
            "Epoch 680/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0063\n",
            "Epoch 681/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 682/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0072\n",
            "Epoch 683/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0057\n",
            "Epoch 684/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0062\n",
            "Epoch 685/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0063\n",
            "Epoch 686/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 687/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 0.0063\n",
            "Epoch 688/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0019 - val_loss: 0.0065\n",
            "Epoch 689/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0063\n",
            "Epoch 690/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 691/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0065\n",
            "Epoch 692/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0061\n",
            "Epoch 693/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0067\n",
            "Epoch 694/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0067\n",
            "Epoch 695/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0065\n",
            "Epoch 696/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0069\n",
            "Epoch 697/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0065\n",
            "Epoch 698/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 0.0063\n",
            "Epoch 699/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0058\n",
            "Epoch 700/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 701/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 702/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0072\n",
            "Epoch 703/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0022 - val_loss: 0.0067\n",
            "Epoch 704/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0071\n",
            "Epoch 705/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 706/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0020 - val_loss: 0.0062\n",
            "Epoch 707/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0063\n",
            "Epoch 708/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 709/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0061\n",
            "Epoch 710/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 711/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0062\n",
            "Epoch 712/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0021 - val_loss: 0.0062\n",
            "Epoch 713/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0061\n",
            "Epoch 714/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0061\n",
            "Epoch 715/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0065\n",
            "Epoch 716/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0066\n",
            "Epoch 717/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 718/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0062\n",
            "Epoch 719/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 720/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 0.0060\n",
            "Epoch 721/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0061\n",
            "Epoch 722/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 723/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0061\n",
            "Epoch 724/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0058\n",
            "Epoch 725/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0059\n",
            "Epoch 726/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 727/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0066\n",
            "Epoch 728/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 729/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 730/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0064\n",
            "Epoch 731/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 732/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0069\n",
            "Epoch 733/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0068\n",
            "Epoch 734/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 735/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 0.0067\n",
            "Epoch 736/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0056\n",
            "Epoch 737/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0064\n",
            "Epoch 738/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0063\n",
            "Epoch 739/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0078\n",
            "Epoch 740/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 741/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 742/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 743/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0062\n",
            "Epoch 744/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 745/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 746/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0060\n",
            "Epoch 747/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0072\n",
            "Epoch 748/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0019 - val_loss: 0.0072\n",
            "Epoch 749/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0065\n",
            "Epoch 750/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 751/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0061\n",
            "Epoch 752/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0064\n",
            "Epoch 753/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0059\n",
            "Epoch 754/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 755/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0065\n",
            "Epoch 756/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0078\n",
            "Epoch 757/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 758/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0059\n",
            "Epoch 759/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 0.0072\n",
            "Epoch 760/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 761/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0068\n",
            "Epoch 762/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0060\n",
            "Epoch 763/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0017 - val_loss: 0.0065\n",
            "Epoch 764/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0062\n",
            "Epoch 765/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 766/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0056\n",
            "Epoch 767/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 768/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0062\n",
            "Epoch 769/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 770/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0060\n",
            "Epoch 771/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0063\n",
            "Epoch 772/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0064\n",
            "Epoch 773/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0060\n",
            "Epoch 774/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 775/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0070\n",
            "Epoch 776/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0065\n",
            "Epoch 777/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 778/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0062\n",
            "Epoch 779/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 780/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0062\n",
            "Epoch 781/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0067\n",
            "Epoch 782/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0060\n",
            "Epoch 783/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 784/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0072\n",
            "Epoch 785/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0064\n",
            "Epoch 786/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0056\n",
            "Epoch 787/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0064\n",
            "Epoch 788/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0062\n",
            "Epoch 789/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0059\n",
            "Epoch 790/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0065\n",
            "Epoch 791/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0057\n",
            "Epoch 792/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0063\n",
            "Epoch 793/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0075\n",
            "Epoch 794/1500\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 795/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0063\n",
            "Epoch 796/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0066\n",
            "Epoch 797/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0062\n",
            "Epoch 798/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0063\n",
            "Epoch 799/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0062\n",
            "Epoch 800/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0067\n",
            "Epoch 801/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0065\n",
            "Epoch 802/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0059\n",
            "Epoch 803/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0018 - val_loss: 0.0061\n",
            "Epoch 804/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0063\n",
            "Epoch 805/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0072\n",
            "Epoch 806/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 807/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0067\n",
            "Epoch 808/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 809/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 810/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0016 - val_loss: 0.0064\n",
            "Epoch 811/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 812/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0067\n",
            "Epoch 813/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0062\n",
            "Epoch 814/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0058\n",
            "Epoch 815/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0064\n",
            "Epoch 816/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0063\n",
            "Epoch 817/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0057\n",
            "Epoch 818/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0057\n",
            "Epoch 819/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0070\n",
            "Epoch 820/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0057\n",
            "Epoch 821/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0062\n",
            "Epoch 822/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 823/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 824/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0065\n",
            "Epoch 825/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0060\n",
            "Epoch 826/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0060\n",
            "Epoch 827/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0077\n",
            "Epoch 828/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 829/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.0059\n",
            "Epoch 830/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0060\n",
            "Epoch 831/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.0058\n",
            "Epoch 832/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0070\n",
            "Epoch 833/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0063\n",
            "Epoch 834/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0061\n",
            "Epoch 835/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0059\n",
            "Epoch 836/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0063\n",
            "Epoch 837/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 838/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 839/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0065\n",
            "Epoch 840/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0060\n",
            "Epoch 841/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0062\n",
            "Epoch 842/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 843/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 844/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0058\n",
            "Epoch 845/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0066\n",
            "Epoch 846/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0062\n",
            "Epoch 847/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0064\n",
            "Epoch 848/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 849/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0058\n",
            "Epoch 850/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0062\n",
            "Epoch 851/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0061\n",
            "Epoch 852/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.0062\n",
            "Epoch 853/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0062\n",
            "Epoch 854/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0015 - val_loss: 0.0058\n",
            "Epoch 855/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0065\n",
            "Epoch 856/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0070\n",
            "Epoch 857/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0059\n",
            "Epoch 858/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 859/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0063\n",
            "Epoch 860/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0061\n",
            "Epoch 861/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0058\n",
            "Epoch 862/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0065\n",
            "Epoch 863/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0066\n",
            "Epoch 864/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0059\n",
            "Epoch 865/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0062\n",
            "Epoch 866/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 0.0063\n",
            "Epoch 867/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0064\n",
            "Epoch 868/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0059\n",
            "Epoch 869/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0059\n",
            "Epoch 870/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0063\n",
            "Epoch 871/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0061\n",
            "Epoch 872/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 873/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0058\n",
            "Epoch 874/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0064\n",
            "Epoch 875/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0064\n",
            "Epoch 876/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0058\n",
            "Epoch 877/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0058\n",
            "Epoch 878/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0062\n",
            "Epoch 879/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0066\n",
            "Epoch 880/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 881/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0062\n",
            "Epoch 882/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.0063\n",
            "Epoch 883/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0056\n",
            "Epoch 884/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0066\n",
            "Epoch 885/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0060\n",
            "Epoch 886/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0061\n",
            "Epoch 887/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0061\n",
            "Epoch 888/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0059\n",
            "Epoch 889/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 0.0058\n",
            "Epoch 890/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0063\n",
            "Epoch 891/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0058\n",
            "Epoch 892/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 0.0064\n",
            "Epoch 893/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0062\n",
            "Epoch 894/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 895/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0059\n",
            "Epoch 896/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0061\n",
            "Epoch 897/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 0.0070\n",
            "Epoch 898/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0059\n",
            "Epoch 899/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0064\n",
            "Epoch 900/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0066\n",
            "Epoch 901/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0064\n",
            "Epoch 902/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0066\n",
            "Epoch 903/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0065\n",
            "Epoch 904/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 905/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 906/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 0.0061\n",
            "Epoch 907/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0067\n",
            "Epoch 908/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0067\n",
            "Epoch 909/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0059\n",
            "Epoch 910/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0067\n",
            "Epoch 911/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0060\n",
            "Epoch 912/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 913/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0014 - val_loss: 0.0071\n",
            "Epoch 914/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0059\n",
            "Epoch 915/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0065\n",
            "Epoch 916/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0061\n",
            "Epoch 917/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0058\n",
            "Epoch 918/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 919/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0060\n",
            "Epoch 920/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0059\n",
            "Epoch 921/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 922/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0064\n",
            "Epoch 923/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0059\n",
            "Epoch 924/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0064\n",
            "Epoch 925/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0065\n",
            "Epoch 926/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0013 - val_loss: 0.0055\n",
            "Epoch 927/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 928/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0075\n",
            "Epoch 929/1500\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 930/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 931/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0057\n",
            "Epoch 932/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0059\n",
            "Epoch 933/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0060\n",
            "Epoch 934/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0061\n",
            "Epoch 935/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 936/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 937/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 938/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 939/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 940/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0061\n",
            "Epoch 941/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 942/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0061\n",
            "Epoch 943/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0064\n",
            "Epoch 944/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0057\n",
            "Epoch 945/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0059\n",
            "Epoch 946/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0060\n",
            "Epoch 947/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0065\n",
            "Epoch 948/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0063\n",
            "Epoch 949/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0062\n",
            "Epoch 950/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0056\n",
            "Epoch 951/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0057\n",
            "Epoch 952/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0058\n",
            "Epoch 953/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0064\n",
            "Epoch 954/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0059\n",
            "Epoch 955/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0059\n",
            "Epoch 956/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0058\n",
            "Epoch 957/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 958/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0059\n",
            "Epoch 959/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 960/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0059\n",
            "Epoch 961/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0058\n",
            "Epoch 962/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 963/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0065\n",
            "Epoch 964/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0064\n",
            "Epoch 965/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0058\n",
            "Epoch 966/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 967/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 968/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0059\n",
            "Epoch 969/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 970/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0060\n",
            "Epoch 971/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0070\n",
            "Epoch 972/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0056\n",
            "Epoch 973/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 974/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0061\n",
            "Epoch 975/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0060\n",
            "Epoch 976/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0058\n",
            "Epoch 977/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 978/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 979/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 0.0063\n",
            "Epoch 980/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0057\n",
            "Epoch 981/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0070\n",
            "Epoch 982/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0059\n",
            "Epoch 983/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0061\n",
            "Epoch 984/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0061\n",
            "Epoch 985/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 986/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0064\n",
            "Epoch 987/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0060\n",
            "Epoch 988/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0061\n",
            "Epoch 989/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0068\n",
            "Epoch 990/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 991/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0061\n",
            "Epoch 992/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0056\n",
            "Epoch 993/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 994/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 995/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 996/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 997/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.9498e-04 - val_loss: 0.0059\n",
            "Epoch 998/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 999/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0058\n",
            "Epoch 1000/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0065\n",
            "Epoch 1001/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0061\n",
            "Epoch 1002/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0065\n",
            "Epoch 1003/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0061\n",
            "Epoch 1004/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.0204e-04 - val_loss: 0.0064\n",
            "Epoch 1005/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 1006/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0067\n",
            "Epoch 1007/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0066\n",
            "Epoch 1008/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0058\n",
            "Epoch 1009/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0056\n",
            "Epoch 1010/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0066\n",
            "Epoch 1011/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0061\n",
            "Epoch 1012/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 1013/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0065\n",
            "Epoch 1014/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0060\n",
            "Epoch 1015/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0060\n",
            "Epoch 1016/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 1017/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0066\n",
            "Epoch 1018/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0058\n",
            "Epoch 1019/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 1020/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0059\n",
            "Epoch 1021/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0060\n",
            "Epoch 1022/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0070\n",
            "Epoch 1023/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 1024/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 1025/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0065\n",
            "Epoch 1026/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0060\n",
            "Epoch 1027/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0064\n",
            "Epoch 1028/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0061\n",
            "Epoch 1029/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0058\n",
            "Epoch 1030/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.8412e-04 - val_loss: 0.0061\n",
            "Epoch 1031/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 1032/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 1033/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0064\n",
            "Epoch 1034/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.8976e-04 - val_loss: 0.0064\n",
            "Epoch 1035/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0056\n",
            "Epoch 1036/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 1037/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0066\n",
            "Epoch 1038/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0069\n",
            "Epoch 1039/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.9503e-04 - val_loss: 0.0058\n",
            "Epoch 1040/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0061\n",
            "Epoch 1041/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0065\n",
            "Epoch 1042/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0065\n",
            "Epoch 1043/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0061\n",
            "Epoch 1044/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 1045/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0058\n",
            "Epoch 1046/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 1047/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0066\n",
            "Epoch 1048/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0056\n",
            "Epoch 1049/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 1050/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.9226e-04 - val_loss: 0.0061\n",
            "Epoch 1051/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 1052/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0060\n",
            "Epoch 1053/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0061\n",
            "Epoch 1054/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.6636e-04 - val_loss: 0.0059\n",
            "Epoch 1055/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0066\n",
            "Epoch 1056/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 1057/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0063\n",
            "Epoch 1058/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0061\n",
            "Epoch 1059/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.1483e-04 - val_loss: 0.0058\n",
            "Epoch 1060/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 1061/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.8472e-04 - val_loss: 0.0060\n",
            "Epoch 1062/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.0177e-04 - val_loss: 0.0060\n",
            "Epoch 1063/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0058\n",
            "Epoch 1064/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 1065/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 1066/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.9919e-04 - val_loss: 0.0063\n",
            "Epoch 1067/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.7675e-04 - val_loss: 0.0059\n",
            "Epoch 1068/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0064\n",
            "Epoch 1069/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 1070/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.6923e-04 - val_loss: 0.0059\n",
            "Epoch 1071/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0058\n",
            "Epoch 1072/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.8434e-04 - val_loss: 0.0064\n",
            "Epoch 1073/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0070\n",
            "Epoch 1074/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 1075/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0071\n",
            "Epoch 1076/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0065\n",
            "Epoch 1077/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0066\n",
            "Epoch 1078/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 1079/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.3609e-04 - val_loss: 0.0063\n",
            "Epoch 1080/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 1081/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.4278e-04 - val_loss: 0.0060\n",
            "Epoch 1082/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0058\n",
            "Epoch 1083/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.7210e-04 - val_loss: 0.0063\n",
            "Epoch 1084/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.6678e-04 - val_loss: 0.0065\n",
            "Epoch 1085/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.8825e-04 - val_loss: 0.0060\n",
            "Epoch 1086/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.4484e-04 - val_loss: 0.0062\n",
            "Epoch 1087/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0064\n",
            "Epoch 1088/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 1089/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.3481e-04 - val_loss: 0.0062\n",
            "Epoch 1090/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0057\n",
            "Epoch 1091/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0069\n",
            "Epoch 1092/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0012 - val_loss: 0.0058\n",
            "Epoch 1093/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0061\n",
            "Epoch 1094/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0065\n",
            "Epoch 1095/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0056\n",
            "Epoch 1096/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0060\n",
            "Epoch 1097/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0065\n",
            "Epoch 1098/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.2853e-04 - val_loss: 0.0060\n",
            "Epoch 1099/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.2327e-04 - val_loss: 0.0065\n",
            "Epoch 1100/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0058\n",
            "Epoch 1101/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.2623e-04 - val_loss: 0.0062\n",
            "Epoch 1102/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 1103/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0058\n",
            "Epoch 1104/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.6594e-04 - val_loss: 0.0058\n",
            "Epoch 1105/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0061\n",
            "Epoch 1106/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.9415e-04 - val_loss: 0.0065\n",
            "Epoch 1107/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0060\n",
            "Epoch 1108/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.9448e-04 - val_loss: 0.0059\n",
            "Epoch 1109/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0061\n",
            "Epoch 1110/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.7273e-04 - val_loss: 0.0062\n",
            "Epoch 1111/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0066\n",
            "Epoch 1112/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.9245e-04 - val_loss: 0.0060\n",
            "Epoch 1113/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.8584e-04 - val_loss: 0.0065\n",
            "Epoch 1114/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0064\n",
            "Epoch 1115/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0063\n",
            "Epoch 1116/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0059\n",
            "Epoch 1117/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.9378e-04 - val_loss: 0.0066\n",
            "Epoch 1118/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0060\n",
            "Epoch 1119/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.7447e-04 - val_loss: 0.0062\n",
            "Epoch 1120/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0064\n",
            "Epoch 1121/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.8980e-04 - val_loss: 0.0063\n",
            "Epoch 1122/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 1123/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.1621e-04 - val_loss: 0.0069\n",
            "Epoch 1124/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0064\n",
            "Epoch 1125/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0012 - val_loss: 0.0061\n",
            "Epoch 1126/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0067\n",
            "Epoch 1127/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 1128/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 1129/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.7805e-04 - val_loss: 0.0070\n",
            "Epoch 1130/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.7900e-04 - val_loss: 0.0063\n",
            "Epoch 1131/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0059\n",
            "Epoch 1132/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0065\n",
            "Epoch 1133/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0058\n",
            "Epoch 1134/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.8594e-04 - val_loss: 0.0063\n",
            "Epoch 1135/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.5481e-04 - val_loss: 0.0058\n",
            "Epoch 1136/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 1137/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.8754e-04 - val_loss: 0.0061\n",
            "Epoch 1138/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.9994e-04 - val_loss: 0.0067\n",
            "Epoch 1139/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.7883e-04 - val_loss: 0.0060\n",
            "Epoch 1140/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.1852e-04 - val_loss: 0.0060\n",
            "Epoch 1141/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.1172e-04 - val_loss: 0.0063\n",
            "Epoch 1142/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.7616e-04 - val_loss: 0.0059\n",
            "Epoch 1143/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.1901e-04 - val_loss: 0.0063\n",
            "Epoch 1144/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.7825e-04 - val_loss: 0.0065\n",
            "Epoch 1145/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.7399e-04 - val_loss: 0.0063\n",
            "Epoch 1146/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.6337e-04 - val_loss: 0.0063\n",
            "Epoch 1147/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.8901e-04 - val_loss: 0.0059\n",
            "Epoch 1148/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.2126e-04 - val_loss: 0.0068\n",
            "Epoch 1149/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 1150/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.4362e-04 - val_loss: 0.0062\n",
            "Epoch 1151/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.3189e-04 - val_loss: 0.0062\n",
            "Epoch 1152/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.2397e-04 - val_loss: 0.0065\n",
            "Epoch 1153/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0069\n",
            "Epoch 1154/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.2038e-04 - val_loss: 0.0062\n",
            "Epoch 1155/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 1156/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0068\n",
            "Epoch 1157/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.7063e-04 - val_loss: 0.0068\n",
            "Epoch 1158/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.9836e-04 - val_loss: 0.0063\n",
            "Epoch 1159/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.9401e-04 - val_loss: 0.0060\n",
            "Epoch 1160/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.0296e-04 - val_loss: 0.0060\n",
            "Epoch 1161/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.5081e-04 - val_loss: 0.0061\n",
            "Epoch 1162/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.8060e-04 - val_loss: 0.0060\n",
            "Epoch 1163/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.7221e-04 - val_loss: 0.0068\n",
            "Epoch 1164/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0058\n",
            "Epoch 1165/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.1756e-04 - val_loss: 0.0057\n",
            "Epoch 1166/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.0598e-04 - val_loss: 0.0066\n",
            "Epoch 1167/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.2611e-04 - val_loss: 0.0057\n",
            "Epoch 1168/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0011 - val_loss: 0.0063\n",
            "Epoch 1169/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 1170/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.9086e-04 - val_loss: 0.0068\n",
            "Epoch 1171/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.1449e-04 - val_loss: 0.0061\n",
            "Epoch 1172/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.3294e-04 - val_loss: 0.0062\n",
            "Epoch 1173/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 0.0061\n",
            "Epoch 1174/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4968e-04 - val_loss: 0.0059\n",
            "Epoch 1175/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.8487e-04 - val_loss: 0.0065\n",
            "Epoch 1176/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.1986e-04 - val_loss: 0.0060\n",
            "Epoch 1177/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.3205e-04 - val_loss: 0.0066\n",
            "Epoch 1178/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.8487e-04 - val_loss: 0.0056\n",
            "Epoch 1179/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.3975e-04 - val_loss: 0.0065\n",
            "Epoch 1180/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.4476e-04 - val_loss: 0.0067\n",
            "Epoch 1181/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.2401e-04 - val_loss: 0.0060\n",
            "Epoch 1182/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0061\n",
            "Epoch 1183/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.1074e-04 - val_loss: 0.0060\n",
            "Epoch 1184/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.0875e-04 - val_loss: 0.0061\n",
            "Epoch 1185/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.6537e-04 - val_loss: 0.0056\n",
            "Epoch 1186/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.3874e-04 - val_loss: 0.0065\n",
            "Epoch 1187/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.4065e-04 - val_loss: 0.0071\n",
            "Epoch 1188/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.1578e-04 - val_loss: 0.0063\n",
            "Epoch 1189/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.0639e-04 - val_loss: 0.0064\n",
            "Epoch 1190/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.0381e-04 - val_loss: 0.0058\n",
            "Epoch 1191/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.5364e-04 - val_loss: 0.0064\n",
            "Epoch 1192/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0060\n",
            "Epoch 1193/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 7.9503e-04 - val_loss: 0.0064\n",
            "Epoch 1194/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.4101e-04 - val_loss: 0.0064\n",
            "Epoch 1195/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.9727e-04 - val_loss: 0.0067\n",
            "Epoch 1196/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.9081e-04 - val_loss: 0.0060\n",
            "Epoch 1197/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.3452e-04 - val_loss: 0.0066\n",
            "Epoch 1198/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.3261e-04 - val_loss: 0.0063\n",
            "Epoch 1199/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.1232e-04 - val_loss: 0.0067\n",
            "Epoch 1200/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.1196e-04 - val_loss: 0.0058\n",
            "Epoch 1201/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.7596e-04 - val_loss: 0.0064\n",
            "Epoch 1202/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3190e-04 - val_loss: 0.0063\n",
            "Epoch 1203/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 9.6927e-04 - val_loss: 0.0060\n",
            "Epoch 1204/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.4951e-04 - val_loss: 0.0061\n",
            "Epoch 1205/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.4428e-04 - val_loss: 0.0062\n",
            "Epoch 1206/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 7.9340e-04 - val_loss: 0.0062\n",
            "Epoch 1207/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.8475e-04 - val_loss: 0.0061\n",
            "Epoch 1208/1500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 8.8290e-04 - val_loss: 0.0059\n",
            "Epoch 1209/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.5791e-04 - val_loss: 0.0057\n",
            "Epoch 1210/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 1211/1500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0067\n",
            "Epoch 1212/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.8260e-04 - val_loss: 0.0061\n",
            "Epoch 1213/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.3149e-04 - val_loss: 0.0055\n",
            "Epoch 1214/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.7071e-04 - val_loss: 0.0056\n",
            "Epoch 1215/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0062\n",
            "Epoch 1216/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 9.5676e-04 - val_loss: 0.0058\n",
            "Epoch 1217/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.5882e-04 - val_loss: 0.0062\n",
            "Epoch 1218/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.5057e-04 - val_loss: 0.0070\n",
            "Epoch 1219/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 8.3229e-04 - val_loss: 0.0058\n",
            "Epoch 1220/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.0807e-04 - val_loss: 0.0058\n",
            "Epoch 1221/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0010 - val_loss: 0.0075\n",
            "Epoch 1222/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 9.3417e-04 - val_loss: 0.0062\n",
            "Epoch 1223/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.2493e-04 - val_loss: 0.0062\n",
            "Epoch 1224/1500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 8.2830e-04 - val_loss: 0.0063\n",
            "Epoch 1225/1500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 7.9643e-04 - val_loss: 0.0062\n",
            "Epoch 1226/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.6486e-04 - val_loss: 0.0059\n",
            "Epoch 1227/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.5955e-04 - val_loss: 0.0063\n",
            "Epoch 1228/1500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.5960e-04 - val_loss: 0.0066\n",
            "Epoch 1229/1500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 8.9725e-04 - val_loss: 0.0060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg_tUmi6vi-t"
      },
      "source": [
        "# Load results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shsNGhJemnRm",
        "outputId": "e8882fc7-bff8-4f8a-d1ea-5dbf18ee1eaf"
      },
      "source": [
        "\n",
        "# LOAD KET QUA TOT NHAT\n",
        "# =============================================================================\n",
        "# Load results\n",
        "loaded_model=load_model(outs[0]+\"/\"+names0[n_out0-1]+str(k)+\"lead\"+str(m)+\"best_stop.keras\")\n",
        "print(\"Loaded model from disk\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDYTivqVvvBn"
      },
      "source": [
        "# Draw graphics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "5KfSXUOqmqb3",
        "outputId": "f06f705f-3c95-49c2-cf49-39f5fdba7201"
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "# DANH GIA\n",
        "# =============================================================================\n",
        "# # TONG KET \n",
        "# # DRAW LOSS CURVE\n",
        "# #Check the Loss curve\n",
        "# fig,ax=plt.subplots(figsize=(6,3))\n",
        "# plt.rcParams.update({'font.size': 11})\n",
        "# plt.plot(history1.history['loss'])\n",
        "# plt.plot(history1.history['val_loss'])\n",
        "# # Draw the minimum epochs \n",
        "# df_val_loss=pd.DataFrame({'val_loss':history1.history['val_loss']})\n",
        "# # print(df_val_loss)\n",
        "# idxmin=df_val_loss[['val_loss']].idxmin().values\n",
        "# val_loss_min_values=df_val_loss.loc[idxmin,:].values.flatten()\n",
        "# print(idxmin,val_loss_min_values)\n",
        "# plt.annotate('epochs at min_val_loss: '+str(idxmin[0]+1)+'\\n'+'min_val_loss: '+str(np.round(val_loss_min_values[0],3)),\n",
        "#              xy=(idxmin,val_loss_min_values), xycoords='data',\n",
        "#             xytext=(idxmin-50, val_loss_min_values+0.02), textcoords='data',\n",
        "#             arrowprops=dict(arrowstyle=\"->\",\n",
        "#                             connectionstyle=\"arc3\"),\n",
        "#             )\n",
        "\n",
        "# plt.legend(['train','val'])\n",
        "# plt.xlabel('epochs')\n",
        "# plt.ylabel('mse')\n",
        "# # plt.title('learning rate of 1 month leadtime prdiction')\n",
        "plt.tight_layout()\n",
        "plt.savefig(outs[3]+'/'+names[n_out0-1]+str(k)+'loss_curve_T3'+str(m)+'.jpeg',dpi=300)\n",
        "plt.show(fig)\n",
        "plt.close(fig)\n",
        "###################################################################################\n",
        "#----------------------Important !!!!-----------------------#\n",
        "pred = loaded_model.predict(train_X)  #(predicted)  \n",
        "obs  = y_train_scale               #(obs) \n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "#----------------------reverse scaling------------------------------#\n",
        "#For training period\n",
        "\n",
        "y_hat_rescaled  = scaler_y.inverse_transform(pred) #prediction value\n",
        "y_rescaled = scaler_y.inverse_transform(obs)         #observed value\n",
        "\n",
        "#Inverse scaled --> pred, obs  \n",
        "pred = y_hat_rescaled\n",
        "obs = y_rescaled\n",
        "\n",
        "# pred1, obs1: pred train, obs train\n",
        "pred1=pred\n",
        "obs1=obs\n",
        "\n",
        "##########################################################\n",
        "# Validation\n",
        "pred = loaded_model.predict(val_X)  #(pred)  \n",
        "obs  = y_val_scale                 #(obs) \n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "#----------------------reverse scaling------------------------------#\n",
        "#For training period\n",
        "y_hat_rescaled  = scaler_y.inverse_transform(pred) #prediction value\n",
        "y_rescaled = scaler_y.inverse_transform(obs)         #observed value\n",
        "\n",
        "#Inverse scaled --> pred, obs  \n",
        "pred = y_hat_rescaled\n",
        "obs = y_rescaled\n",
        "\n",
        "# pred1, obs1: pred val, obs val\n",
        "pred2=pred\n",
        "obs2=obs\n",
        "\n",
        "################################################################\n",
        "pred = loaded_model.predict(test_X)  #(pred)  \n",
        "obs  = y_test_scale                 #(obs) \n",
        "#-----------------------------------------------------------#\n",
        "\n",
        "#----------------------reverse scaling------------------------------#\n",
        "#For training period\n",
        "y_hat_rescaled  = scaler_y.inverse_transform(pred) #prediction value\n",
        "y_rescaled = scaler_y.inverse_transform(obs)         #observed value\n",
        "\n",
        "#Inverse scaled --> pred, obs  \n",
        "pred = y_hat_rescaled\n",
        "obs = y_rescaled\n",
        "\n",
        "# pred1, obs1: pred val, obs val\n",
        "pred3=pred\n",
        "obs3=obs\n",
        "#--------------------------------------------------------------------#\n",
        "\n",
        "# TOM LAI\n",
        "list_con=list()\n",
        "df_train=pd.DataFrame({'obs':obs1.flatten(),'pred':pred1.flatten()})\n",
        "list_con.append(df_train)\n",
        "df_val=pd.DataFrame({'obs':obs2.flatten(),'pred':pred2.flatten()})\n",
        "list_con.append(df_val)\n",
        "df_test=pd.DataFrame({'obs':obs3.flatten(),'pred':pred3.flatten()})\n",
        "list_con.append(df_test)\n",
        "# =============================================================================\n",
        "# SAVE RESULTS\n",
        "# =============================================================================\n",
        "with open(outs[1]+'/'+names[n_out0-1]+str(k)+'lead'+str(m)+'T4_lag3.pkl', 'wb') as f: # khong nen\n",
        "  # compressed_file = bz2.BZ2File(f, 'w')\n",
        "  pickle.dump(list_con, f)\n",
        "\n",
        "#####\n",
        "## mo kiem tra lai\n",
        "with open(outs[1]+'/'+names[n_out0-1]+str(k)+'lead'+str(m)+'T4_lag3.pkl', 'rb') as f: # khong nen\n",
        "    # compressed_file = bz2.BZ2File(f, 'r')\n",
        "    load_list_con = pickle.load(f)\n",
        "# 0,1,2 tuong ung voi train, val, test\n",
        "# pearson,dotincay=pearsonr(load_list_con[1]['obs'],load_list_con[1]['pred'])\n",
        "# print('cc of val: '+str(pearson))\n",
        "# =============================================================================\n",
        "# VE HINH\n",
        "# =============================================================================\n",
        "# HINH  SCATTER\n",
        "# Ve hinh statter plot cua training, validation and testing\n",
        "\n",
        "# scale plot M1\n",
        "\n",
        "\n",
        "axes=[131,132,133]\n",
        "obs_all=[obs1,obs2,obs3]\n",
        "pred_all=[pred1,pred2,pred3]\n",
        "# lead_time=0\n",
        "names_phases=['training','validation','testing']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(9,3))\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "# lead_time=2\n",
        "  for phase in range(3):\n",
        "  # for lead_time in range(3):\n",
        "\n",
        "    plt.subplot(axes[phase])\n",
        "    pearson,dotincay=pearsonr(load_list_con[phase]['obs'],load_list_con[phase]['pred'])\n",
        "    r2_vanila_1m =pearson\n",
        "    plt.rcParams.update({'font.size': 12})\n",
        "    \n",
        "    min_values=-5.9\n",
        "    max_values=2.29\n",
        "\n",
        "    plt.xlim(min_values,max_values)\n",
        "    plt.ylim(min_values,max_values)\n",
        "\n",
        "    plt.scatter(x=load_list_con[phase]['obs'],\n",
        "                y=load_list_con[phase]['pred'],\n",
        "                s=None,\n",
        "                c='k', \n",
        "                marker='.', \n",
        "                cmap=None,\n",
        "                norm=None,\n",
        "                vmin=None, \n",
        "                vmax=None,\n",
        "                alpha=None,            \n",
        "                linewidths=None,\n",
        "                edgecolors=None,plotnonfinite=False,data=None)\n",
        "\n",
        "    # ve duong 45\n",
        "    # plt.legend(['NDI'])\n",
        "    plt.xlabel('obs')\n",
        "    if lead_time==0:\n",
        "      plt.ylabel('pred')\n",
        "    # if lead_time==1:\n",
        "    # plt.title('M1S4prs_prs '+names_phases[m])\n",
        "    # add_identity(ax, color='r', ls='--')\n",
        "    plt.text(min_values,min_values,'R= '+str(round(r2_vanila_1m,2)))\n",
        "    xpoints = ypoints = plt.xlim()\n",
        "    plt.plot(xpoints, ypoints, linestyle='--', color='r', lw=1, scalex=False, scaley=False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "  plt.savefig(outs[3]+'/'+names[n_out0]+str(k)+'train_time_T3'+str(m)+'.jpeg',dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "# =============================================================================\n",
        "#VE HINH TIME SERIES\n",
        "# =============================================================================\n",
        "  \n",
        "  # Ve TRAIN ***************************************************************\n",
        "# Time series cua train\n",
        "#Graph\n",
        "months=['1month','2months','3months']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(6,4))\n",
        "  plt.subplot(211)\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        " \n",
        "  vector_date=pd.date_range(start='1968-01',periods=df1.shape[0],freq='MS')\n",
        "  plt.plot(vector_date[0+lead_time:lead_time+int(obs1.shape[0]*0.5)],obs1[0:int(obs1.shape[0]*0.5),lead_time],'k-.')\n",
        "  plt.plot(vector_date[0+lead_time:lead_time+int(obs1.shape[0]*0.5)],pred1[0:int(obs1.shape[0]*0.5),lead_time],'r-.')\n",
        "\n",
        "  plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  # plt.title('Time series '+'1 month' +' lead time prediction at trainning')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.subplot(212)\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  \n",
        "  plt.plot(vector_date[lead_time+int(obs1.shape[0]*0.5):lead_time+int(obs1.shape[0]*1)],obs1[int(obs1.shape[0]*0.5):int(obs1.shape[0]*1),lead_time],'k-.')\n",
        "  plt.plot(vector_date[lead_time+int(obs1.shape[0]*0.5):lead_time+int(obs1.shape[0]*1)],pred1[int(pred1.shape[0]*0.5):int(pred1.shape[0]*1),lead_time],'r-.')\n",
        "  plt.ylabel('NDI')\n",
        "  plt.tight_layout()\n",
        "\n",
        "plt.savefig(outs[3]+'/'+names[n_out0]+str(k)+'train_time_T3'+str(m)+'.jpeg',dpi=300)\n",
        "plt.show()\n",
        "plt.close()\n",
        "############ VAL **************************************************************\n",
        "# Time series cua val\n",
        "#Graph\n",
        "months=['1month','2months','3months']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(6,3))\n",
        "  plt.subplot(111)\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  plt.plot(vector_date[n_train+lead_time:n_train+lead_time+obs2.shape[0]],obs2[:,lead_time],'k-.')\n",
        "  plt.plot(vector_date[n_train+lead_time:n_train+lead_time+obs2.shape[0]],pred2[:,lead_time],'r-.')\n",
        "  plt.legend(['obs','simulation'])\n",
        "  plt.ylabel('NDI')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  plt.savefig(outs[3]+'/'+names[n_out0-1]+str(k)+'val_time_T3'+str(m)+'.jpeg',dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "#   # TEST*************************************************************************\n",
        "  \n",
        "# #Graph\n",
        "# months=['1month','2months','3months']\n",
        "# for lead_time in range(1):\n",
        "#   fig,ax=plt.subplots(figsize=(6,3))\n",
        "#   plt.subplot(111)\n",
        "#   plt.rcParams.update({'font.size': 12})\n",
        "#   plt.ylim([-6.0,2.3])\n",
        "#   vector_date_test=vector_date[-24:]\n",
        "#   plt.plot(vector_date[-n_test:],obs3[:,lead_time],'k-.')\n",
        "#   plt.plot(vector_date[-n_test:],pred3[:,lead_time],'r-.')\n",
        "#     # plt.xticks(['2015-01','2015-06','2015-12','2016-12'])\n",
        "#   plt.legend(['obs','simulation'])\n",
        "\n",
        "#   plt.ylabel('NDI')\n",
        "#   # plt.title('Time series '+'1month' +' lead time prediction at testing')\n",
        "#   plt.tight_layout() \n",
        "\n",
        "#   plt.savefig(outs[3]+'/'+str(k)+'test_time_T4'+str(m)+'.jpeg',dpi=300)\n",
        "#   plt.show()\n",
        "#   plt.close()\n",
        "# =============================================================================\n",
        "\n",
        "# TEST*************************************************************************\n",
        "  # Chi plot 2015-2016\n",
        "#Graph\n",
        "months=['1month','2months','3months']\n",
        "for lead_time in range(1):\n",
        "  fig,ax=plt.subplots(figsize=(6,3))\n",
        "  plt.subplot(111)\n",
        "  plt.rcParams.update({'font.size': 12})\n",
        "  plt.ylim([-6.0,2.3])\n",
        "  # vector_date_test=vector_date[-24:]\n",
        "  n_test_plot=len(pred3)\n",
        "  vector_date_test=vector_date[-n_test_plot:]\n",
        "  plt.plot(vector_date[-n_test_plot:],obs3[-n_test_plot:],'k-.')\n",
        "  plt.plot(vector_date[-n_test_plot:],pred3[-n_test_plot:],'r-.')\n",
        "    # plt.xticks(['2015-01','2015-06','2015-12','2016-12'])\n",
        "  plt.legend(['obs','simulation'])\n",
        "\n",
        "  plt.ylabel('NDI')\n",
        "  # plt.title('Time series '+'1month' +' lead time prediction at testing')\n",
        "  plt.tight_layout() \n",
        "\n",
        "  plt.savefig(outs[3]+'/'+names[n_out0-1]+str(k)+'test_time_T4'+str(m)+'.jpeg',dpi=300)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "# =============================================================================\n"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQcfupdK98gU"
      },
      "source": [
        "# Save result to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsVUpAeo-AZJ"
      },
      "source": [
        "  \n",
        "      # compressed_file = bz2.BZ2File(f, 'w')\n",
        "m=0\n",
        "\n",
        "# 0: train, #1: val, # 2:test\n",
        "# list_con[2].iloc[-24:,:].to_csv(outs[2]+'/'+'T4-'+str(m+1)+'.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhIdX5BRPW7Z"
      },
      "source": [
        "# ## enable to see data franame\n",
        "# %load_ext google.colab.data_table\n",
        "# df_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBhIXQgZPrWO"
      },
      "source": [
        "\n",
        "\n",
        "# ## diable to see dataframe\n",
        "# %unload_ext google.colab.data_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LkWwR5qpE6p"
      },
      "source": [
        "# %tensorboard --logdir logs/T4-M1-TB-2021/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6GP0lqu3PT0"
      },
      "source": [
        "# from tensorboard import notebook\n",
        "# notebook.list() # View open TensorBoard instances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN_uJJhS3X_B"
      },
      "source": [
        "# # Control TensorBoard display. If no port is provided, \n",
        "# # the most recently launched TensorBoard is used\n",
        "# notebook.display(port=13042, height=1000) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}